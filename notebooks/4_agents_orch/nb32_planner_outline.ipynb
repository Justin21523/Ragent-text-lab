{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1fc7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cache] ../ai_warehouse/cache | GPU: True\n"
     ]
    }
   ],
   "source": [
    "# nb32_planner_outline.ipynb\n",
    "# Goals: Implement Planner agent for structured outline generation\n",
    "# Prerequisites: LLMAdapter, basic message formatting, style dictionary concepts\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (è¤‡è£½åˆ°æ¯æœ¬ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdb8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Dependencies\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d58aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: LLMAdapter (Minimal)\n",
    "class LLMAdapter:\n",
    "    def __init__(self, model_id=\"Qwen/Qwen2.5-7B-Instruct\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id, device_map=\"auto\", torch_dtype=torch.float16\n",
    "        )\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def generate(self, messages, max_new_tokens=512, temperature=0.7):\n",
    "        # Simple message formatting\n",
    "        prompt = \"\\n\".join(\n",
    "            [f\"{msg['role'].upper()}: {msg['content']}\" for msg in messages]\n",
    "        )\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, return_tensors=\"pt\", truncation=True, max_length=2048\n",
    "        )\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "            )\n",
    "\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Extract only the new generated part\n",
    "        return response[len(prompt) :].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cde70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Outline Data Structures\n",
    "@dataclass\n",
    "class OutlineNode:\n",
    "    title: str\n",
    "    level: int  # 1=chapter, 2=section, 3=subsection\n",
    "    description: str = \"\"\n",
    "    key_points: List[str] = None\n",
    "    children: List[\"OutlineNode\"] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.key_points is None:\n",
    "            self.key_points = []\n",
    "        if self.children is None:\n",
    "            self.children = []\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"title\": self.title,\n",
    "            \"level\": self.level,\n",
    "            \"description\": self.description,\n",
    "            \"key_points\": self.key_points,\n",
    "            \"children\": [child.to_dict() for child in self.children],\n",
    "        }\n",
    "\n",
    "    def to_markdown(self, indent=\"\"):\n",
    "        lines = []\n",
    "        prefix = \"#\" * self.level\n",
    "        lines.append(f\"{indent}{prefix} {self.title}\")\n",
    "\n",
    "        if self.description:\n",
    "            lines.append(f\"{indent}{self.description}\")\n",
    "\n",
    "        for point in self.key_points:\n",
    "            lines.append(f\"{indent}- {point}\")\n",
    "\n",
    "        for child in self.children:\n",
    "            lines.extend(child.to_markdown(indent))\n",
    "\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Document Type Templates\n",
    "OUTLINE_TEMPLATES = {\n",
    "    \"research_report\": {\n",
    "        \"structure\": [\n",
    "            {\"title\": \"æ‘˜è¦\", \"level\": 1, \"description\": \"æ ¸å¿ƒç™¼ç¾èˆ‡çµè«–æ¦‚è¦\"},\n",
    "            {\"title\": \"èƒŒæ™¯èˆ‡å‹•æ©Ÿ\", \"level\": 1, \"description\": \"ç ”ç©¶å•é¡Œèˆ‡é‡è¦æ€§\"},\n",
    "            {\"title\": \"ä¸»è¦ç™¼ç¾\", \"level\": 1, \"description\": \"æ ¸å¿ƒç ”ç©¶çµæœåˆ†æ\"},\n",
    "            {\"title\": \"æ·±å…¥è¨è«–\", \"level\": 1, \"description\": \"ç™¼ç¾çš„æ„æ¶µèˆ‡å½±éŸ¿\"},\n",
    "            {\"title\": \"çµè«–èˆ‡å»ºè­°\", \"level\": 1, \"description\": \"è¡Œå‹•å»ºè­°èˆ‡æœªä¾†æ–¹å‘\"},\n",
    "        ]\n",
    "    },\n",
    "    \"technical_guide\": {\n",
    "        \"structure\": [\n",
    "            {\"title\": \"æ¦‚è¿°\", \"level\": 1, \"description\": \"æŠ€è¡“æ¦‚å¿µèˆ‡ç›®æ¨™\"},\n",
    "            {\"title\": \"æº–å‚™å·¥ä½œ\", \"level\": 1, \"description\": \"ç’°å¢ƒè¨­å®šèˆ‡å‰ç½®éœ€æ±‚\"},\n",
    "            {\"title\": \"å¯¦ä½œæ­¥é©Ÿ\", \"level\": 1, \"description\": \"è©³ç´°æ“ä½œæµç¨‹\"},\n",
    "            {\"title\": \"æœ€ä½³å¯¦å‹™\", \"level\": 1, \"description\": \"ç¶“é©—åˆ†äº«èˆ‡æ³¨æ„äº‹é …\"},\n",
    "            {\"title\": \"ç–‘é›£æ’è§£\", \"level\": 1, \"description\": \"å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ\"},\n",
    "        ]\n",
    "    },\n",
    "    \"business_proposal\": {\n",
    "        \"structure\": [\n",
    "            {\"title\": \"åŸ·è¡Œæ‘˜è¦\", \"level\": 1, \"description\": \"ææ¡ˆæ ¸å¿ƒé‡é»\"},\n",
    "            {\"title\": \"å¸‚å ´åˆ†æ\", \"level\": 1, \"description\": \"æ©Ÿæœƒèˆ‡ç«¶çˆ­ç’°å¢ƒ\"},\n",
    "            {\"title\": \"è§£æ±ºæ–¹æ¡ˆ\", \"level\": 1, \"description\": \"ç”¢å“æˆ–æœå‹™èªªæ˜\"},\n",
    "            {\"title\": \"å¯¦æ–½è¨ˆç•«\", \"level\": 1, \"description\": \"æ™‚ç¨‹èˆ‡è³‡æºé…ç½®\"},\n",
    "            {\"title\": \"è²¡å‹™é æ¸¬\", \"level\": 1, \"description\": \"æˆæœ¬æ•ˆç›Šåˆ†æ\"},\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7cdc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Style Dictionary Integration\n",
    "class StyleDictionary:\n",
    "    def __init__(self, config_path=None):\n",
    "        if config_path and os.path.exists(config_path):\n",
    "            with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.config = yaml.safe_load(f)\n",
    "        else:\n",
    "            # Default Chinese style configuration\n",
    "            self.config = {\n",
    "                \"tone\": \"professional\",\n",
    "                \"format\": {\n",
    "                    \"use_numbered_chapters\": True,\n",
    "                    \"max_sections_per_chapter\": 5,\n",
    "                    \"prefer_bullet_points\": True,\n",
    "                },\n",
    "                \"terminology\": {\n",
    "                    \"RAG\": \"æª¢ç´¢å¢å¼·ç”Ÿæˆ\",\n",
    "                    \"LLM\": \"å¤§å‹èªè¨€æ¨¡å‹\",\n",
    "                    \"embedding\": \"åµŒå…¥å‘é‡\",\n",
    "                    \"chunk\": \"æ–‡æœ¬ç‰‡æ®µ\",\n",
    "                },\n",
    "                \"structure_rules\": [\n",
    "                    \"æ¯ç« æ‡‰æœ‰æ˜ç¢ºçš„å­¸ç¿’ç›®æ¨™\",\n",
    "                    \"ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«\",\n",
    "                    \"æŠ€è¡“è¡“èªä¿æŒä¸­è‹±å°ç…§\",\n",
    "                    \"ç« ç¯€å®‰æ’è¦å¾ªåºæ¼¸é€²\",\n",
    "                ],\n",
    "            }\n",
    "\n",
    "    def apply_terminology(self, text):\n",
    "        \"\"\"Apply terminology mapping to text\"\"\"\n",
    "        for en_term, zh_term in self.config.get(\"terminology\", {}).items():\n",
    "            # Replace English terms with Chinese equivalents\n",
    "            text = re.sub(\n",
    "                r\"\\b\" + re.escape(en_term) + r\"\\b\", f\"{zh_term} ({en_term})\", text\n",
    "            )\n",
    "        return text\n",
    "\n",
    "    def get_structure_guidelines(self):\n",
    "        \"\"\"Get structure rules for outline generation\"\"\"\n",
    "        return self.config.get(\"structure_rules\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Main Planner Agent\n",
    "class PlannerAgent:\n",
    "    def __init__(self, llm_adapter, style_config=None):\n",
    "        self.llm = llm_adapter\n",
    "        self.style = StyleDictionary(style_config)\n",
    "\n",
    "    def create_outline(\n",
    "        self, research_data, document_type=\"research_report\", target_audience=\"general\"\n",
    "    ):\n",
    "        \"\"\"Generate structured outline based on research data\"\"\"\n",
    "\n",
    "        # Get template structure\n",
    "        template = OUTLINE_TEMPLATES.get(\n",
    "            document_type, OUTLINE_TEMPLATES[\"research_report\"]\n",
    "        )\n",
    "\n",
    "        # Prepare planning prompt\n",
    "        style_rules = \"\\n\".join(self.style.get_structure_guidelines())\n",
    "\n",
    "        planning_prompt = f\"\"\"\n",
    "åŸºæ–¼ä»¥ä¸‹ç ”ç©¶è³‡æ–™ï¼Œç‚ºã€Œ{document_type}ã€é¡å‹æ–‡ä»¶è¦åŠƒè©³ç´°å¤§ç¶±ã€‚\n",
    "\n",
    "ç ”ç©¶è³‡æ–™ï¼š\n",
    "{research_data[:2000]}  # Truncate to avoid token limit\n",
    "\n",
    "ç›®æ¨™è®€è€…ï¼š{target_audience}\n",
    "\n",
    "åŸºæœ¬çµæ§‹ç¯„æœ¬ï¼š\n",
    "{json.dumps(template, ensure_ascii=False, indent=2)}\n",
    "\n",
    "é¢¨æ ¼è¦æ±‚ï¼š\n",
    "{style_rules}\n",
    "\n",
    "è«‹ç”ŸæˆåŒ…å«ä»¥ä¸‹è¦ç´ çš„çµæ§‹åŒ–å¤§ç¶±ï¼š\n",
    "1. ä¸»è¦ç« ç¯€ï¼ˆç¬¬ä¸€å±¤ï¼‰\n",
    "2. å„ç« ç¯€ä¸‹çš„å°ç¯€ï¼ˆç¬¬äºŒå±¤ï¼‰\n",
    "3. æ¯å€‹å°ç¯€çš„æ ¸å¿ƒè¦é»ï¼ˆ3-5é»ï¼‰\n",
    "4. ç°¡çŸ­çš„å…§å®¹æè¿°\n",
    "\n",
    "è¼¸å‡ºæ ¼å¼è¦æ±‚ï¼šJSONæ ¼å¼ï¼Œçµæ§‹å¦‚ä¸‹ï¼š\n",
    "{{\n",
    "  \"outline\": [\n",
    "    {{\n",
    "      \"title\": \"ç« ç¯€æ¨™é¡Œ\",\n",
    "      \"level\": 1,\n",
    "      \"description\": \"ç« ç¯€æè¿°\",\n",
    "      \"key_points\": [\"è¦é»1\", \"è¦é»2\"],\n",
    "      \"sections\": [\n",
    "        {{\n",
    "          \"title\": \"å°ç¯€æ¨™é¡Œ\",\n",
    "          \"level\": 2,\n",
    "          \"description\": \"å°ç¯€æè¿°\",\n",
    "          \"key_points\": [\"ç´°ç¯€è¦é»1\", \"ç´°ç¯€è¦é»2\"]\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡ä»¶çµæ§‹è¦åŠƒå°ˆå®¶ï¼Œæ“…é•·å‰µå»ºé‚è¼¯æ¸…æ™°ã€å…§å®¹å®Œæ•´çš„æ–‡ä»¶å¤§ç¶±ã€‚\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": planning_prompt},\n",
    "        ]\n",
    "\n",
    "        response = self.llm.generate(messages, max_new_tokens=1024, temperature=0.5)\n",
    "\n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            # Extract JSON from response\n",
    "            json_match = re.search(r\"\\{.*\\}\", response, re.DOTALL)\n",
    "            if json_match:\n",
    "                outline_data = json.loads(json_match.group())\n",
    "                return self._parse_outline_data(outline_data)\n",
    "            else:\n",
    "                # Fallback: create basic outline from template\n",
    "                return self._create_fallback_outline(template, research_data)\n",
    "        except json.JSONDecodeError:\n",
    "            return self._create_fallback_outline(template, research_data)\n",
    "\n",
    "    def _parse_outline_data(self, data):\n",
    "        \"\"\"Parse JSON outline data into OutlineNode objects\"\"\"\n",
    "        outline_nodes = []\n",
    "\n",
    "        for chapter_data in data.get(\"outline\", []):\n",
    "            chapter = OutlineNode(\n",
    "                title=chapter_data[\"title\"],\n",
    "                level=chapter_data[\"level\"],\n",
    "                description=chapter_data.get(\"description\", \"\"),\n",
    "                key_points=chapter_data.get(\"key_points\", []),\n",
    "            )\n",
    "\n",
    "            # Add sections\n",
    "            for section_data in chapter_data.get(\"sections\", []):\n",
    "                section = OutlineNode(\n",
    "                    title=section_data[\"title\"],\n",
    "                    level=section_data[\"level\"],\n",
    "                    description=section_data.get(\"description\", \"\"),\n",
    "                    key_points=section_data.get(\"key_points\", []),\n",
    "                )\n",
    "                chapter.children.append(section)\n",
    "\n",
    "            outline_nodes.append(chapter)\n",
    "\n",
    "        return outline_nodes\n",
    "\n",
    "    def _create_fallback_outline(self, template, research_data):\n",
    "        \"\"\"Create basic outline when JSON parsing fails\"\"\"\n",
    "        outline_nodes = []\n",
    "\n",
    "        for item in template[\"structure\"]:\n",
    "            node = OutlineNode(\n",
    "                title=item[\"title\"],\n",
    "                level=item[\"level\"],\n",
    "                description=item[\"description\"],\n",
    "                key_points=[\"å¾…è¦åŠƒå…§å®¹è¦é»\"],\n",
    "            )\n",
    "            outline_nodes.append(node)\n",
    "\n",
    "        return outline_nodes\n",
    "\n",
    "    def validate_outline(self, outline):\n",
    "        \"\"\"Validate outline structure and completeness\"\"\"\n",
    "        issues = []\n",
    "\n",
    "        if not outline:\n",
    "            issues.append(\"å¤§ç¶±ç‚ºç©º\")\n",
    "            return issues\n",
    "\n",
    "        # Check minimum chapters\n",
    "        if len(outline) < 3:\n",
    "            issues.append(\"ç« ç¯€æ•¸é‡éå°‘ï¼ˆå»ºè­°è‡³å°‘3ç« ï¼‰\")\n",
    "\n",
    "        # Check maximum chapters\n",
    "        if len(outline) > 10:\n",
    "            issues.append(\"ç« ç¯€æ•¸é‡éå¤šï¼ˆå»ºè­°ä¸è¶…é10ç« ï¼‰\")\n",
    "\n",
    "        # Check each chapter\n",
    "        for i, chapter in enumerate(outline):\n",
    "            if not chapter.title.strip():\n",
    "                issues.append(f\"ç¬¬{i+1}ç« ç¼ºå°‘æ¨™é¡Œ\")\n",
    "\n",
    "            if len(chapter.children) == 0:\n",
    "                issues.append(f\"ç¬¬{i+1}ç« ã€Œ{chapter.title}ã€ç¼ºå°‘å°ç¯€\")\n",
    "\n",
    "            if len(chapter.children) > 7:\n",
    "                issues.append(f\"ç¬¬{i+1}ç« ã€Œ{chapter.title}ã€å°ç¯€éå¤šï¼ˆå»ºè­°ä¸è¶…é7å€‹ï¼‰\")\n",
    "\n",
    "            # Check sections\n",
    "            for j, section in enumerate(chapter.children):\n",
    "                if not section.key_points:\n",
    "                    issues.append(f\"ç¬¬{i+1}ç« ç¬¬{j+1}å°ç¯€ã€Œ{section.title}ã€ç¼ºå°‘è¦é»\")\n",
    "\n",
    "        return issues\n",
    "\n",
    "    def refine_outline(self, outline, feedback):\n",
    "        \"\"\"Refine outline based on feedback\"\"\"\n",
    "        refinement_prompt = f\"\"\"\n",
    "è«‹æ ¹æ“šä»¥ä¸‹å›é¥‹æ„è¦‹å„ªåŒ–å¤§ç¶±çµæ§‹ï¼š\n",
    "\n",
    "å›é¥‹æ„è¦‹ï¼š\n",
    "{feedback}\n",
    "\n",
    "ç›®å‰å¤§ç¶±ï¼š\n",
    "{self._outline_to_text(outline)}\n",
    "\n",
    "è«‹æä¾›æ”¹é€²å»ºè­°ï¼Œè¼¸å‡ºæ ¼å¼ï¼š\n",
    "1. å…·é«”ä¿®æ”¹å»ºè­°\n",
    "2. èª¿æ•´å¾Œçš„å¤§ç¶±çµæ§‹ï¼ˆé‡é»ç« ç¯€ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"ä½ æ˜¯æ–‡ä»¶çµæ§‹å„ªåŒ–å°ˆå®¶ï¼Œèƒ½æ ¹æ“šå›é¥‹æ”¹å–„å¤§ç¶±å“è³ªã€‚\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": refinement_prompt},\n",
    "        ]\n",
    "\n",
    "        response = self.llm.generate(messages, max_new_tokens=512, temperature=0.3)\n",
    "        return response\n",
    "\n",
    "    def _outline_to_text(self, outline):\n",
    "        \"\"\"Convert outline to readable text format\"\"\"\n",
    "        lines = []\n",
    "        for chapter in outline:\n",
    "            lines.extend(chapter.to_markdown())\n",
    "            lines.append(\"\")  # Empty line between chapters\n",
    "        return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d68432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Blackboard Integration\n",
    "class PlannerBlackboard:\n",
    "    \"\"\"Shared state management for planner\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.research_data = \"\"\n",
    "        self.outline_history = []\n",
    "        self.feedback_log = []\n",
    "        self.current_outline = None\n",
    "        self.metadata = {}\n",
    "\n",
    "    def update_research(self, data):\n",
    "        self.research_data = data\n",
    "        self.metadata[\"research_updated\"] = True\n",
    "\n",
    "    def add_outline_version(self, outline, version_note=\"\"):\n",
    "        self.outline_history.append(\n",
    "            {\n",
    "                \"outline\": outline,\n",
    "                \"timestamp\": str(torch.cuda.Event().record()),  # Simple timestamp\n",
    "                \"note\": version_note,\n",
    "            }\n",
    "        )\n",
    "        self.current_outline = outline\n",
    "\n",
    "    def add_feedback(self, feedback, source=\"manual\"):\n",
    "        self.feedback_log.append(\n",
    "            {\n",
    "                \"feedback\": feedback,\n",
    "                \"source\": source,\n",
    "                \"timestamp\": str(torch.cuda.Event().record()),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def get_status(self):\n",
    "        return {\n",
    "            \"has_research\": bool(self.research_data),\n",
    "            \"outline_versions\": len(self.outline_history),\n",
    "            \"feedback_count\": len(self.feedback_log),\n",
    "            \"current_outline_chapters\": (\n",
    "                len(self.current_outline) if self.current_outline else 0\n",
    "            ),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Smoke Test - End-to-End Outline Generation\n",
    "print(\"=== nb32 Planner Agent ç…™éœ§æ¸¬è©¦ ===\\n\")\n",
    "\n",
    "# Initialize components\n",
    "llm = LLMAdapter()\n",
    "planner = PlannerAgent(llm)\n",
    "blackboard = PlannerBlackboard()\n",
    "\n",
    "# Mock research data\n",
    "research_data = \"\"\"\n",
    "ç ”ç©¶ä¸»é¡Œï¼šä¸­æ–‡RAGç³»çµ±å¯¦ä½œæŒ‡å—\n",
    "\n",
    "ä¸»è¦ç™¼ç¾ï¼š\n",
    "1. ä¸­æ–‡æ–‡æœ¬åˆ†æ®µç­–ç•¥éœ€è¦è€ƒæ…®æ¨™é»ç¬¦è™Ÿå¯†åº¦\n",
    "2. BGE-M3åµŒå…¥æ¨¡å‹åœ¨ä¸­æ–‡æª¢ç´¢ä»»å‹™è¡¨ç¾å„ªç•°\n",
    "3. FAISSç´¢å¼•é…ç½®å°æª¢ç´¢é€Ÿåº¦å½±éŸ¿é¡¯è‘—\n",
    "4. é‡æ’åºæ¨¡å‹èƒ½æœ‰æ•ˆæå‡æª¢ç´¢ç²¾åº¦\n",
    "5. å¼•ç”¨æ ¼å¼æ¨™æº–åŒ–æœ‰åŠ©æå‡å¯ä¿¡åº¦\n",
    "\n",
    "æŠ€è¡“ç´°ç¯€ï¼š\n",
    "- chunk_sizeå»ºè­°800-1000 tokens\n",
    "- æ··åˆæª¢ç´¢(BM25+å‘é‡)æ¯”å–®ä¸€æ–¹æ³•æ•ˆæœå¥½\n",
    "- å¤šåŸŸç´¢å¼•è·¯ç”±èƒ½è™•ç†ä¸åŒä¸»é¡Œæ–‡æª”\n",
    "- Style Dictionaryç¢ºä¿è¼¸å‡ºæ ¼å¼ä¸€è‡´æ€§\n",
    "\n",
    "å¯¦é©—çµæœï¼š\n",
    "- Recall@5é”åˆ°0.85ä»¥ä¸Š\n",
    "- å¹³å‡æª¢ç´¢å»¶é²<100ms\n",
    "- å¼•ç”¨æº–ç¢ºç‡>90%\n",
    "\"\"\"\n",
    "\n",
    "print(\"1. æ›´æ–°ç ”ç©¶è³‡æ–™åˆ°å…±äº«ç‹€æ…‹...\")\n",
    "blackboard.update_research(research_data)\n",
    "\n",
    "print(\"2. ç”ŸæˆæŠ€è¡“æŒ‡å—å¤§ç¶±...\")\n",
    "outline = planner.create_outline(\n",
    "    research_data, document_type=\"technical_guide\", target_audience=\"AIé–‹ç™¼è€…\"\n",
    ")\n",
    "\n",
    "print(\"3. é©—è­‰å¤§ç¶±çµæ§‹...\")\n",
    "issues = planner.validate_outline(outline)\n",
    "print(f\"   ç™¼ç¾å•é¡Œæ•¸é‡: {len(issues)}\")\n",
    "if issues:\n",
    "    for issue in issues[:3]:  # Show first 3 issues\n",
    "        print(f\"   - {issue}\")\n",
    "\n",
    "print(\"4. å„²å­˜å¤§ç¶±ç‰ˆæœ¬...\")\n",
    "blackboard.add_outline_version(outline, \"åˆå§‹ç‰ˆæœ¬\")\n",
    "\n",
    "print(\"5. è¼¸å‡ºå¤§ç¶±æ‘˜è¦...\")\n",
    "if outline:\n",
    "    print(f\"   ç« ç¯€æ•¸é‡: {len(outline)}\")\n",
    "    for i, chapter in enumerate(outline[:3]):  # Show first 3 chapters\n",
    "        print(f\"   {i+1}. {chapter.title}\")\n",
    "        if chapter.children:\n",
    "            print(f\"      å°ç¯€æ•¸é‡: {len(chapter.children)}\")\n",
    "\n",
    "print(\"6. åŒ¯å‡ºç‚ºMarkdownæ ¼å¼...\")\n",
    "markdown_content = OutlineExporter.to_markdown(outline)\n",
    "print(f\"   Markdowné•·åº¦: {len(markdown_content)} å­—å…ƒ\")\n",
    "\n",
    "print(\"7. å…±äº«ç‹€æ…‹æª¢æŸ¥...\")\n",
    "status = blackboard.get_status()\n",
    "for key, value in status.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Save to outputs for inspection\n",
    "os.makedirs(\"outs\", exist_ok=True)\n",
    "OutlineExporter.save_outline(outline, \"outs/sample_outline.md\", \"markdown\")\n",
    "OutlineExporter.save_outline(outline, \"outs/sample_outline.json\", \"json\")\n",
    "\n",
    "print(\"\\nâœ… Planner Agent æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦å®Œæˆï¼\")\n",
    "print(\"ğŸ”¥ Smoke test é€šé - èƒ½å¤ ç”Ÿæˆçµæ§‹åŒ–å¤§ç¶±ä¸¦æ•´åˆåˆ°å¤šä»£ç†å·¥ä½œæµç¨‹\")\n",
    "\n",
    "# Key parameters and configurations\n",
    "print(\"\\n=== é—œéµåƒæ•¸èªªæ˜ ===\")\n",
    "print(\"â€¢ LLMæº«åº¦: 0.5 (å¹³è¡¡å‰µæ„èˆ‡ä¸€è‡´æ€§)\")\n",
    "print(\"â€¢ æœ€å¤§æ–°tokens: 1024 (æ”¯æ´è©³ç´°å¤§ç¶±)\")\n",
    "print(\"â€¢ ç« ç¯€æ•¸é‡é™åˆ¶: 3-10ç« \")\n",
    "print(\"â€¢ æ¯ç« å°ç¯€é™åˆ¶: æœ€å¤š7å€‹\")\n",
    "print(\"â€¢ æ”¯æ´æ–‡ä»¶é¡å‹: research_report, technical_guide, business_proposal\")\n",
    "print(\"â€¢ è¼¸å‡ºæ ¼å¼: Markdown, JSON\")\n",
    "\n",
    "print(\"\\n=== ä½•æ™‚ä½¿ç”¨æ­¤æ¨¡çµ„ ===\")\n",
    "print(\"âœ“ éœ€è¦å°‡ç ”ç©¶è³‡æ–™è½‰åŒ–ç‚ºçµæ§‹åŒ–æ–‡ä»¶å¤§ç¶±\")\n",
    "print(\"âœ“ å¤šä»£ç†å”ä½œä¸­çš„è¦åŠƒéšæ®µ\")\n",
    "print(\"âœ“ ç¢ºä¿æ–‡ä»¶é‚è¼¯çµæ§‹å®Œæ•´æ€§\")\n",
    "print(\"âœ“ æ¨™æº–åŒ–ä¸åŒé¡å‹æ–‡ä»¶çš„çµ„ç¹”æ–¹å¼\")\n",
    "print(\"âœ“ æ•´åˆé¢¨æ ¼æŒ‡å—åˆ°æ–‡ä»¶è¦åŠƒæµç¨‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Outline Export and Utilities\n",
    "class OutlineExporter:\n",
    "    @staticmethod\n",
    "    def to_markdown(outline):\n",
    "        \"\"\"Export outline to Markdown format\"\"\"\n",
    "        lines = []\n",
    "        for chapter in outline:\n",
    "            lines.extend(chapter.to_markdown())\n",
    "            lines.append(\"\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_json(outline):\n",
    "        \"\"\"Export outline to JSON format\"\"\"\n",
    "        return json.dumps(\n",
    "            [node.to_dict() for node in outline], ensure_ascii=False, indent=2\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_outline(outline, filepath, format=\"markdown\"):\n",
    "        \"\"\"Save outline to file\"\"\"\n",
    "        pathlib.Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if format == \"markdown\":\n",
    "            content = OutlineExporter.to_markdown(outline)\n",
    "        elif format == \"json\":\n",
    "            content = OutlineExporter.to_json(outline)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format: {format}\")\n",
    "\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        print(f\"Outline saved to: {filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
