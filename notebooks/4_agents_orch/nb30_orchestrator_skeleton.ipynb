{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (複製到每本 notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Dependencies & Imports\n",
    "import json, time, asyncio, traceback\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from enum import Enum\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Blackboard State Management\n",
    "class Blackboard(dict):\n",
    "    \"\"\"\n",
    "    Shared state management for multi-agent collaboration.\n",
    "    Stores research results, plans, drafts, and review feedback.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.update(\n",
    "            {\n",
    "                \"query\": \"\",\n",
    "                \"research_results\": [],\n",
    "                \"plan\": [],\n",
    "                \"draft\": \"\",\n",
    "                \"review_feedback\": [],\n",
    "                \"final_output\": \"\",\n",
    "                \"metadata\": {\"start_time\": time.time(), \"iterations\": 0, \"errors\": []},\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def log_error(self, agent: str, error: str):\n",
    "        \"\"\"Log errors for debugging\"\"\"\n",
    "        self[\"metadata\"][\"errors\"].append(\n",
    "            {\"agent\": agent, \"error\": error, \"timestamp\": time.time()}\n",
    "        )\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        \"\"\"Get formatted context for agents\"\"\"\n",
    "        context = f\"Query: {self['query']}\\n\"\n",
    "        if self[\"research_results\"]:\n",
    "            context += f\"Research: {len(self['research_results'])} findings\\n\"\n",
    "        if self[\"plan\"]:\n",
    "            context += f\"Plan: {len(self['plan'])} sections\\n\"\n",
    "        if self[\"draft\"]:\n",
    "            context += f\"Draft: {len(self['draft'])} chars\\n\"\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d389c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Agent Role Definitions\n",
    "class AgentRole(Enum):\n",
    "    RESEARCHER = \"researcher\"\n",
    "    PLANNER = \"planner\"\n",
    "    WRITER = \"writer\"\n",
    "    REVIEWER = \"reviewer\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"Configuration for each agent role\"\"\"\n",
    "\n",
    "    max_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    timeout: int = 60\n",
    "    max_retries: int = 2\n",
    "\n",
    "\n",
    "# Default configs for each role\n",
    "AGENT_CONFIGS = {\n",
    "    AgentRole.RESEARCHER: AgentConfig(max_tokens=1024, temperature=0.3),\n",
    "    AgentRole.PLANNER: AgentConfig(max_tokens=512, temperature=0.5),\n",
    "    AgentRole.WRITER: AgentConfig(max_tokens=2048, temperature=0.7),\n",
    "    AgentRole.REVIEWER: AgentConfig(max_tokens=512, temperature=0.2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f130764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Base Agent Class\n",
    "class BaseAgent:\n",
    "    \"\"\"Base class for all agents with common functionality\"\"\"\n",
    "\n",
    "    def __init__(self, role: AgentRole, llm_adapter, config: AgentConfig = None):\n",
    "        self.role = role\n",
    "        self.llm = llm_adapter\n",
    "        self.config = config or AGENT_CONFIGS[role]\n",
    "        self.logger = logging.getLogger(f\"Agent.{role.value}\")\n",
    "\n",
    "    def _create_messages(self, system_prompt: str, user_prompt: str) -> List[Dict]:\n",
    "        \"\"\"Create messages format for LLM\"\"\"\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "\n",
    "    def _call_llm(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"Safe LLM call with error handling\"\"\"\n",
    "        try:\n",
    "            response = self.llm.generate(\n",
    "                messages=messages,\n",
    "                max_new_tokens=self.config.max_tokens,\n",
    "                temperature=self.config.temperature,\n",
    "            )\n",
    "            # Extract only the assistant's response\n",
    "            if \"assistant:\" in response:\n",
    "                return response.split(\"assistant:\")[-1].strip()\n",
    "            return response.strip()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"LLM call failed: {e}\")\n",
    "            return f\"[ERROR] {str(e)}\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Execute agent's task - to be overridden by subclasses\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Individual Agent Implementations\n",
    "class ResearcherAgent(BaseAgent):\n",
    "    \"\"\"Researcher: Gathers information using RAG and web search\"\"\"\n",
    "\n",
    "    def __init__(self, llm_adapter, rag_retriever=None):\n",
    "        super().__init__(AgentRole.RESEARCHER, llm_adapter)\n",
    "        self.rag = rag_retriever\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Research the query and populate research_results\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "\n",
    "        system_prompt = \"\"\"You are a research assistant. Your job is to gather relevant information and provide key findings with citations where possible.\n",
    "Focus on factual information and cite sources. Keep each finding concise but informative.\"\"\"\n",
    "\n",
    "        # Use RAG if available\n",
    "        context = \"\"\n",
    "        if self.rag:\n",
    "            try:\n",
    "                # Simplified RAG call (assumes retrieve method exists)\n",
    "                rag_results = self.rag.search(query, k=5)\n",
    "                context = \"\\n\".join(\n",
    "                    [f\"[{i+1}] {item[0]}\" for i, item in enumerate(rag_results)]\n",
    "                )\n",
    "                context = f\"Available knowledge:\\n{context}\\n\\n\"\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"RAG search failed: {e}\")\n",
    "\n",
    "        user_prompt = f\"\"\"{context}Research query: {query}\n",
    "\n",
    "Provide 3-5 key research findings. Format each as:\n",
    "- Finding: [brief description]\n",
    "- Source: [if available]\n",
    "- Relevance: [why important for this query]\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            blackboard[\"research_results\"].append(\n",
    "                {\"agent\": \"researcher\", \"content\": response, \"timestamp\": time.time()}\n",
    "            )\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"researcher\", response)\n",
    "            return False\n",
    "\n",
    "\n",
    "class PlannerAgent(BaseAgent):\n",
    "    \"\"\"Planner: Creates structured outline based on research\"\"\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Create a structured plan based on research results\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "        research = blackboard[\"research_results\"]\n",
    "\n",
    "        system_prompt = \"\"\"You are a planning assistant. Create a clear, structured outline for addressing the user's query based on research findings.\n",
    "Focus on logical flow and completeness. Keep each section concise but comprehensive.\"\"\"\n",
    "\n",
    "        research_summary = \"\\n\".join(\n",
    "            [\n",
    "                f\"Research {i+1}: {r['content'][:200]}...\"\n",
    "                for i, r in enumerate(research[-3:])  # Last 3 research results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "Available research:\n",
    "{research_summary}\n",
    "\n",
    "Create a structured outline with 3-5 main sections. Format as:\n",
    "1. Section Title: Brief description\n",
    "2. Section Title: Brief description\n",
    "...\n",
    "\n",
    "Each section should be actionable and directly address the query.\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            # Parse plan into sections\n",
    "            sections = []\n",
    "            for line in response.split(\"\\n\"):\n",
    "                if line.strip() and (\n",
    "                    line.strip()[0].isdigit() or line.strip().startswith(\"-\")\n",
    "                ):\n",
    "                    sections.append(line.strip())\n",
    "\n",
    "            blackboard[\"plan\"] = sections\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"planner\", response)\n",
    "            return False\n",
    "\n",
    "\n",
    "class WriterAgent(BaseAgent):\n",
    "    \"\"\"Writer: Produces content based on plan and research\"\"\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Write content following the plan and incorporating research\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "        plan = blackboard[\"plan\"]\n",
    "        research = blackboard[\"research_results\"]\n",
    "\n",
    "        system_prompt = \"\"\"You are a skilled writer. Create comprehensive, well-structured content that follows the provided outline and incorporates research findings.\n",
    "Write in Traditional Chinese with clear explanations. Include citations where appropriate.\"\"\"\n",
    "\n",
    "        plan_text = \"\\n\".join(plan)\n",
    "        research_text = \"\\n\\n\".join(\n",
    "            [r[\"content\"] for r in research[-2:]]\n",
    "        )  # Last 2 research items\n",
    "\n",
    "        user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "Outline to follow:\n",
    "{plan_text}\n",
    "\n",
    "Research to incorporate:\n",
    "{research_text}\n",
    "\n",
    "Write a comprehensive response (300-800 words) that:\n",
    "1. Directly answers the query\n",
    "2. Follows the outline structure\n",
    "3. Incorporates research findings with citations\n",
    "4. Uses Traditional Chinese\n",
    "5. Is clear and well-organized\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            blackboard[\"draft\"] = response\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"writer\", response)\n",
    "            return False\n",
    "\n",
    "\n",
    "class ReviewerAgent(BaseAgent):\n",
    "    \"\"\"Reviewer: Evaluates content quality and provides feedback\"\"\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Review the draft and provide feedback\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "        draft = blackboard[\"draft\"]\n",
    "\n",
    "        if not draft:\n",
    "            blackboard.log_error(\"reviewer\", \"No draft available to review\")\n",
    "            return False\n",
    "\n",
    "        system_prompt = \"\"\"You are a quality reviewer. Evaluate content for accuracy, completeness, clarity, and alignment with the original query.\n",
    "Provide constructive feedback and suggest improvements. Be specific and actionable.\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Original query: {query}\n",
    "\n",
    "Draft to review:\n",
    "{draft}\n",
    "\n",
    "Evaluate this draft on:\n",
    "1. Accuracy - Are the facts correct?\n",
    "2. Completeness - Does it fully address the query?\n",
    "3. Clarity - Is it well-organized and easy to understand?\n",
    "4. Citations - Are sources properly referenced?\n",
    "\n",
    "Provide specific feedback and a quality score (1-10). If score ≥7, approve for final output.\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            blackboard[\"review_feedback\"].append(\n",
    "                {\"content\": response, \"timestamp\": time.time()}\n",
    "            )\n",
    "\n",
    "            # Simple approval logic - look for score ≥7 or positive keywords\n",
    "            is_approved = any(\n",
    "                keyword in response.lower()\n",
    "                for keyword in [\n",
    "                    \"score: 7\",\n",
    "                    \"score: 8\",\n",
    "                    \"score: 9\",\n",
    "                    \"score: 10\",\n",
    "                    \"approve\",\n",
    "                    \"good quality\",\n",
    "                    \"well done\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if is_approved:\n",
    "                blackboard[\"final_output\"] = draft\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"reviewer\", response)\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288154dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Core Orchestrator Class\n",
    "class Orchestrator:\n",
    "    \"\"\"\n",
    "    Main orchestrator that coordinates the 4-agent workflow.\n",
    "    Manages execution order, retries, and error handling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm_adapter, rag_retriever=None, max_iterations=3, timeout=300):\n",
    "        self.llm = llm_adapter\n",
    "        self.rag = rag_retriever\n",
    "        self.max_iterations = max_iterations\n",
    "        self.timeout = timeout\n",
    "\n",
    "        # Initialize agents\n",
    "        self.agents = {\n",
    "            AgentRole.RESEARCHER: ResearcherAgent(llm_adapter, rag_retriever),\n",
    "            AgentRole.PLANNER: PlannerAgent(llm_adapter),\n",
    "            AgentRole.WRITER: WriterAgent(llm_adapter),\n",
    "            AgentRole.REVIEWER: ReviewerAgent(llm_adapter),\n",
    "        }\n",
    "\n",
    "        self.logger = logging.getLogger(\"Orchestrator\")\n",
    "\n",
    "    def execute_workflow(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute the complete 4-agent workflow.\n",
    "        Returns final result with metadata.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        blackboard = Blackboard()\n",
    "        blackboard[\"query\"] = query\n",
    "\n",
    "        self.logger.info(f\"Starting workflow for query: {query[:100]}...\")\n",
    "\n",
    "        try:\n",
    "            for iteration in range(self.max_iterations):\n",
    "                blackboard[\"metadata\"][\"iterations\"] = iteration + 1\n",
    "\n",
    "                # Check timeout\n",
    "                if time.time() - start_time > self.timeout:\n",
    "                    self.logger.error(\"Workflow timeout reached\")\n",
    "                    break\n",
    "\n",
    "                # Execute agent sequence\n",
    "                workflow_success = self._execute_agent_sequence(blackboard)\n",
    "\n",
    "                if workflow_success and blackboard[\"final_output\"]:\n",
    "                    self.logger.info(\n",
    "                        f\"Workflow completed successfully in {iteration + 1} iterations\"\n",
    "                    )\n",
    "                    break\n",
    "                elif iteration == self.max_iterations - 1:\n",
    "                    self.logger.warning(\"Max iterations reached without approval\")\n",
    "                    # Use draft as final output if available\n",
    "                    if blackboard[\"draft\"]:\n",
    "                        blackboard[\"final_output\"] = blackboard[\"draft\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Workflow failed: {e}\")\n",
    "            blackboard.log_error(\"orchestrator\", str(e))\n",
    "\n",
    "        # Compile final result\n",
    "        result = {\n",
    "            \"query\": query,\n",
    "            \"final_output\": blackboard.get(\"final_output\", \"未能完成任務\"),\n",
    "            \"research_count\": len(blackboard[\"research_results\"]),\n",
    "            \"plan_sections\": len(blackboard[\"plan\"]),\n",
    "            \"review_feedback\": blackboard[\"review_feedback\"],\n",
    "            \"iterations\": blackboard[\"metadata\"][\"iterations\"],\n",
    "            \"duration\": time.time() - start_time,\n",
    "            \"errors\": blackboard[\"metadata\"][\"errors\"],\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _execute_agent_sequence(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Execute the standard agent sequence: Research → Plan → Write → Review\"\"\"\n",
    "\n",
    "        sequence = [\n",
    "            (AgentRole.RESEARCHER, \"研究階段\"),\n",
    "            (AgentRole.PLANNER, \"規劃階段\"),\n",
    "            (AgentRole.WRITER, \"寫作階段\"),\n",
    "            (AgentRole.REVIEWER, \"審核階段\"),\n",
    "        ]\n",
    "\n",
    "        for role, stage_name in sequence:\n",
    "            self.logger.info(f\"Executing {stage_name} ({role.value})\")\n",
    "\n",
    "            agent = self.agents[role]\n",
    "            success = False\n",
    "\n",
    "            # Retry logic for each agent\n",
    "            for attempt in range(agent.config.max_retries + 1):\n",
    "                try:\n",
    "                    success = agent.execute(blackboard)\n",
    "                    if success:\n",
    "                        break\n",
    "                    else:\n",
    "                        self.logger.warning(\n",
    "                            f\"{role.value} attempt {attempt + 1} failed\"\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"{role.value} attempt {attempt + 1} error: {e}\")\n",
    "                    blackboard.log_error(role.value, str(e))\n",
    "\n",
    "            if not success:\n",
    "                self.logger.error(f\"{stage_name} failed after all retries\")\n",
    "                return False\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4da88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Integration Setup (Mock LLM for testing)\n",
    "class MockLLMAdapter:\n",
    "    \"\"\"Mock LLM adapter for testing when real models aren't available\"\"\"\n",
    "\n",
    "    def generate(self, messages, max_new_tokens=256, temperature=0.7):\n",
    "        # Extract the last user message for context\n",
    "        user_content = \"\"\n",
    "        for msg in reversed(messages):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                user_content = msg[\"content\"]\n",
    "                break\n",
    "\n",
    "        # Generate mock responses based on content\n",
    "        if \"research\" in user_content.lower():\n",
    "            return \"\"\"- Finding: 這是一個關於機器學習的重要概念\n",
    "- Source: 學術文獻\n",
    "- Relevance: 直接回答用戶問題\n",
    "\n",
    "- Finding: RAG 技術提高了回答準確性\n",
    "- Source: 最新研究\n",
    "- Relevance: 與查詢高度相關\"\"\"\n",
    "\n",
    "        elif \"outline\" in user_content.lower() or \"plan\" in user_content.lower():\n",
    "            return \"\"\"1. 基本概念介紹：定義和背景\n",
    "2. 技術原理：詳細解釋工作機制\n",
    "3. 實際應用：案例分析和使用場景\n",
    "4. 總結建議：關鍵要點和最佳實踐\"\"\"\n",
    "\n",
    "        elif \"write\" in user_content.lower() or \"comprehensive\" in user_content.lower():\n",
    "            return \"\"\"基於研究結果，我來詳細回答您的問題。\n",
    "\n",
    "## 基本概念介紹\n",
    "這個主題涉及多個重要概念，需要從基礎開始理解。\n",
    "\n",
    "## 技術原理\n",
    "核心機制包括幾個關鍵步驟，每個步驟都有其特定作用。\n",
    "\n",
    "## 實際應用\n",
    "在實際場景中，這些技術被廣泛應用於解決各種問題。\n",
    "\n",
    "## 總結建議\n",
    "總結來說，掌握這些概念對於理解整個領域非常重要。\"\"\"\n",
    "\n",
    "        elif \"review\" in user_content.lower():\n",
    "            return \"\"\"Quality review:\n",
    "1. Accuracy: 內容準確，基於可靠來源 - 8/10\n",
    "2. Completeness: 涵蓋了主要方面 - 7/10\n",
    "3. Clarity: 結構清晰，易於理解 - 8/10\n",
    "4. Citations: 引用適當 - 7/10\n",
    "\n",
    "Overall score: 8/10 - Approve for final output. 文章品質良好，建議發布。\"\"\"\n",
    "\n",
    "        return \"Mock response generated for testing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Smoke Test\n",
    "def run_smoke_test():\n",
    "    \"\"\"Test the orchestrator with a simple query\"\"\"\n",
    "    print(\"=== 四角色協調器煙霧測試 ===\")\n",
    "\n",
    "    # Use mock LLM for testing\n",
    "    mock_llm = MockLLMAdapter()\n",
    "\n",
    "    # Initialize orchestrator\n",
    "    orchestrator = Orchestrator(\n",
    "        llm_adapter=mock_llm,\n",
    "        rag_retriever=None,  # No RAG for smoke test\n",
    "        max_iterations=2,\n",
    "        timeout=120,\n",
    "    )\n",
    "\n",
    "    # Test query\n",
    "    test_query = \"什麼是 RAG（檢索增強生成）技術？\"\n",
    "\n",
    "    print(f\"測試查詢: {test_query}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Execute workflow\n",
    "    result = orchestrator.execute_workflow(test_query)\n",
    "\n",
    "    # Display results\n",
    "    print(f\"✅ 完成狀態: {'成功' if result['final_output'] else '失敗'}\")\n",
    "    print(f\"📊 統計數據:\")\n",
    "    print(f\"  - 研究結果: {result['research_count']} 條\")\n",
    "    print(f\"  - 規劃章節: {result['plan_sections']} 個\")\n",
    "    print(f\"  - 迭代次數: {result['iterations']}\")\n",
    "    print(f\"  - 執行時間: {result['duration']:.2f} 秒\")\n",
    "    print(f\"  - 錯誤數量: {len(result['errors'])}\")\n",
    "\n",
    "    if result[\"errors\"]:\n",
    "        print(\"⚠️  錯誤詳情:\")\n",
    "        for error in result[\"errors\"]:\n",
    "            print(f\"  - {error['agent']}: {error['error'][:100]}...\")\n",
    "\n",
    "    print(f\"\\n📝 最終輸出:\")\n",
    "    print(\n",
    "        result[\"final_output\"][:300] + \"...\"\n",
    "        if len(result[\"final_output\"]) > 300\n",
    "        else result[\"final_output\"]\n",
    "    )\n",
    "\n",
    "    print(f\"\\n💭 審核反饋:\")\n",
    "    for i, feedback in enumerate(result[\"review_feedback\"]):\n",
    "        print(f\"審核 {i+1}: {feedback['content'][:150]}...\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run the smoke test\n",
    "smoke_result = run_smoke_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c59f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Error Handling & Circuit Breaker Patterns\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Simple circuit breaker for agent failure handling\"\"\"\n",
    "\n",
    "    def __init__(self, failure_threshold=3, timeout=60):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout\n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "\n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Execute function with circuit breaker protection\"\"\"\n",
    "        if self.state == \"OPEN\":\n",
    "            if time.time() - self.last_failure_time > self.timeout:\n",
    "                self.state = \"HALF_OPEN\"\n",
    "            else:\n",
    "                raise Exception(\"Circuit breaker is OPEN\")\n",
    "\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            if self.state == \"HALF_OPEN\":\n",
    "                self.state = \"CLOSED\"\n",
    "                self.failure_count = 0\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.failure_count += 1\n",
    "            self.last_failure_time = time.time()\n",
    "\n",
    "            if self.failure_count >= self.failure_threshold:\n",
    "                self.state = \"OPEN\"\n",
    "\n",
    "            raise e\n",
    "\n",
    "\n",
    "# Usage example\n",
    "def test_circuit_breaker():\n",
    "    \"\"\"Test circuit breaker functionality\"\"\"\n",
    "    print(\"=== 斷路器測試 ===\")\n",
    "\n",
    "    breaker = CircuitBreaker(failure_threshold=2, timeout=5)\n",
    "\n",
    "    def failing_function():\n",
    "        raise Exception(\"模擬失敗\")\n",
    "\n",
    "    def working_function():\n",
    "        return \"成功執行\"\n",
    "\n",
    "    # Test failures\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            result = breaker.call(failing_function)\n",
    "        except Exception as e:\n",
    "            print(f\"嘗試 {i+1}: {e} (狀態: {breaker.state})\")\n",
    "\n",
    "    # Test recovery after timeout\n",
    "    time.sleep(6)  # Wait for timeout\n",
    "    try:\n",
    "        result = breaker.call(working_function)\n",
    "        print(f\"恢復後: {result} (狀態: {breaker.state})\")\n",
    "    except Exception as e:\n",
    "        print(f\"恢復失敗: {e}\")\n",
    "\n",
    "\n",
    "test_circuit_breaker()\n",
    "\n",
    "print(\"\\n🎯 關鍵參數說明:\")\n",
    "print(\"- max_iterations: 最大協作輪數 (預設 3)\")\n",
    "print(\"- timeout: 總時間限制秒數 (預設 300)\")\n",
    "print(\"- max_retries: 每個代理最大重試次數 (預設 2)\")\n",
    "print(\"- temperature: 各角色創造性設定 (研究員 0.3, 寫作者 0.7)\")\n",
    "\n",
    "print(\"\\n📋 使用時機:\")\n",
    "print(\"- 需要多步驟推理和協作的複雜任務\")\n",
    "print(\"- 要求高品質輸出且有驗證機制的場景\")\n",
    "print(\"- 整合研究、規劃、寫作、審核的完整工作流\")\n",
    "print(\"- 需要容錯和重試機制的生產環境\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
