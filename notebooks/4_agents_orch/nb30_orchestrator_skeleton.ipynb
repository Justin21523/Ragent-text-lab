{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (è¤‡è£½åˆ°æ¯æœ¬ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Dependencies & Imports\n",
    "import json, time, asyncio, traceback\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from enum import Enum\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Blackboard State Management\n",
    "class Blackboard(dict):\n",
    "    \"\"\"\n",
    "    Shared state management for multi-agent collaboration.\n",
    "    Stores research results, plans, drafts, and review feedback.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.update(\n",
    "            {\n",
    "                \"query\": \"\",\n",
    "                \"research_results\": [],\n",
    "                \"plan\": [],\n",
    "                \"draft\": \"\",\n",
    "                \"review_feedback\": [],\n",
    "                \"final_output\": \"\",\n",
    "                \"metadata\": {\"start_time\": time.time(), \"iterations\": 0, \"errors\": []},\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def log_error(self, agent: str, error: str):\n",
    "        \"\"\"Log errors for debugging\"\"\"\n",
    "        self[\"metadata\"][\"errors\"].append(\n",
    "            {\"agent\": agent, \"error\": error, \"timestamp\": time.time()}\n",
    "        )\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        \"\"\"Get formatted context for agents\"\"\"\n",
    "        context = f\"Query: {self['query']}\\n\"\n",
    "        if self[\"research_results\"]:\n",
    "            context += f\"Research: {len(self['research_results'])} findings\\n\"\n",
    "        if self[\"plan\"]:\n",
    "            context += f\"Plan: {len(self['plan'])} sections\\n\"\n",
    "        if self[\"draft\"]:\n",
    "            context += f\"Draft: {len(self['draft'])} chars\\n\"\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d389c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Agent Role Definitions\n",
    "class AgentRole(Enum):\n",
    "    RESEARCHER = \"researcher\"\n",
    "    PLANNER = \"planner\"\n",
    "    WRITER = \"writer\"\n",
    "    REVIEWER = \"reviewer\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"Configuration for each agent role\"\"\"\n",
    "\n",
    "    max_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    timeout: int = 60\n",
    "    max_retries: int = 2\n",
    "\n",
    "\n",
    "# Default configs for each role\n",
    "AGENT_CONFIGS = {\n",
    "    AgentRole.RESEARCHER: AgentConfig(max_tokens=1024, temperature=0.3),\n",
    "    AgentRole.PLANNER: AgentConfig(max_tokens=512, temperature=0.5),\n",
    "    AgentRole.WRITER: AgentConfig(max_tokens=2048, temperature=0.7),\n",
    "    AgentRole.REVIEWER: AgentConfig(max_tokens=512, temperature=0.2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f130764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Base Agent Class\n",
    "class BaseAgent:\n",
    "    \"\"\"Base class for all agents with common functionality\"\"\"\n",
    "\n",
    "    def __init__(self, role: AgentRole, llm_adapter, config: AgentConfig = None):\n",
    "        self.role = role\n",
    "        self.llm = llm_adapter\n",
    "        self.config = config or AGENT_CONFIGS[role]\n",
    "        self.logger = logging.getLogger(f\"Agent.{role.value}\")\n",
    "\n",
    "    def _create_messages(self, system_prompt: str, user_prompt: str) -> List[Dict]:\n",
    "        \"\"\"Create messages format for LLM\"\"\"\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "\n",
    "    def _call_llm(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"Safe LLM call with error handling\"\"\"\n",
    "        try:\n",
    "            response = self.llm.generate(\n",
    "                messages=messages,\n",
    "                max_new_tokens=self.config.max_tokens,\n",
    "                temperature=self.config.temperature,\n",
    "            )\n",
    "            # Extract only the assistant's response\n",
    "            if \"assistant:\" in response:\n",
    "                return response.split(\"assistant:\")[-1].strip()\n",
    "            return response.strip()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"LLM call failed: {e}\")\n",
    "            return f\"[ERROR] {str(e)}\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Execute agent's task - to be overridden by subclasses\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Individual Agent Implementations\n",
    "class ResearcherAgent(BaseAgent):\n",
    "    \"\"\"Researcher: Gathers information using RAG and web search\"\"\"\n",
    "\n",
    "    def __init__(self, llm_adapter, rag_retriever=None):\n",
    "        super().__init__(AgentRole.RESEARCHER, llm_adapter)\n",
    "        self.rag = rag_retriever\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Research the query and populate research_results\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "\n",
    "        system_prompt = \"\"\"You are a research assistant. Your job is to gather relevant information and provide key findings with citations where possible.\n",
    "Focus on factual information and cite sources. Keep each finding concise but informative.\"\"\"\n",
    "\n",
    "        # Use RAG if available\n",
    "        context = \"\"\n",
    "        if self.rag:\n",
    "            try:\n",
    "                # Simplified RAG call (assumes retrieve method exists)\n",
    "                rag_results = self.rag.search(query, k=5)\n",
    "                context = \"\\n\".join(\n",
    "                    [f\"[{i+1}] {item[0]}\" for i, item in enumerate(rag_results)]\n",
    "                )\n",
    "                context = f\"Available knowledge:\\n{context}\\n\\n\"\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"RAG search failed: {e}\")\n",
    "\n",
    "        user_prompt = f\"\"\"{context}Research query: {query}\n",
    "\n",
    "Provide 3-5 key research findings. Format each as:\n",
    "- Finding: [brief description]\n",
    "- Source: [if available]\n",
    "- Relevance: [why important for this query]\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            blackboard[\"research_results\"].append(\n",
    "                {\"agent\": \"researcher\", \"content\": response, \"timestamp\": time.time()}\n",
    "            )\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"researcher\", response)\n",
    "            return False\n",
    "\n",
    "\n",
    "class PlannerAgent(BaseAgent):\n",
    "    \"\"\"Planner: Creates structured outline based on research\"\"\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Create a structured plan based on research results\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "        research = blackboard[\"research_results\"]\n",
    "\n",
    "        system_prompt = \"\"\"You are a planning assistant. Create a clear, structured outline for addressing the user's query based on research findings.\n",
    "Focus on logical flow and completeness. Keep each section concise but comprehensive.\"\"\"\n",
    "\n",
    "        research_summary = \"\\n\".join(\n",
    "            [\n",
    "                f\"Research {i+1}: {r['content'][:200]}...\"\n",
    "                for i, r in enumerate(research[-3:])  # Last 3 research results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "Available research:\n",
    "{research_summary}\n",
    "\n",
    "Create a structured outline with 3-5 main sections. Format as:\n",
    "1. Section Title: Brief description\n",
    "2. Section Title: Brief description\n",
    "...\n",
    "\n",
    "Each section should be actionable and directly address the query.\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            # Parse plan into sections\n",
    "            sections = []\n",
    "            for line in response.split(\"\\n\"):\n",
    "                if line.strip() and (\n",
    "                    line.strip()[0].isdigit() or line.strip().startswith(\"-\")\n",
    "                ):\n",
    "                    sections.append(line.strip())\n",
    "\n",
    "            blackboard[\"plan\"] = sections\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"planner\", response)\n",
    "            return False\n",
    "\n",
    "\n",
    "class WriterAgent(BaseAgent):\n",
    "    \"\"\"Writer: Produces content based on plan and research\"\"\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Write content following the plan and incorporating research\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "        plan = blackboard[\"plan\"]\n",
    "        research = blackboard[\"research_results\"]\n",
    "\n",
    "        system_prompt = \"\"\"You are a skilled writer. Create comprehensive, well-structured content that follows the provided outline and incorporates research findings.\n",
    "Write in Traditional Chinese with clear explanations. Include citations where appropriate.\"\"\"\n",
    "\n",
    "        plan_text = \"\\n\".join(plan)\n",
    "        research_text = \"\\n\\n\".join(\n",
    "            [r[\"content\"] for r in research[-2:]]\n",
    "        )  # Last 2 research items\n",
    "\n",
    "        user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "Outline to follow:\n",
    "{plan_text}\n",
    "\n",
    "Research to incorporate:\n",
    "{research_text}\n",
    "\n",
    "Write a comprehensive response (300-800 words) that:\n",
    "1. Directly answers the query\n",
    "2. Follows the outline structure\n",
    "3. Incorporates research findings with citations\n",
    "4. Uses Traditional Chinese\n",
    "5. Is clear and well-organized\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            blackboard[\"draft\"] = response\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"writer\", response)\n",
    "            return False\n",
    "\n",
    "\n",
    "class ReviewerAgent(BaseAgent):\n",
    "    \"\"\"Reviewer: Evaluates content quality and provides feedback\"\"\"\n",
    "\n",
    "    def execute(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Review the draft and provide feedback\"\"\"\n",
    "        query = blackboard[\"query\"]\n",
    "        draft = blackboard[\"draft\"]\n",
    "\n",
    "        if not draft:\n",
    "            blackboard.log_error(\"reviewer\", \"No draft available to review\")\n",
    "            return False\n",
    "\n",
    "        system_prompt = \"\"\"You are a quality reviewer. Evaluate content for accuracy, completeness, clarity, and alignment with the original query.\n",
    "Provide constructive feedback and suggest improvements. Be specific and actionable.\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Original query: {query}\n",
    "\n",
    "Draft to review:\n",
    "{draft}\n",
    "\n",
    "Evaluate this draft on:\n",
    "1. Accuracy - Are the facts correct?\n",
    "2. Completeness - Does it fully address the query?\n",
    "3. Clarity - Is it well-organized and easy to understand?\n",
    "4. Citations - Are sources properly referenced?\n",
    "\n",
    "Provide specific feedback and a quality score (1-10). If score â‰¥7, approve for final output.\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_prompt)\n",
    "        response = self._call_llm(messages)\n",
    "\n",
    "        if not response.startswith(\"[ERROR]\"):\n",
    "            blackboard[\"review_feedback\"].append(\n",
    "                {\"content\": response, \"timestamp\": time.time()}\n",
    "            )\n",
    "\n",
    "            # Simple approval logic - look for score â‰¥7 or positive keywords\n",
    "            is_approved = any(\n",
    "                keyword in response.lower()\n",
    "                for keyword in [\n",
    "                    \"score: 7\",\n",
    "                    \"score: 8\",\n",
    "                    \"score: 9\",\n",
    "                    \"score: 10\",\n",
    "                    \"approve\",\n",
    "                    \"good quality\",\n",
    "                    \"well done\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if is_approved:\n",
    "                blackboard[\"final_output\"] = draft\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            blackboard.log_error(\"reviewer\", response)\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288154dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Core Orchestrator Class\n",
    "class Orchestrator:\n",
    "    \"\"\"\n",
    "    Main orchestrator that coordinates the 4-agent workflow.\n",
    "    Manages execution order, retries, and error handling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm_adapter, rag_retriever=None, max_iterations=3, timeout=300):\n",
    "        self.llm = llm_adapter\n",
    "        self.rag = rag_retriever\n",
    "        self.max_iterations = max_iterations\n",
    "        self.timeout = timeout\n",
    "\n",
    "        # Initialize agents\n",
    "        self.agents = {\n",
    "            AgentRole.RESEARCHER: ResearcherAgent(llm_adapter, rag_retriever),\n",
    "            AgentRole.PLANNER: PlannerAgent(llm_adapter),\n",
    "            AgentRole.WRITER: WriterAgent(llm_adapter),\n",
    "            AgentRole.REVIEWER: ReviewerAgent(llm_adapter),\n",
    "        }\n",
    "\n",
    "        self.logger = logging.getLogger(\"Orchestrator\")\n",
    "\n",
    "    def execute_workflow(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute the complete 4-agent workflow.\n",
    "        Returns final result with metadata.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        blackboard = Blackboard()\n",
    "        blackboard[\"query\"] = query\n",
    "\n",
    "        self.logger.info(f\"Starting workflow for query: {query[:100]}...\")\n",
    "\n",
    "        try:\n",
    "            for iteration in range(self.max_iterations):\n",
    "                blackboard[\"metadata\"][\"iterations\"] = iteration + 1\n",
    "\n",
    "                # Check timeout\n",
    "                if time.time() - start_time > self.timeout:\n",
    "                    self.logger.error(\"Workflow timeout reached\")\n",
    "                    break\n",
    "\n",
    "                # Execute agent sequence\n",
    "                workflow_success = self._execute_agent_sequence(blackboard)\n",
    "\n",
    "                if workflow_success and blackboard[\"final_output\"]:\n",
    "                    self.logger.info(\n",
    "                        f\"Workflow completed successfully in {iteration + 1} iterations\"\n",
    "                    )\n",
    "                    break\n",
    "                elif iteration == self.max_iterations - 1:\n",
    "                    self.logger.warning(\"Max iterations reached without approval\")\n",
    "                    # Use draft as final output if available\n",
    "                    if blackboard[\"draft\"]:\n",
    "                        blackboard[\"final_output\"] = blackboard[\"draft\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Workflow failed: {e}\")\n",
    "            blackboard.log_error(\"orchestrator\", str(e))\n",
    "\n",
    "        # Compile final result\n",
    "        result = {\n",
    "            \"query\": query,\n",
    "            \"final_output\": blackboard.get(\"final_output\", \"æœªèƒ½å®Œæˆä»»å‹™\"),\n",
    "            \"research_count\": len(blackboard[\"research_results\"]),\n",
    "            \"plan_sections\": len(blackboard[\"plan\"]),\n",
    "            \"review_feedback\": blackboard[\"review_feedback\"],\n",
    "            \"iterations\": blackboard[\"metadata\"][\"iterations\"],\n",
    "            \"duration\": time.time() - start_time,\n",
    "            \"errors\": blackboard[\"metadata\"][\"errors\"],\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _execute_agent_sequence(self, blackboard: Blackboard) -> bool:\n",
    "        \"\"\"Execute the standard agent sequence: Research â†’ Plan â†’ Write â†’ Review\"\"\"\n",
    "\n",
    "        sequence = [\n",
    "            (AgentRole.RESEARCHER, \"ç ”ç©¶éšæ®µ\"),\n",
    "            (AgentRole.PLANNER, \"è¦åŠƒéšæ®µ\"),\n",
    "            (AgentRole.WRITER, \"å¯«ä½œéšæ®µ\"),\n",
    "            (AgentRole.REVIEWER, \"å¯©æ ¸éšæ®µ\"),\n",
    "        ]\n",
    "\n",
    "        for role, stage_name in sequence:\n",
    "            self.logger.info(f\"Executing {stage_name} ({role.value})\")\n",
    "\n",
    "            agent = self.agents[role]\n",
    "            success = False\n",
    "\n",
    "            # Retry logic for each agent\n",
    "            for attempt in range(agent.config.max_retries + 1):\n",
    "                try:\n",
    "                    success = agent.execute(blackboard)\n",
    "                    if success:\n",
    "                        break\n",
    "                    else:\n",
    "                        self.logger.warning(\n",
    "                            f\"{role.value} attempt {attempt + 1} failed\"\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"{role.value} attempt {attempt + 1} error: {e}\")\n",
    "                    blackboard.log_error(role.value, str(e))\n",
    "\n",
    "            if not success:\n",
    "                self.logger.error(f\"{stage_name} failed after all retries\")\n",
    "                return False\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4da88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Integration Setup (Mock LLM for testing)\n",
    "class MockLLMAdapter:\n",
    "    \"\"\"Mock LLM adapter for testing when real models aren't available\"\"\"\n",
    "\n",
    "    def generate(self, messages, max_new_tokens=256, temperature=0.7):\n",
    "        # Extract the last user message for context\n",
    "        user_content = \"\"\n",
    "        for msg in reversed(messages):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                user_content = msg[\"content\"]\n",
    "                break\n",
    "\n",
    "        # Generate mock responses based on content\n",
    "        if \"research\" in user_content.lower():\n",
    "            return \"\"\"- Finding: é€™æ˜¯ä¸€å€‹é—œæ–¼æ©Ÿå™¨å­¸ç¿’çš„é‡è¦æ¦‚å¿µ\n",
    "- Source: å­¸è¡“æ–‡ç»\n",
    "- Relevance: ç›´æ¥å›ç­”ç”¨æˆ¶å•é¡Œ\n",
    "\n",
    "- Finding: RAG æŠ€è¡“æé«˜äº†å›ç­”æº–ç¢ºæ€§\n",
    "- Source: æœ€æ–°ç ”ç©¶\n",
    "- Relevance: èˆ‡æŸ¥è©¢é«˜åº¦ç›¸é—œ\"\"\"\n",
    "\n",
    "        elif \"outline\" in user_content.lower() or \"plan\" in user_content.lower():\n",
    "            return \"\"\"1. åŸºæœ¬æ¦‚å¿µä»‹ç´¹ï¼šå®šç¾©å’ŒèƒŒæ™¯\n",
    "2. æŠ€è¡“åŸç†ï¼šè©³ç´°è§£é‡‹å·¥ä½œæ©Ÿåˆ¶\n",
    "3. å¯¦éš›æ‡‰ç”¨ï¼šæ¡ˆä¾‹åˆ†æå’Œä½¿ç”¨å ´æ™¯\n",
    "4. ç¸½çµå»ºè­°ï¼šé—œéµè¦é»å’Œæœ€ä½³å¯¦è¸\"\"\"\n",
    "\n",
    "        elif \"write\" in user_content.lower() or \"comprehensive\" in user_content.lower():\n",
    "            return \"\"\"åŸºæ–¼ç ”ç©¶çµæœï¼Œæˆ‘ä¾†è©³ç´°å›ç­”æ‚¨çš„å•é¡Œã€‚\n",
    "\n",
    "## åŸºæœ¬æ¦‚å¿µä»‹ç´¹\n",
    "é€™å€‹ä¸»é¡Œæ¶‰åŠå¤šå€‹é‡è¦æ¦‚å¿µï¼Œéœ€è¦å¾åŸºç¤é–‹å§‹ç†è§£ã€‚\n",
    "\n",
    "## æŠ€è¡“åŸç†\n",
    "æ ¸å¿ƒæ©Ÿåˆ¶åŒ…æ‹¬å¹¾å€‹é—œéµæ­¥é©Ÿï¼Œæ¯å€‹æ­¥é©Ÿéƒ½æœ‰å…¶ç‰¹å®šä½œç”¨ã€‚\n",
    "\n",
    "## å¯¦éš›æ‡‰ç”¨\n",
    "åœ¨å¯¦éš›å ´æ™¯ä¸­ï¼Œé€™äº›æŠ€è¡“è¢«å»£æ³›æ‡‰ç”¨æ–¼è§£æ±ºå„ç¨®å•é¡Œã€‚\n",
    "\n",
    "## ç¸½çµå»ºè­°\n",
    "ç¸½çµä¾†èªªï¼ŒæŒæ¡é€™äº›æ¦‚å¿µå°æ–¼ç†è§£æ•´å€‹é ˜åŸŸéå¸¸é‡è¦ã€‚\"\"\"\n",
    "\n",
    "        elif \"review\" in user_content.lower():\n",
    "            return \"\"\"Quality review:\n",
    "1. Accuracy: å…§å®¹æº–ç¢ºï¼ŒåŸºæ–¼å¯é ä¾†æº - 8/10\n",
    "2. Completeness: æ¶µè“‹äº†ä¸»è¦æ–¹é¢ - 7/10\n",
    "3. Clarity: çµæ§‹æ¸…æ™°ï¼Œæ˜“æ–¼ç†è§£ - 8/10\n",
    "4. Citations: å¼•ç”¨é©ç•¶ - 7/10\n",
    "\n",
    "Overall score: 8/10 - Approve for final output. æ–‡ç« å“è³ªè‰¯å¥½ï¼Œå»ºè­°ç™¼å¸ƒã€‚\"\"\"\n",
    "\n",
    "        return \"Mock response generated for testing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Smoke Test\n",
    "def run_smoke_test():\n",
    "    \"\"\"Test the orchestrator with a simple query\"\"\"\n",
    "    print(\"=== å››è§’è‰²å”èª¿å™¨ç…™éœ§æ¸¬è©¦ ===\")\n",
    "\n",
    "    # Use mock LLM for testing\n",
    "    mock_llm = MockLLMAdapter()\n",
    "\n",
    "    # Initialize orchestrator\n",
    "    orchestrator = Orchestrator(\n",
    "        llm_adapter=mock_llm,\n",
    "        rag_retriever=None,  # No RAG for smoke test\n",
    "        max_iterations=2,\n",
    "        timeout=120,\n",
    "    )\n",
    "\n",
    "    # Test query\n",
    "    test_query = \"ä»€éº¼æ˜¯ RAGï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰æŠ€è¡“ï¼Ÿ\"\n",
    "\n",
    "    print(f\"æ¸¬è©¦æŸ¥è©¢: {test_query}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Execute workflow\n",
    "    result = orchestrator.execute_workflow(test_query)\n",
    "\n",
    "    # Display results\n",
    "    print(f\"âœ… å®Œæˆç‹€æ…‹: {'æˆåŠŸ' if result['final_output'] else 'å¤±æ•—'}\")\n",
    "    print(f\"ğŸ“Š çµ±è¨ˆæ•¸æ“š:\")\n",
    "    print(f\"  - ç ”ç©¶çµæœ: {result['research_count']} æ¢\")\n",
    "    print(f\"  - è¦åŠƒç« ç¯€: {result['plan_sections']} å€‹\")\n",
    "    print(f\"  - è¿­ä»£æ¬¡æ•¸: {result['iterations']}\")\n",
    "    print(f\"  - åŸ·è¡Œæ™‚é–“: {result['duration']:.2f} ç§’\")\n",
    "    print(f\"  - éŒ¯èª¤æ•¸é‡: {len(result['errors'])}\")\n",
    "\n",
    "    if result[\"errors\"]:\n",
    "        print(\"âš ï¸  éŒ¯èª¤è©³æƒ…:\")\n",
    "        for error in result[\"errors\"]:\n",
    "            print(f\"  - {error['agent']}: {error['error'][:100]}...\")\n",
    "\n",
    "    print(f\"\\nğŸ“ æœ€çµ‚è¼¸å‡º:\")\n",
    "    print(\n",
    "        result[\"final_output\"][:300] + \"...\"\n",
    "        if len(result[\"final_output\"]) > 300\n",
    "        else result[\"final_output\"]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nğŸ’­ å¯©æ ¸åé¥‹:\")\n",
    "    for i, feedback in enumerate(result[\"review_feedback\"]):\n",
    "        print(f\"å¯©æ ¸ {i+1}: {feedback['content'][:150]}...\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run the smoke test\n",
    "smoke_result = run_smoke_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c59f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Error Handling & Circuit Breaker Patterns\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Simple circuit breaker for agent failure handling\"\"\"\n",
    "\n",
    "    def __init__(self, failure_threshold=3, timeout=60):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout\n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "\n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Execute function with circuit breaker protection\"\"\"\n",
    "        if self.state == \"OPEN\":\n",
    "            if time.time() - self.last_failure_time > self.timeout:\n",
    "                self.state = \"HALF_OPEN\"\n",
    "            else:\n",
    "                raise Exception(\"Circuit breaker is OPEN\")\n",
    "\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            if self.state == \"HALF_OPEN\":\n",
    "                self.state = \"CLOSED\"\n",
    "                self.failure_count = 0\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.failure_count += 1\n",
    "            self.last_failure_time = time.time()\n",
    "\n",
    "            if self.failure_count >= self.failure_threshold:\n",
    "                self.state = \"OPEN\"\n",
    "\n",
    "            raise e\n",
    "\n",
    "\n",
    "# Usage example\n",
    "def test_circuit_breaker():\n",
    "    \"\"\"Test circuit breaker functionality\"\"\"\n",
    "    print(\"=== æ–·è·¯å™¨æ¸¬è©¦ ===\")\n",
    "\n",
    "    breaker = CircuitBreaker(failure_threshold=2, timeout=5)\n",
    "\n",
    "    def failing_function():\n",
    "        raise Exception(\"æ¨¡æ“¬å¤±æ•—\")\n",
    "\n",
    "    def working_function():\n",
    "        return \"æˆåŠŸåŸ·è¡Œ\"\n",
    "\n",
    "    # Test failures\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            result = breaker.call(failing_function)\n",
    "        except Exception as e:\n",
    "            print(f\"å˜—è©¦ {i+1}: {e} (ç‹€æ…‹: {breaker.state})\")\n",
    "\n",
    "    # Test recovery after timeout\n",
    "    time.sleep(6)  # Wait for timeout\n",
    "    try:\n",
    "        result = breaker.call(working_function)\n",
    "        print(f\"æ¢å¾©å¾Œ: {result} (ç‹€æ…‹: {breaker.state})\")\n",
    "    except Exception as e:\n",
    "        print(f\"æ¢å¾©å¤±æ•—: {e}\")\n",
    "\n",
    "\n",
    "test_circuit_breaker()\n",
    "\n",
    "print(\"\\nğŸ¯ é—œéµåƒæ•¸èªªæ˜:\")\n",
    "print(\"- max_iterations: æœ€å¤§å”ä½œè¼ªæ•¸ (é è¨­ 3)\")\n",
    "print(\"- timeout: ç¸½æ™‚é–“é™åˆ¶ç§’æ•¸ (é è¨­ 300)\")\n",
    "print(\"- max_retries: æ¯å€‹ä»£ç†æœ€å¤§é‡è©¦æ¬¡æ•¸ (é è¨­ 2)\")\n",
    "print(\"- temperature: å„è§’è‰²å‰µé€ æ€§è¨­å®š (ç ”ç©¶å“¡ 0.3, å¯«ä½œè€… 0.7)\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ä½¿ç”¨æ™‚æ©Ÿ:\")\n",
    "print(\"- éœ€è¦å¤šæ­¥é©Ÿæ¨ç†å’Œå”ä½œçš„è¤‡é›œä»»å‹™\")\n",
    "print(\"- è¦æ±‚é«˜å“è³ªè¼¸å‡ºä¸”æœ‰é©—è­‰æ©Ÿåˆ¶çš„å ´æ™¯\")\n",
    "print(\"- æ•´åˆç ”ç©¶ã€è¦åŠƒã€å¯«ä½œã€å¯©æ ¸çš„å®Œæ•´å·¥ä½œæµ\")\n",
    "print(\"- éœ€è¦å®¹éŒ¯å’Œé‡è©¦æ©Ÿåˆ¶çš„ç”Ÿç”¢ç’°å¢ƒ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
