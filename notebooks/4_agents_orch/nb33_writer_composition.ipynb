{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62674fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer Composition Agent Implementation\n",
    "# Stage 4 - Multi-Agent Orchestrator\n",
    "# File: notebooks/4_agents_orch/nb33_writer_composition.ipynb\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (è¤‡è£½åˆ°æ¯æœ¬ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89837849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Dependencies and Imports\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "\n",
    "# LLM Adapter (from previous notebooks)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LLMAdapter:\n",
    "    def __init__(self, model_id: str, device_map=\"auto\", **kwargs):\n",
    "        self.model_id = model_id\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=device_map,\n",
    "            torch_dtype=torch.float16,\n",
    "            load_in_4bit=True,  # Low VRAM\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def generate(\n",
    "        self, messages: List[Dict], max_new_tokens=512, temperature=0.7, **kwargs\n",
    "    ):\n",
    "        # Simple chat template\n",
    "        prompt = \"\"\n",
    "        for msg in messages:\n",
    "            role = msg.get(\"role\", \"user\")\n",
    "            content = msg.get(\"content\", \"\")\n",
    "            if role == \"system\":\n",
    "                prompt += f\"System: {content}\\n\"\n",
    "            elif role == \"user\":\n",
    "                prompt += f\"User: {content}\\n\"\n",
    "            elif role == \"assistant\":\n",
    "                prompt += f\"Assistant: {content}\\n\"\n",
    "        prompt += \"Assistant: \"\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, return_tensors=\"pt\", truncation=True, max_length=3072\n",
    "        )\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                **kwargs,\n",
    "            )\n",
    "\n",
    "        response = self.tokenizer.decode(\n",
    "            outputs[0][inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True\n",
    "        )\n",
    "        return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e781543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Writer Agent Core Class\n",
    "@dataclass\n",
    "class WritingSection:\n",
    "    \"\"\"Represents a section to be written\"\"\"\n",
    "\n",
    "    title: str\n",
    "    outline_points: List[str]\n",
    "    target_length: int = 300  # Target word count\n",
    "    context: str = \"\"  # Background context\n",
    "    citations: List[str] = field(default_factory=list)\n",
    "    content: str = \"\"  # Generated content\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WritingProject:\n",
    "    \"\"\"Complete writing project structure\"\"\"\n",
    "\n",
    "    title: str\n",
    "    sections: List[WritingSection]\n",
    "    research_context: str = \"\"\n",
    "    style_guide: Dict = field(default_factory=dict)\n",
    "    references: List[str] = field(default_factory=list)\n",
    "\n",
    "\n",
    "class WriterAgent:\n",
    "    \"\"\"Writer agent for content composition\"\"\"\n",
    "\n",
    "    def __init__(self, llm_adapter: LLMAdapter, style_config: Dict = None):\n",
    "        self.llm = llm_adapter\n",
    "        self.style_config = style_config or {}\n",
    "        self.writing_history = []\n",
    "\n",
    "    def load_style_dictionary(self, style_path: str) -> Dict:\n",
    "        \"\"\"Load style dictionary from YAML\"\"\"\n",
    "        try:\n",
    "            with open(style_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return yaml.safe_load(f)\n",
    "        except FileNotFoundError:\n",
    "            return self._get_default_style()\n",
    "\n",
    "    def _get_default_style(self) -> Dict:\n",
    "        \"\"\"Default Chinese writing style\"\"\"\n",
    "        return {\n",
    "            \"tone\": \"formal-neutral\",\n",
    "            \"format\": {\n",
    "                \"bullets\": True,\n",
    "                \"numbered_steps\": True,\n",
    "                \"citations\": \"brackets\",\n",
    "            },\n",
    "            \"glossary\": [\n",
    "                {\"src\": \"RAG\", \"tgt\": \"æª¢ç´¢å¢å¼·ç”Ÿæˆ\"},\n",
    "                {\"src\": \"LLM\", \"tgt\": \"å¤§å‹èªè¨€æ¨¡å‹\"},\n",
    "                {\"src\": \"Agent\", \"tgt\": \"æ™ºèƒ½ä»£ç†\"},\n",
    "            ],\n",
    "            \"avoid_phrases\": [\"ä»¥ä¸‹æ˜¯\", \"ä½œç‚ºä¸€å€‹AI\"],\n",
    "            \"style_rules\": [\n",
    "                \"ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«\",\n",
    "                \"ä¿æŒæ®µè½ç°¡æ½”ï¼Œæ¯æ®µä¸è¶…é150å­—\",\n",
    "                \"é©ç•¶ä½¿ç”¨åˆ—é»å’Œç·¨è™Ÿ\",\n",
    "                \"å¼•ç”¨æ ¼å¼ä½¿ç”¨ [1], [2] æ–¹å¼\",\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    def _build_style_prompt(self, style_dict: Dict) -> str:\n",
    "        \"\"\"Convert style dictionary to prompt instructions\"\"\"\n",
    "        tone = style_dict.get(\"tone\", \"neutral\")\n",
    "        rules = \"\\n\".join(style_dict.get(\"style_rules\", []))\n",
    "\n",
    "        glossary = \"\"\n",
    "        for term in style_dict.get(\"glossary\", []):\n",
    "            glossary += f\"- {term['src']} â†’ {term['tgt']}\\n\"\n",
    "\n",
    "        avoid = \", \".join(style_dict.get(\"avoid_phrases\", []))\n",
    "\n",
    "        return f\"\"\"\n",
    "å¯«ä½œé¢¨æ ¼æŒ‡å—ï¼š\n",
    "èªèª¿ï¼š{tone}\n",
    "å°ˆæ¥­è¡“èªå°ç…§ï¼š\n",
    "{glossary}\n",
    "é¿å…ç”¨è©ï¼š{avoid}\n",
    "å¯«ä½œè¦å‰‡ï¼š\n",
    "{rules}\n",
    "\"\"\"\n",
    "\n",
    "    def write_section(\n",
    "        self,\n",
    "        section: WritingSection,\n",
    "        project_context: str = \"\",\n",
    "        previous_sections: List[str] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Write a single section based on outline\"\"\"\n",
    "        previous_sections = previous_sections or []\n",
    "        style_prompt = self._build_style_prompt(self.style_config)\n",
    "\n",
    "        # Build context from previous sections for coherence\n",
    "        context_summary = \"\"\n",
    "        if previous_sections:\n",
    "            context_summary = (\n",
    "                f\"\\nå‰æ–‡æ‘˜è¦ï¼š\\n{' '.join(previous_sections[-2:])}\"  # Last 2 sections\n",
    "            )\n",
    "\n",
    "        system_prompt = f\"\"\"ä½ æ˜¯å°ˆæ¥­çš„ä¸­æ–‡å¯«ä½œåŠ©æ‰‹ã€‚è«‹æ ¹æ“šå¤§ç¶±è¦é»æ’°å¯«å…§å®¹ã€‚\n",
    "\n",
    "{style_prompt}\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "1. å…§å®¹å¿…é ˆåŸºæ–¼æä¾›çš„å¤§ç¶±è¦é»\n",
    "2. ä¿æŒèˆ‡å‰æ–‡çš„é‚è¼¯é€£è²«æ€§\n",
    "3. ç›®æ¨™é•·åº¦ç´„ {section.target_length} å­—\n",
    "4. å¦‚æœ‰å¼•ç”¨è³‡æ–™ï¼Œä½¿ç”¨ [1], [2] æ ¼å¼æ¨™è¨»\n",
    "5. ç›´æ¥è¼¸å‡ºå…§å®¹ï¼Œä¸è¦åŒ…å«ã€Œä»¥ä¸‹æ˜¯ã€ç­‰å¼•å°èª\n",
    "\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "å°ˆæ¡ˆèƒŒæ™¯ï¼š{project_context}\n",
    "\n",
    "ç« ç¯€æ¨™é¡Œï¼š{section.title}\n",
    "\n",
    "å¤§ç¶±è¦é»ï¼š\n",
    "{chr(10).join([f\"- {point}\" for point in section.outline_points])}\n",
    "\n",
    "{f\"åƒè€ƒè³‡æ–™ï¼š{section.context}\" if section.context else \"\"}\n",
    "\n",
    "{context_summary}\n",
    "\n",
    "è«‹æ’°å¯«æ­¤ç« ç¯€çš„å…§å®¹ï¼š\n",
    "\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "\n",
    "        content = self.llm.generate(\n",
    "            messages,\n",
    "            max_new_tokens=min(800, section.target_length * 2),  # Control length\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        section.content = content\n",
    "        return content\n",
    "\n",
    "    def write_project(self, project: WritingProject) -> str:\n",
    "        \"\"\"Write complete project with all sections\"\"\"\n",
    "        full_content = f\"# {project.title}\\n\\n\"\n",
    "        written_sections = []\n",
    "\n",
    "        for i, section in enumerate(project.sections):\n",
    "            print(f\"Writing section {i+1}/{len(project.sections)}: {section.title}\")\n",
    "\n",
    "            content = self.write_section(\n",
    "                section, project.research_context, written_sections\n",
    "            )\n",
    "\n",
    "            # Format section\n",
    "            section_text = f\"## {section.title}\\n\\n{content}\\n\\n\"\n",
    "            full_content += section_text\n",
    "            written_sections.append(content)\n",
    "\n",
    "            # Brief pause between sections\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Add references if any\n",
    "        if project.references:\n",
    "            full_content += \"## åƒè€ƒè³‡æ–™\\n\\n\"\n",
    "            for i, ref in enumerate(project.references, 1):\n",
    "                full_content += f\"[{i}] {ref}\\n\"\n",
    "\n",
    "        return full_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e09d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Style Dictionary Integration\n",
    "def create_style_config():\n",
    "    \"\"\"Create sample style configuration\"\"\"\n",
    "    return {\n",
    "        \"tone\": \"professional-friendly\",\n",
    "        \"format\": {\n",
    "            \"bullets\": True,\n",
    "            \"numbered_steps\": True,\n",
    "            \"citations\": \"brackets\",\n",
    "            \"max_paragraph_length\": 150,\n",
    "        },\n",
    "        \"glossary\": [\n",
    "            {\"src\": \"RAG\", \"tgt\": \"æª¢ç´¢å¢å¼·ç”Ÿæˆ\"},\n",
    "            {\"src\": \"Retrieval\", \"tgt\": \"æª¢ç´¢\"},\n",
    "            {\"src\": \"Embedding\", \"tgt\": \"åµŒå…¥å‘é‡\"},\n",
    "            {\"src\": \"Chunk\", \"tgt\": \"æ–‡æœ¬ç‰‡æ®µ\"},\n",
    "            {\"src\": \"LLM\", \"tgt\": \"å¤§å‹èªè¨€æ¨¡å‹\"},\n",
    "            {\"src\": \"Agent\", \"tgt\": \"æ™ºèƒ½ä»£ç†\"},\n",
    "            {\"src\": \"Orchestrator\", \"tgt\": \"å”èª¿å™¨\"},\n",
    "        ],\n",
    "        \"avoid_phrases\": [\"ä»¥ä¸‹æ˜¯\", \"ä½œç‚ºä¸€å€‹AIåŠ©æ‰‹\", \"è®“æˆ‘ä¾†ç‚ºæ‚¨\", \"ç¸½çš„ä¾†èªª\"],\n",
    "        \"style_rules\": [\n",
    "            \"ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«æ­£æ–‡\",\n",
    "            \"æŠ€è¡“è¡“èªä¿æŒä¸­è‹±æ–‡å°ç…§ä¸€è‡´æ€§\",\n",
    "            \"æ¯æ®µè½ä¸è¶…é150å­—ï¼Œä¿æŒç°¡æ½”\",\n",
    "            \"ä½¿ç”¨æ¢åˆ—å¼é‡é»æ•´ç†\",\n",
    "            \"å¼•ç”¨æ ¼å¼çµ±ä¸€ä½¿ç”¨ [æ•¸å­—] æ–¹å¼\",\n",
    "            \"ä¿æŒå®¢è§€å°ˆæ¥­èªèª¿ï¼Œé¿å…éåº¦ä¸»è§€è¡¨é”\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def save_style_config(config: Dict, path: str):\n",
    "    \"\"\"Save style configuration to YAML\"\"\"\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.dump(config, f, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "\n",
    "# Create and save sample style\n",
    "style_config = create_style_config()\n",
    "style_path = \"configs/styles/zh_general.yaml\"\n",
    "save_style_config(style_config, style_path)\n",
    "print(f\"Style config saved to: {style_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Sectional Writing Strategy\n",
    "class SectionalWriter:\n",
    "    \"\"\"Handles sectional writing with smart splitting\"\"\"\n",
    "\n",
    "    def __init__(self, writer_agent: WriterAgent, max_section_length=400):\n",
    "        self.writer = writer_agent\n",
    "        self.max_section_length = max_section_length\n",
    "\n",
    "    def split_long_outline(\n",
    "        self, title: str, outline_points: List[str], target_total_length: int = 1000\n",
    "    ) -> List[WritingSection]:\n",
    "        \"\"\"Split long outline into manageable sections\"\"\"\n",
    "        sections = []\n",
    "\n",
    "        if len(outline_points) <= 3 or target_total_length <= self.max_section_length:\n",
    "            # Single section\n",
    "            sections.append(\n",
    "                WritingSection(\n",
    "                    title=title,\n",
    "                    outline_points=outline_points,\n",
    "                    target_length=min(target_total_length, self.max_section_length),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # Split into multiple sections\n",
    "            points_per_section = max(2, len(outline_points) // 3)\n",
    "            length_per_section = target_total_length // (\n",
    "                (len(outline_points) + points_per_section - 1) // points_per_section\n",
    "            )\n",
    "\n",
    "            for i in range(0, len(outline_points), points_per_section):\n",
    "                section_points = outline_points[i : i + points_per_section]\n",
    "                section_num = i // points_per_section + 1\n",
    "\n",
    "                section_title = (\n",
    "                    f\"{title} - ç¬¬{section_num}éƒ¨åˆ†\"\n",
    "                    if len(outline_points) > 3\n",
    "                    else title\n",
    "                )\n",
    "\n",
    "                sections.append(\n",
    "                    WritingSection(\n",
    "                        title=section_title,\n",
    "                        outline_points=section_points,\n",
    "                        target_length=min(length_per_section, self.max_section_length),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return sections\n",
    "\n",
    "    def estimate_writing_time(self, sections: List[WritingSection]) -> int:\n",
    "        \"\"\"Estimate total writing time in seconds\"\"\"\n",
    "        total_length = sum(s.target_length for s in sections)\n",
    "        # Rough estimate: 1 second per 2 characters (Chinese)\n",
    "        return max(30, total_length // 2 + len(sections) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Content Cohesion and Formatting\n",
    "class ContentFormatter:\n",
    "    \"\"\"Handles content formatting and cohesion\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_cohesion(sections: List[str]) -> List[str]:\n",
    "        \"\"\"Ensure smooth transitions between sections\"\"\"\n",
    "        if len(sections) <= 1:\n",
    "            return sections\n",
    "\n",
    "        cohesive_sections = []\n",
    "        for i, section in enumerate(sections):\n",
    "            if i > 0:\n",
    "                # Add transition if needed\n",
    "                prev_ends_with = sections[i - 1].strip()[-10:]\n",
    "                curr_starts_with = section.strip()[:10:]\n",
    "\n",
    "                # Simple heuristic for adding transitions\n",
    "                if not any(\n",
    "                    word in curr_starts_with\n",
    "                    for word in [\"æ­¤å¤–\", \"å¦å¤–\", \"æ¥ä¸‹ä¾†\", \"ç„¶è€Œ\", \"å› æ­¤\"]\n",
    "                ):\n",
    "                    # Check if we need a transition\n",
    "                    section = (\n",
    "                        f\"æ­¤å¤–ï¼Œ{section}\"\n",
    "                        if not section.startswith((\"åœ¨\", \"å°æ–¼\", \"é—œæ–¼\"))\n",
    "                        else section\n",
    "                    )\n",
    "\n",
    "            cohesive_sections.append(section)\n",
    "\n",
    "        return cohesive_sections\n",
    "\n",
    "    @staticmethod\n",
    "    def format_citations(content: str, references: List[str]) -> str:\n",
    "        \"\"\"Format citations consistently\"\"\"\n",
    "        # Ensure citation numbers are in order\n",
    "        import re\n",
    "\n",
    "        # Find all citation patterns\n",
    "        citations = re.findall(r\"\\[(\\d+)\\]\", content)\n",
    "        if not citations:\n",
    "            return content\n",
    "\n",
    "        # Renumber citations sequentially\n",
    "        citation_map = {}\n",
    "        for i, cite in enumerate(sorted(set(citations), key=int), 1):\n",
    "            citation_map[cite] = str(i)\n",
    "\n",
    "        # Replace citations in content\n",
    "        formatted_content = content\n",
    "        for old_num, new_num in citation_map.items():\n",
    "            formatted_content = formatted_content.replace(\n",
    "                f\"[{old_num}]\", f\"[{new_num}]\"\n",
    "            )\n",
    "\n",
    "        return formatted_content\n",
    "\n",
    "    @staticmethod\n",
    "    def add_word_count(content: str) -> str:\n",
    "        \"\"\"Add word count information\"\"\"\n",
    "        # Chinese character count (rough approximation)\n",
    "        chinese_chars = len([c for c in content if \"\\u4e00\" <= c <= \"\\u9fff\"])\n",
    "        total_chars = len(content.replace(\" \", \"\").replace(\"\\n\", \"\"))\n",
    "\n",
    "        return f\"{content}\\n\\n---\\n*å­—æ•¸çµ±è¨ˆï¼šç´„ {chinese_chars} ä¸­æ–‡å­—ï¼Œç¸½è¨ˆ {total_chars} å­—ç¬¦*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Blackboard Integration\n",
    "class Blackboard(dict):\n",
    "    \"\"\"Simple blackboard for inter-agent communication\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.history = []\n",
    "\n",
    "    def update_state(self, key: str, value, agent: str = \"unknown\"):\n",
    "        \"\"\"Update state with tracking\"\"\"\n",
    "        self[key] = value\n",
    "        self.history.append(\n",
    "            {\"timestamp\": time.time(), \"agent\": agent, \"key\": key, \"action\": \"update\"}\n",
    "        )\n",
    "\n",
    "    def get_state(self, key: str, default=None):\n",
    "        \"\"\"Get state value\"\"\"\n",
    "        return self.get(key, default)\n",
    "\n",
    "\n",
    "def integrate_with_blackboard(\n",
    "    blackboard: Blackboard, writer: WriterAgent\n",
    ") -> WritingProject:\n",
    "    \"\"\"Create writing project from blackboard state\"\"\"\n",
    "\n",
    "    # Get research context\n",
    "    research_data = blackboard.get_state(\"research_summary\", \"\")\n",
    "\n",
    "    # Get outline from planner\n",
    "    outline_data = blackboard.get_state(\"outline\", {})\n",
    "    if not outline_data:\n",
    "        raise ValueError(\"No outline found in blackboard. Run planner first.\")\n",
    "\n",
    "    # Get style preferences\n",
    "    style_prefs = blackboard.get_state(\"style_preferences\", {})\n",
    "\n",
    "    # Create writing project\n",
    "    project = WritingProject(\n",
    "        title=outline_data.get(\"title\", \"æœªå‘½åå°ˆæ¡ˆ\"),\n",
    "        research_context=research_data,\n",
    "        references=blackboard.get_state(\"references\", []),\n",
    "    )\n",
    "\n",
    "    # Convert outline to sections\n",
    "    sections_data = outline_data.get(\"sections\", [])\n",
    "    for section_data in sections_data:\n",
    "        section = WritingSection(\n",
    "            title=section_data.get(\"title\", \"æœªå‘½åç« ç¯€\"),\n",
    "            outline_points=section_data.get(\"points\", []),\n",
    "            target_length=section_data.get(\"target_length\", 300),\n",
    "            context=research_data,  # Share research context\n",
    "        )\n",
    "        project.sections.append(section)\n",
    "\n",
    "    return project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea586b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Complete Writing Workflow Demo\n",
    "def demo_complete_writing_workflow():\n",
    "    \"\"\"Demonstrate complete writing workflow\"\"\"\n",
    "\n",
    "    # Initialize LLM (using smaller model for demo)\n",
    "    print(\"Initializing LLM...\")\n",
    "    llm = LLMAdapter(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "    # Load style configuration\n",
    "    style_config = create_style_config()\n",
    "\n",
    "    # Initialize writer agent\n",
    "    writer = WriterAgent(llm, style_config)\n",
    "\n",
    "    # Create blackboard with sample data\n",
    "    blackboard = Blackboard()\n",
    "\n",
    "    # Simulate previous agent outputs\n",
    "    blackboard.update_state(\n",
    "        \"research_summary\",\n",
    "        \"RAGï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰æ˜¯çµåˆè³‡è¨Šæª¢ç´¢èˆ‡èªè¨€ç”Ÿæˆçš„æŠ€è¡“ï¼Œèƒ½è®“å¤§å‹èªè¨€æ¨¡å‹åŸºæ–¼å¤–éƒ¨çŸ¥è­˜åº«æä¾›æ›´æº–ç¢ºçš„å›ç­”ã€‚\"\n",
    "        \"ä¸»è¦çµ„æˆåŒ…æ‹¬æ–‡æª”åˆ†å‰²ã€å‘é‡åµŒå…¥ã€ç›¸ä¼¼åº¦æª¢ç´¢å’Œç­”æ¡ˆç”Ÿæˆç­‰æ­¥é©Ÿã€‚\",\n",
    "        \"researcher\",\n",
    "    )\n",
    "\n",
    "    blackboard.update_state(\n",
    "        \"outline\",\n",
    "        {\n",
    "            \"title\": \"RAG ç³»çµ±å¯¦ä½œæŒ‡å—\",\n",
    "            \"sections\": [\n",
    "                {\n",
    "                    \"title\": \"RAG ç³»çµ±æ¦‚è¿°\",\n",
    "                    \"points\": [\n",
    "                        \"RAG çš„åŸºæœ¬æ¦‚å¿µèˆ‡æ¶æ§‹\",\n",
    "                        \"èˆ‡å‚³çµ±æœå°‹å¼•æ“çš„å·®ç•°\",\n",
    "                        \"ä¸»è¦æ‡‰ç”¨å ´æ™¯\",\n",
    "                    ],\n",
    "                    \"target_length\": 300,\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"æŠ€è¡“å¯¦ä½œè¦é»\",\n",
    "                    \"points\": [\n",
    "                        \"æ–‡æª”é è™•ç†èˆ‡åˆ†å‰²ç­–ç•¥\",\n",
    "                        \"åµŒå…¥æ¨¡å‹é¸æ“‡èˆ‡å„ªåŒ–\",\n",
    "                        \"æª¢ç´¢èˆ‡é‡æ’æ©Ÿåˆ¶\",\n",
    "                    ],\n",
    "                    \"target_length\": 400,\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"è©•ä¼°èˆ‡å„ªåŒ–\",\n",
    "                    \"points\": [\n",
    "                        \"æª¢ç´¢å“è³ªè©•ä¼°æŒ‡æ¨™\",\n",
    "                        \"å›ç­”å“è³ªè©•ä¼°æ–¹æ³•\",\n",
    "                        \"ç³»çµ±æ•ˆèƒ½å„ªåŒ–å»ºè­°\",\n",
    "                    ],\n",
    "                    \"target_length\": 300,\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"planner\",\n",
    "    )\n",
    "\n",
    "    blackboard.update_state(\n",
    "        \"references\",\n",
    "        [\n",
    "            \"Lewis et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\",\n",
    "            \"BGE: General Embedding Model (BAAI, 2023)\",\n",
    "            \"FAISS: A Library for Efficient Similarity Search (Facebook AI, 2017)\",\n",
    "        ],\n",
    "        \"researcher\",\n",
    "    )\n",
    "\n",
    "    # Create writing project from blackboard\n",
    "    print(\"\\nCreating writing project from blackboard...\")\n",
    "    project = integrate_with_blackboard(blackboard, writer)\n",
    "\n",
    "    # Execute writing\n",
    "    print(f\"\\nStarting writing project: {project.title}\")\n",
    "    print(f\"Sections to write: {len(project.sections)}\")\n",
    "\n",
    "    # Write the complete project\n",
    "    final_content = writer.write_project(project)\n",
    "\n",
    "    # Format and finalize\n",
    "    formatter = ContentFormatter()\n",
    "    final_content = formatter.format_citations(final_content, project.references)\n",
    "    final_content = formatter.add_word_count(final_content)\n",
    "\n",
    "    # Update blackboard with results\n",
    "    blackboard.update_state(\"final_content\", final_content, \"writer\")\n",
    "    blackboard.update_state(\"writing_completed\", True, \"writer\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"WRITING COMPLETED\")\n",
    "    print(\"=\" * 50)\n",
    "    print(final_content[:500] + \"...\" if len(final_content) > 500 else final_content)\n",
    "\n",
    "    return final_content, blackboard\n",
    "\n",
    "\n",
    "# Run the demo\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        content, bb = demo_complete_writing_workflow()\n",
    "        print(f\"\\nBlackboard final state keys: {list(bb.keys())}\")\n",
    "        print(f\"Total characters generated: {len(content)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Demo failed: {e}\")\n",
    "        print(\"This is expected in minimal environment. Check dependencies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Smoke Test\n",
    "def smoke_test_writer():\n",
    "    \"\"\"Minimal smoke test for writer functionality\"\"\"\n",
    "    print(\"Running Writer Agent Smoke Test...\")\n",
    "\n",
    "    try:\n",
    "        # Test style configuration\n",
    "        style = create_style_config()\n",
    "        assert \"tone\" in style\n",
    "        assert \"glossary\" in style\n",
    "        print(\"âœ“ Style configuration OK\")\n",
    "\n",
    "        # Test section creation\n",
    "        section = WritingSection(\n",
    "            title=\"æ¸¬è©¦ç« ç¯€\", outline_points=[\"è¦é»ä¸€\", \"è¦é»äºŒ\"], target_length=200\n",
    "        )\n",
    "        assert section.title == \"æ¸¬è©¦ç« ç¯€\"\n",
    "        assert len(section.outline_points) == 2\n",
    "        print(\"âœ“ WritingSection creation OK\")\n",
    "\n",
    "        # Test blackboard\n",
    "        bb = Blackboard()\n",
    "        bb.update_state(\"test_key\", \"test_value\", \"test_agent\")\n",
    "        assert bb.get_state(\"test_key\") == \"test_value\"\n",
    "        assert len(bb.history) == 1\n",
    "        print(\"âœ“ Blackboard integration OK\")\n",
    "\n",
    "        # Test content formatting\n",
    "        formatter = ContentFormatter()\n",
    "        test_content = \"é€™æ˜¯æ¸¬è©¦å…§å®¹ [2] å’Œå¼•ç”¨ [1]ã€‚\"\n",
    "        formatted = formatter.format_citations(test_content, [\"ref1\", \"ref2\"])\n",
    "        assert \"[1]\" in formatted\n",
    "        print(\"âœ“ Content formatting OK\")\n",
    "\n",
    "        print(\"\\nğŸ‰ All smoke tests passed!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Smoke test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Run smoke test\n",
    "smoke_test_writer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a713bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Summary and Next Steps\n",
    "print(\n",
    "    \"\"\"\n",
    "## ğŸ“ Writer Agent å¯¦ä½œå®Œæˆ\n",
    "\n",
    "### å·²å®ŒæˆåŠŸèƒ½ï¼š\n",
    "1. âœ… Writer ä»£ç†æ ¸å¿ƒé¡åˆ¥ - æ”¯æ´åˆ†æ®µå¯«ä½œèˆ‡é¢¨æ ¼æ§åˆ¶\n",
    "2. âœ… Style Dictionary æ•´åˆ - èªæ°£ã€è¡“èªã€æ ¼å¼çµ±ä¸€\n",
    "3. âœ… åˆ†æ®µå¯«ä½œç­–ç•¥ - é¿å…éé•·å…§å®¹ï¼Œæå‡å“è³ª\n",
    "4. âœ… å…§å®¹éŠœæ¥æ©Ÿåˆ¶ - æ®µè½é–“é‚è¼¯é€£è²«\n",
    "5. âœ… é»‘æ¿ç³»çµ±æ•´åˆ - è®€å–ç ”ç©¶è³‡æ–™èˆ‡å¤§ç¶±\n",
    "6. âœ… æ ¼å¼åŒ–èˆ‡å¼•ç”¨ - çµ±ä¸€å¼•ç”¨æ ¼å¼ï¼Œå­—æ•¸çµ±è¨ˆ\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µï¼š\n",
    "- **åˆ†æ®µå¯«ä½œ**ï¼šå°‡é•·æ–‡æª”åˆ†å‰²ç‚ºå¯ç®¡ç†çš„æ®µè½ï¼Œé€ä¸€ç”Ÿæˆ\n",
    "- **é¢¨æ ¼ä¸€è‡´æ€§**ï¼šé€é Style Dictionary ç¢ºä¿èªæ°£èˆ‡è¡“èªçµ±ä¸€\n",
    "- **ä¸Šä¸‹æ–‡é€£è²«**ï¼šä½¿ç”¨å‰æ–‡æ‘˜è¦ç¶­æŒé‚è¼¯é€£è²«æ€§\n",
    "- **å¼•ç”¨æ¨™æº–åŒ–**ï¼šçµ±ä¸€ [1], [2] æ ¼å¼ï¼Œè‡ªå‹•é‡æ–°ç·¨è™Ÿ\n",
    "\n",
    "### å¸¸è¦‹é™·é˜±ï¼š\n",
    "âš ï¸ **é•·åº¦æ§åˆ¶**ï¼šè¨­å®šåˆç†çš„ target_lengthï¼Œé¿å…ç”Ÿæˆéé•·å…§å®¹\n",
    "âš ï¸ **é¢¨æ ¼æ¼‚ç§»**ï¼šç¢ºä¿ Style Dictionary è¦å‰‡æ¸…æ™°ä¸”ä¸€è‡´\n",
    "âš ï¸ **è¨˜æ†¶é«”ä½¿ç”¨**ï¼šåˆ†æ®µå¯«ä½œæ™‚æ³¨æ„ç´¯ç©çš„ä¸Šä¸‹æ–‡é•·åº¦\n",
    "âš ï¸ **å¼•ç”¨å°é½Š**ï¼šç¢ºä¿å¼•ç”¨ç·¨è™Ÿèˆ‡åƒè€ƒè³‡æ–™æ¸…å–®ä¸€è‡´\n",
    "\n",
    "### ä¸‹ä¸€æ­¥è¡Œå‹•ï¼š\n",
    "1. å¯¦ä½œ **nb34_reviewer_groundedness.ipynb** - äº‹å¯¦æ ¸æŸ¥èˆ‡å¼•ç”¨é©—è­‰\n",
    "2. æ•´åˆ **å¤±æ•—é‡è©¦æ©Ÿåˆ¶** - è™•ç†ç”Ÿæˆå“è³ªä¸ä½³çš„æƒ…æ³\n",
    "3. åŠ å…¥ **ç‰ˆæœ¬æ§åˆ¶** - æ”¯æ´å¤šæ¬¡ä¿®æ”¹èˆ‡ç‰ˆæœ¬æ¯”è¼ƒ\n",
    "4. å„ªåŒ– **æ•ˆèƒ½ç›£æ§** - è¿½è¹¤å¯«ä½œé€Ÿåº¦èˆ‡å“è³ªæŒ‡æ¨™\n",
    "\n",
    "### Git å·¥ä½œæµï¼š\n",
    "```bash\n",
    "git checkout -b feature/nb33-writer-composition\n",
    "git add notebooks/4_agents_orch/nb33_writer_composition.ipynb\n",
    "git add configs/styles/zh_general.yaml\n",
    "git commit -m \"feat(agent): writer composition with style dictionary\"\n",
    "git commit -m \"feat(agent): sectional writing and blackboard integration\"\n",
    "```\n",
    "\n",
    "ğŸš€ Writer Agent å·²æº–å‚™å¥½èˆ‡å…¶ä»–ä»£ç†å”ä½œï¼\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
