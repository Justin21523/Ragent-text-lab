{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8d8c06",
   "metadata": {},
   "source": [
    "# Goals 目標\n",
    " 1. 實作安全的檔案查找與讀取工具（白名單路徑保護）\n",
    " 2. 支援多種格式：txt/md/json/csv/yaml 等文字檔案\n",
    " 3. 建立檔案索引與快速查詢功能（避免目錄遍歷攻擊）\n",
    " 4. 整合到 function calling 架構中\n",
    " 5. 提供檔案內容搜尋與摘要功能\n",
    "\n",
    "# Prerequisites 前置需求\n",
    " - 完成 nb20-nb23 (function calling format, calculator, search, extraction)\n",
    " - 理解 pydantic schema validation \n",
    " - 基本檔案系統安全概念\n",
    " - 路徑正規化與白名單設計原則"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfae59b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cache] ../ai_warehouse/cache | GPU: True\n"
     ]
    }
   ],
   "source": [
    "# nb24_file_lookup_tool.ipynb\n",
    "# Stage 3: 檔案索引/讀取工具（路徑白名單）\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (複製到每本 notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41949ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: Import Dependencies & Setup\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Union\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "import mimetypes\n",
    "\n",
    "# For CSV reading\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# File type detection\n",
    "def detect_file_type(filepath: Path) -> str:\n",
    "    \"\"\"Detect file type based on extension and content\"\"\"\n",
    "    suffix = filepath.suffix.lower()\n",
    "    mime_type, _ = mimetypes.guess_type(str(filepath))\n",
    "\n",
    "    if suffix in [\".txt\", \".md\", \".markdown\"]:\n",
    "        return \"text\"\n",
    "    elif suffix in [\".json\"]:\n",
    "        return \"json\"\n",
    "    elif suffix in [\".yaml\", \".yml\"]:\n",
    "        return \"yaml\"\n",
    "    elif suffix in [\".csv\"]:\n",
    "        return \"csv\"\n",
    "    elif suffix in [\".py\"]:\n",
    "        return \"python\"\n",
    "    elif suffix in [\".log\"]:\n",
    "        return \"log\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "print(\"✅ Dependencies imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeaf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: File Lookup Tool Schema & Validation\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class FileLookupArgs(BaseModel):\n",
    "    \"\"\"File lookup tool arguments with security validation\"\"\"\n",
    "\n",
    "    action: str = Field(..., description=\"Action: 'search', 'read', 'list', 'info'\")\n",
    "    path: Optional[str] = Field(None, description=\"Target file/directory path\")\n",
    "    pattern: Optional[str] = Field(\n",
    "        None, description=\"Search pattern (filename or content)\"\n",
    "    )\n",
    "    max_results: int = Field(10, description=\"Maximum results to return\")\n",
    "    content_preview: bool = Field(\n",
    "        True, description=\"Include content preview in results\"\n",
    "    )\n",
    "\n",
    "    @validator(\"action\")\n",
    "    def validate_action(cls, v):\n",
    "        allowed = [\"search\", \"read\", \"list\", \"info\"]\n",
    "        if v not in allowed:\n",
    "            raise ValueError(f\"Action must be one of: {allowed}\")\n",
    "        return v\n",
    "\n",
    "    @validator(\"path\")\n",
    "    def validate_path(cls, v):\n",
    "        if v is None:\n",
    "            return v\n",
    "        # Normalize path and prevent directory traversal\n",
    "        normalized = str(Path(v).resolve())\n",
    "        if \"..\" in normalized or normalized.startswith(\"/\"):\n",
    "            raise ValueError(\"Invalid path: directory traversal not allowed\")\n",
    "        return normalized\n",
    "\n",
    "\n",
    "class FileInfo(BaseModel):\n",
    "    \"\"\"File information structure\"\"\"\n",
    "\n",
    "    path: str\n",
    "    name: str\n",
    "    size: int\n",
    "    type: str\n",
    "    modified: str\n",
    "    preview: Optional[str] = None\n",
    "    hash: Optional[str] = None\n",
    "\n",
    "\n",
    "# Test schema validation\n",
    "test_args = FileLookupArgs(action=\"search\", pattern=\"*.md\")\n",
    "print(\"✅ Schema validation working:\", test_args.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 4: Safe File Lookup Core Implementation\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class SafeFileLookup:\n",
    "    \"\"\"Safe file lookup tool with whitelist protection\"\"\"\n",
    "\n",
    "    def __init__(self, whitelist_dirs: List[str] = None):\n",
    "        # Default whitelist: only allow specific directories\n",
    "        self.whitelist_dirs = whitelist_dirs or [\n",
    "            \"data/docs\",\n",
    "            \"data/samples\",\n",
    "            \"outs/reports\",\n",
    "            \"configs\",\n",
    "            \"README.md\",\n",
    "        ]\n",
    "\n",
    "        # Convert to resolved paths for security\n",
    "        self.safe_paths = []\n",
    "        for dir_path in self.whitelist_dirs:\n",
    "            try:\n",
    "                resolved = Path(dir_path).resolve()\n",
    "                self.safe_paths.append(resolved)\n",
    "                # Ensure directory exists\n",
    "                if resolved.suffix == \"\":  # is directory\n",
    "                    resolved.mkdir(parents=True, exist_ok=True)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Warning: Cannot resolve {dir_path}: {e}\")\n",
    "\n",
    "    def _is_path_safe(self, target_path: Path) -> bool:\n",
    "        \"\"\"Check if target path is within whitelist\"\"\"\n",
    "        try:\n",
    "            resolved_target = target_path.resolve()\n",
    "\n",
    "            for safe_path in self.safe_paths:\n",
    "                try:\n",
    "                    # Check if target is safe_path itself or under safe_path\n",
    "                    if resolved_target == safe_path:\n",
    "                        return True\n",
    "                    if safe_path.is_dir() and resolved_target.is_relative_to(safe_path):\n",
    "                        return True\n",
    "                except (ValueError, OSError):\n",
    "                    continue\n",
    "            return False\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def _read_file_content(self, filepath: Path, max_chars: int = 2000) -> str:\n",
    "        \"\"\"Safely read file content with size limit\"\"\"\n",
    "        try:\n",
    "            if filepath.stat().st_size > 1024 * 1024:  # 1MB limit\n",
    "                return \"[File too large (>1MB)]\"\n",
    "\n",
    "            # Try different encodings\n",
    "            for encoding in [\"utf-8\", \"utf-8-sig\", \"gbk\", \"big5\"]:\n",
    "                try:\n",
    "                    with open(filepath, \"r\", encoding=encoding) as f:\n",
    "                        content = f.read(max_chars)\n",
    "                        if len(content) == max_chars:\n",
    "                            content += \"...[truncated]\"\n",
    "                        return content\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "\n",
    "            # If all text encodings fail, try as binary\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                raw = f.read(min(max_chars, 1000))\n",
    "                return f\"[Binary file, {len(raw)} bytes]: \" + str(raw[:100])\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"[Error reading file: {e}]\"\n",
    "\n",
    "    def search_files(\n",
    "        self, pattern: str = \"*\", content_search: str = None\n",
    "    ) -> List[FileInfo]:\n",
    "        \"\"\"Search files by pattern or content\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for safe_dir in self.safe_paths:\n",
    "            if not safe_dir.exists():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Search by filename pattern\n",
    "                if safe_dir.is_file():\n",
    "                    files = [safe_dir] if safe_dir.match(pattern) else []\n",
    "                else:\n",
    "                    files = list(safe_dir.rglob(pattern))\n",
    "\n",
    "                for filepath in files:\n",
    "                    if not filepath.is_file():\n",
    "                        continue\n",
    "\n",
    "                    # Check content search if specified\n",
    "                    if content_search:\n",
    "                        content = self._read_file_content(filepath, max_chars=5000)\n",
    "                        if content_search.lower() not in content.lower():\n",
    "                            continue\n",
    "\n",
    "                    # Build file info\n",
    "                    stat = filepath.stat()\n",
    "                    file_info = FileInfo(\n",
    "                        path=str(filepath),\n",
    "                        name=filepath.name,\n",
    "                        size=stat.st_size,\n",
    "                        type=detect_file_type(filepath),\n",
    "                        modified=datetime.fromtimestamp(stat.st_mtime).isoformat(),\n",
    "                        preview=self._read_file_content(filepath, max_chars=200),\n",
    "                    )\n",
    "                    results.append(file_info)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Search error in {safe_dir}: {e}\")\n",
    "\n",
    "        return sorted(results, key=lambda x: x.modified, reverse=True)\n",
    "\n",
    "\n",
    "# Initialize lookup tool\n",
    "file_lookup = SafeFileLookup()\n",
    "print(\"✅ SafeFileLookup initialized\")\n",
    "print(\"📁 Whitelist paths:\", [str(p) for p in file_lookup.safe_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Function Calling Interface\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def file_lookup_tool(args_dict: dict) -> dict:\n",
    "    \"\"\"Main file lookup tool function for agent calling\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Validate arguments\n",
    "        args = FileLookupArgs(**args_dict)\n",
    "\n",
    "        if args.action == \"list\":\n",
    "            # List files in whitelist directories\n",
    "            files = file_lookup.search_files(\"*\")\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"action\": \"list\",\n",
    "                \"count\": len(files),\n",
    "                \"files\": [f.dict() for f in files[: args.max_results]],\n",
    "            }\n",
    "\n",
    "        elif args.action == \"search\":\n",
    "            # Search by pattern or content\n",
    "            if not args.pattern:\n",
    "                return {\"status\": \"error\", \"message\": \"Pattern required for search\"}\n",
    "\n",
    "            files = file_lookup.search_files(pattern=args.pattern)\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"action\": \"search\",\n",
    "                \"pattern\": args.pattern,\n",
    "                \"count\": len(files),\n",
    "                \"files\": [f.dict() for f in files[: args.max_results]],\n",
    "            }\n",
    "\n",
    "        elif args.action == \"read\":\n",
    "            # Read specific file\n",
    "            if not args.path:\n",
    "                return {\"status\": \"error\", \"message\": \"Path required for read\"}\n",
    "\n",
    "            target_path = Path(args.path)\n",
    "            if not file_lookup._is_path_safe(target_path):\n",
    "                return {\"status\": \"error\", \"message\": \"Path not in whitelist\"}\n",
    "\n",
    "            if not target_path.exists():\n",
    "                return {\"status\": \"error\", \"message\": \"File not found\"}\n",
    "\n",
    "            content = file_lookup._read_file_content(target_path)\n",
    "            stat = target_path.stat()\n",
    "\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"action\": \"read\",\n",
    "                \"path\": str(target_path),\n",
    "                \"size\": stat.st_size,\n",
    "                \"type\": detect_file_type(target_path),\n",
    "                \"content\": content,\n",
    "            }\n",
    "\n",
    "        elif args.action == \"info\":\n",
    "            # Get file information only\n",
    "            if not args.path:\n",
    "                return {\"status\": \"error\", \"message\": \"Path required for info\"}\n",
    "\n",
    "            target_path = Path(args.path)\n",
    "            if not file_lookup._is_path_safe(target_path):\n",
    "                return {\"status\": \"error\", \"message\": \"Path not in whitelist\"}\n",
    "\n",
    "            if not target_path.exists():\n",
    "                return {\"status\": \"error\", \"message\": \"File not found\"}\n",
    "\n",
    "            stat = target_path.stat()\n",
    "            file_info = FileInfo(\n",
    "                path=str(target_path),\n",
    "                name=target_path.name,\n",
    "                size=stat.st_size,\n",
    "                type=detect_file_type(target_path),\n",
    "                modified=datetime.fromtimestamp(stat.st_mtime).isoformat(),\n",
    "                hash=hashlib.md5(target_path.read_bytes()).hexdigest()[:16],\n",
    "            )\n",
    "\n",
    "            return {\"status\": \"success\", \"action\": \"info\", \"file\": file_info.dict()}\n",
    "\n",
    "        else:\n",
    "            return {\"status\": \"error\", \"message\": f\"Unknown action: {args.action}\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Tool error: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Register tool for agent framework\n",
    "TOOL_REGISTRY = {\n",
    "    \"file_lookup\": {\n",
    "        \"function\": file_lookup_tool,\n",
    "        \"schema\": FileLookupArgs,\n",
    "        \"description\": \"Search, read, and get info about files in whitelisted directories\",\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"✅ File lookup tool registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: Create Sample Data for Testing\n",
    "# ============================================================================\n",
    "\n",
    "# Create sample files for testing\n",
    "sample_dir = Path(\"data/docs\")\n",
    "sample_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sample 1: README\n",
    "readme_content = \"\"\"# 專案文檔\n",
    "\n",
    "## 簡介\n",
    "這是一個 LLM × RAG × Agent 的測試專案。\n",
    "\n",
    "## 主要功能\n",
    "- 文檔處理與索引\n",
    "- 檢索增強生成\n",
    "- 多代理協作\n",
    "\n",
    "## 使用方法\n",
    "1. 設定環境變數\n",
    "2. 載入模型\n",
    "3. 建立索引\n",
    "4. 開始對話\n",
    "\n",
    "## 注意事項\n",
    "- 確保 GPU 記憶體充足\n",
    "- 模型檔案存放在 cache 目錄\n",
    "\"\"\"\n",
    "\n",
    "with open(sample_dir / \"README.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "# Sample 2: Config YAML\n",
    "config_content = \"\"\"\n",
    "model:\n",
    "  name: \"Qwen2.5-7B-Instruct\"\n",
    "  max_tokens: 2048\n",
    "  temperature: 0.7\n",
    "\n",
    "rag:\n",
    "  chunk_size: 800\n",
    "  overlap: 80\n",
    "  top_k: 5\n",
    "\n",
    "agent:\n",
    "  roles: [\"researcher\", \"planner\", \"writer\", \"reviewer\"]\n",
    "  max_iterations: 5\n",
    "\"\"\"\n",
    "\n",
    "with open(sample_dir / \"config.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "# Sample 3: Sample data CSV\n",
    "import csv\n",
    "\n",
    "csv_path = sample_dir / \"sample_data.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"name\", \"type\", \"score\", \"description\"])\n",
    "    writer.writerow([\"RAG\", \"技術\", \"95\", \"檢索增強生成\"])\n",
    "    writer.writerow([\"Agent\", \"架構\", \"90\", \"多代理系統\"])\n",
    "    writer.writerow([\"LLM\", \"模型\", \"88\", \"大型語言模型\"])\n",
    "\n",
    "print(\"✅ Sample files created:\")\n",
    "for file in sample_dir.iterdir():\n",
    "    print(f\"  📄 {file.name} ({file.stat().st_size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Smoke Test - Basic Tool Operations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"🧪 Smoke Test: File Lookup Tool\")\n",
    "\n",
    "# Test 1: List all files\n",
    "print(\"\\n=== Test 1: List Files ===\")\n",
    "result = file_lookup_tool({\"action\": \"list\", \"max_results\": 5})\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Found {result.get('count', 0)} files\")\n",
    "if result[\"status\"] == \"success\":\n",
    "    for file in result[\"files\"][:2]:\n",
    "        print(f\"  📄 {file['name']} ({file['size']} bytes, {file['type']})\")\n",
    "\n",
    "# Test 2: Search for markdown files\n",
    "print(\"\\n=== Test 2: Search Markdown ===\")\n",
    "result = file_lookup_tool({\"action\": \"search\", \"pattern\": \"*.md\"})\n",
    "print(f\"Status: {result['status']}\")\n",
    "if result[\"status\"] == \"success\":\n",
    "    print(f\"Found {result['count']} .md files\")\n",
    "    for file in result[\"files\"]:\n",
    "        print(f\"  📄 {file['name']}: {file['preview'][:50]}...\")\n",
    "\n",
    "# Test 3: Read specific file\n",
    "print(\"\\n=== Test 3: Read Config ===\")\n",
    "result = file_lookup_tool({\"action\": \"read\", \"path\": \"data/docs/config.yaml\"})\n",
    "print(f\"Status: {result['status']}\")\n",
    "if result[\"status\"] == \"success\":\n",
    "    print(f\"File: {result['path']}\")\n",
    "    print(f\"Type: {result['type']}\")\n",
    "    print(f\"Content preview:\\n{result['content'][:200]}...\")\n",
    "\n",
    "# Test 4: Security test (should fail)\n",
    "print(\"\\n=== Test 4: Security Check ===\")\n",
    "result = file_lookup_tool({\"action\": \"read\", \"path\": \"../../../etc/passwd\"})\n",
    "print(f\"Status: {result['status']} (should be 'error')\")\n",
    "print(f\"Message: {result.get('message', 'N/A')}\")\n",
    "\n",
    "print(\"\\n✅ All smoke tests completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e2972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 8: Integration with ReAct Agent Pattern\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def simple_react_with_file_lookup(query: str, max_iterations: int = 3) -> str:\n",
    "    \"\"\"Simple ReAct pattern with file lookup capability\"\"\"\n",
    "\n",
    "    # Mock LLM response generator (replace with real LLM)\n",
    "    def mock_llm_response(prompt: str) -> str:\n",
    "        \"\"\"Mock LLM that recognizes file lookup needs\"\"\"\n",
    "        if \"檔案\" in query or \"文件\" in query or \"file\" in query.lower():\n",
    "            return \"\"\"Thought: User is asking about files. I should search for relevant files first.\n",
    "\n",
    "Action: file_lookup\n",
    "Args: {\"action\": \"search\", \"pattern\": \"*\", \"max_results\": 5}\"\"\"\n",
    "\n",
    "        elif \"讀取\" in query or \"read\" in query.lower():\n",
    "            return \"\"\"Thought: User wants to read a specific file. I should list available files first.\n",
    "\n",
    "Action: file_lookup\n",
    "Args: {\"action\": \"list\", \"max_results\": 10}\"\"\"\n",
    "\n",
    "        else:\n",
    "            return f\"Answer: I can help you with file operations. Available actions: search, read, list, info.\"\n",
    "\n",
    "    conversation = f\"User Query: {query}\\n\\n\"\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Get LLM response\n",
    "        llm_output = mock_llm_response(query)\n",
    "        conversation += f\"Iteration {i+1}:\\n{llm_output}\\n\\n\"\n",
    "\n",
    "        # Parse action if present\n",
    "        if \"Action: file_lookup\" in llm_output:\n",
    "            # Extract args (simple parsing)\n",
    "            import re\n",
    "\n",
    "            args_match = re.search(r\"Args: ({.*?})\", llm_output, re.DOTALL)\n",
    "            if args_match:\n",
    "                try:\n",
    "                    args = json.loads(args_match.group(1))\n",
    "                    result = file_lookup_tool(args)\n",
    "                    conversation += f\"Observation: {json.dumps(result, ensure_ascii=False, indent=2)}\\n\\n\"\n",
    "\n",
    "                    # Simple follow-up logic\n",
    "                    if result[\"status\"] == \"success\" and result.get(\"files\"):\n",
    "                        files_summary = []\n",
    "                        for file in result[\"files\"][:3]:\n",
    "                            files_summary.append(f\"- {file['name']} ({file['type']})\")\n",
    "\n",
    "                        answer = f\"找到以下檔案：\\n\" + \"\\n\".join(files_summary)\n",
    "                        if len(result[\"files\"]) > 3:\n",
    "                            answer += f\"\\n... 還有 {len(result['files']) - 3} 個檔案\"\n",
    "\n",
    "                        conversation += f\"Answer: {answer}\\n\"\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    conversation += f\"Observation: Error parsing args: {e}\\n\\n\"\n",
    "        else:\n",
    "            # No action, return answer\n",
    "            break\n",
    "\n",
    "    return conversation\n",
    "\n",
    "\n",
    "# Test ReAct integration\n",
    "print(\"🤖 Testing ReAct + File Lookup Integration\")\n",
    "\n",
    "test_query = \"幫我找一下專案中有哪些文件\"\n",
    "result = simple_react_with_file_lookup(test_query)\n",
    "print(\"Query:\", test_query)\n",
    "print(\"\\nReAct Process:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: Key Parameters & Low-VRAM Considerations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"⚙️ Key Parameters & Low-VRAM Options\")\n",
    "\n",
    "# File lookup configuration\n",
    "FILE_LOOKUP_CONFIG = {\n",
    "    # Security settings\n",
    "    \"whitelist_dirs\": [\"data/docs\", \"data/samples\", \"outs/reports\", \"configs\"],\n",
    "    # Performance settings\n",
    "    \"max_file_size_mb\": 1,  # Max file size to read\n",
    "    \"max_content_chars\": 2000,  # Max characters to read per file\n",
    "    \"max_search_results\": 10,  # Max files to return in search\n",
    "    # Memory optimization\n",
    "    \"use_streaming_read\": True,  # For large files\n",
    "    \"cache_file_info\": False,  # Don't cache to save RAM\n",
    "    \"lazy_content_loading\": True,  # Only load content when needed\n",
    "}\n",
    "\n",
    "print(\"Configuration:\", json.dumps(FILE_LOOKUP_CONFIG, indent=2))\n",
    "\n",
    "# Low-VRAM considerations:\n",
    "print(\"\\n💾 Low-VRAM Considerations:\")\n",
    "print(\"- File content is read in chunks, not loaded entirely into memory\")\n",
    "print(\"- Large files (>1MB) are automatically truncated or skipped\")\n",
    "print(\"- No persistent caching to minimize RAM usage\")\n",
    "print(\"- Content preview is limited to first 200 chars\")\n",
    "print(\"- Use streaming reads for CSV/JSON parsing when possible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 10: When to Use This & Next Steps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"📋 When to Use File Lookup Tool:\")\n",
    "print()\n",
    "print(\"✅ Suitable scenarios:\")\n",
    "print(\"- Reading configuration files (YAML, JSON)\")\n",
    "print(\"- Searching project documentation\")\n",
    "print(\"- Loading sample data for processing\")\n",
    "print(\"- Accessing structured data files (CSV, logs)\")\n",
    "print(\"- Building knowledge bases from local files\")\n",
    "print()\n",
    "print(\"⚠️ Limitations:\")\n",
    "print(\"- Only works with whitelisted directories (security)\")\n",
    "print(\"- Large files (>1MB) are truncated\")\n",
    "print(\"- No real-time file watching\")\n",
    "print(\"- Limited to text-based formats\")\n",
    "print()\n",
    "print(\"🔄 Integration points:\")\n",
    "print(\"- RAG systems: Load documents for indexing\")\n",
    "print(\"- Agent workflows: Access configuration and data\")\n",
    "print(\"- Research tasks: Find and read relevant documents\")\n",
    "print(\"- File-based knowledge retrieval\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps (nb25 onwards):\")\n",
    "print(\"- nb25: ReAct Pattern Implementation\")\n",
    "print(\"- nb26: Tool Router & Security Guards\")\n",
    "print(\"- nb27: Schema Validation & Auto-Retry\")\n",
    "print(\"- nb28: Multi-step Plan-Execute with File Access\")\n",
    "\n",
    "# Save notebook state summary\n",
    "summary = {\n",
    "    \"notebook\": \"nb24_file_lookup_tool\",\n",
    "    \"completed_features\": [\n",
    "        \"Safe file lookup with whitelist protection\",\n",
    "        \"Multiple file formats support (txt/md/json/yaml/csv)\",\n",
    "        \"Function calling integration\",\n",
    "        \"Security validation against directory traversal\",\n",
    "        \"ReAct pattern integration demo\",\n",
    "    ],\n",
    "    \"files_created\": [\n",
    "        \"data/docs/README.md\",\n",
    "        \"data/docs/config.yaml\",\n",
    "        \"data/docs/sample_data.csv\",\n",
    "    ],\n",
    "    \"next_notebook\": \"nb25_react_pattern_minimal\",\n",
    "}\n",
    "\n",
    "print(f\"\\n📝 Notebook Summary: {json.dumps(summary, ensure_ascii=False, indent=2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
