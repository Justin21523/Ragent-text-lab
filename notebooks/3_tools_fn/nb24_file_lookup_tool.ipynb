{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8d8c06",
   "metadata": {},
   "source": [
    "# Goals ÁõÆÊ®ô\n",
    " 1. ÂØ¶‰ΩúÂÆâÂÖ®ÁöÑÊ™îÊ°àÊü•ÊâæËàáËÆÄÂèñÂ∑•ÂÖ∑ÔºàÁôΩÂêçÂñÆË∑ØÂæë‰øùË≠∑Ôºâ\n",
    " 2. ÊîØÊè¥Â§öÁ®ÆÊ†ºÂºèÔºötxt/md/json/csv/yaml Á≠âÊñáÂ≠óÊ™îÊ°à\n",
    " 3. Âª∫Á´ãÊ™îÊ°àÁ¥¢ÂºïËàáÂø´ÈÄüÊü•Ë©¢ÂäüËÉΩÔºàÈÅøÂÖçÁõÆÈåÑÈÅçÊ≠∑ÊîªÊìäÔºâ\n",
    " 4. Êï¥ÂêàÂà∞ function calling Êû∂Êßã‰∏≠\n",
    " 5. Êèê‰æõÊ™îÊ°àÂÖßÂÆπÊêúÂ∞ãËàáÊëòË¶ÅÂäüËÉΩ\n",
    "\n",
    "# Prerequisites ÂâçÁΩÆÈúÄÊ±Ç\n",
    " - ÂÆåÊàê nb20-nb23 (function calling format, calculator, search, extraction)\n",
    " - ÁêÜËß£ pydantic schema validation \n",
    " - Âü∫Êú¨Ê™îÊ°àÁ≥ªÁµ±ÂÆâÂÖ®Ê¶ÇÂøµ\n",
    " - Ë∑ØÂæëÊ≠£Ë¶èÂåñËàáÁôΩÂêçÂñÆË®≠Ë®àÂéüÂâá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfae59b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cache] ../ai_warehouse/cache | GPU: True\n"
     ]
    }
   ],
   "source": [
    "# nb24_file_lookup_tool.ipynb\n",
    "# Stage 3: Ê™îÊ°àÁ¥¢Âºï/ËÆÄÂèñÂ∑•ÂÖ∑ÔºàË∑ØÂæëÁôΩÂêçÂñÆÔºâ\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (Ë§áË£ΩÂà∞ÊØèÊú¨ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41949ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: Import Dependencies & Setup\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Union\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "import mimetypes\n",
    "\n",
    "# For CSV reading\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# File type detection\n",
    "def detect_file_type(filepath: Path) -> str:\n",
    "    \"\"\"Detect file type based on extension and content\"\"\"\n",
    "    suffix = filepath.suffix.lower()\n",
    "    mime_type, _ = mimetypes.guess_type(str(filepath))\n",
    "\n",
    "    if suffix in [\".txt\", \".md\", \".markdown\"]:\n",
    "        return \"text\"\n",
    "    elif suffix in [\".json\"]:\n",
    "        return \"json\"\n",
    "    elif suffix in [\".yaml\", \".yml\"]:\n",
    "        return \"yaml\"\n",
    "    elif suffix in [\".csv\"]:\n",
    "        return \"csv\"\n",
    "    elif suffix in [\".py\"]:\n",
    "        return \"python\"\n",
    "    elif suffix in [\".log\"]:\n",
    "        return \"log\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Dependencies imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeaf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: File Lookup Tool Schema & Validation\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class FileLookupArgs(BaseModel):\n",
    "    \"\"\"File lookup tool arguments with security validation\"\"\"\n",
    "\n",
    "    action: str = Field(..., description=\"Action: 'search', 'read', 'list', 'info'\")\n",
    "    path: Optional[str] = Field(None, description=\"Target file/directory path\")\n",
    "    pattern: Optional[str] = Field(\n",
    "        None, description=\"Search pattern (filename or content)\"\n",
    "    )\n",
    "    max_results: int = Field(10, description=\"Maximum results to return\")\n",
    "    content_preview: bool = Field(\n",
    "        True, description=\"Include content preview in results\"\n",
    "    )\n",
    "\n",
    "    @validator(\"action\")\n",
    "    def validate_action(cls, v):\n",
    "        allowed = [\"search\", \"read\", \"list\", \"info\"]\n",
    "        if v not in allowed:\n",
    "            raise ValueError(f\"Action must be one of: {allowed}\")\n",
    "        return v\n",
    "\n",
    "    @validator(\"path\")\n",
    "    def validate_path(cls, v):\n",
    "        if v is None:\n",
    "            return v\n",
    "        # Normalize path and prevent directory traversal\n",
    "        normalized = str(Path(v).resolve())\n",
    "        if \"..\" in normalized or normalized.startswith(\"/\"):\n",
    "            raise ValueError(\"Invalid path: directory traversal not allowed\")\n",
    "        return normalized\n",
    "\n",
    "\n",
    "class FileInfo(BaseModel):\n",
    "    \"\"\"File information structure\"\"\"\n",
    "\n",
    "    path: str\n",
    "    name: str\n",
    "    size: int\n",
    "    type: str\n",
    "    modified: str\n",
    "    preview: Optional[str] = None\n",
    "    hash: Optional[str] = None\n",
    "\n",
    "\n",
    "# Test schema validation\n",
    "test_args = FileLookupArgs(action=\"search\", pattern=\"*.md\")\n",
    "print(\"‚úÖ Schema validation working:\", test_args.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 4: Safe File Lookup Core Implementation\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class SafeFileLookup:\n",
    "    \"\"\"Safe file lookup tool with whitelist protection\"\"\"\n",
    "\n",
    "    def __init__(self, whitelist_dirs: List[str] = None):\n",
    "        # Default whitelist: only allow specific directories\n",
    "        self.whitelist_dirs = whitelist_dirs or [\n",
    "            \"data/docs\",\n",
    "            \"data/samples\",\n",
    "            \"outs/reports\",\n",
    "            \"configs\",\n",
    "            \"README.md\",\n",
    "        ]\n",
    "\n",
    "        # Convert to resolved paths for security\n",
    "        self.safe_paths = []\n",
    "        for dir_path in self.whitelist_dirs:\n",
    "            try:\n",
    "                resolved = Path(dir_path).resolve()\n",
    "                self.safe_paths.append(resolved)\n",
    "                # Ensure directory exists\n",
    "                if resolved.suffix == \"\":  # is directory\n",
    "                    resolved.mkdir(parents=True, exist_ok=True)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Warning: Cannot resolve {dir_path}: {e}\")\n",
    "\n",
    "    def _is_path_safe(self, target_path: Path) -> bool:\n",
    "        \"\"\"Check if target path is within whitelist\"\"\"\n",
    "        try:\n",
    "            resolved_target = target_path.resolve()\n",
    "\n",
    "            for safe_path in self.safe_paths:\n",
    "                try:\n",
    "                    # Check if target is safe_path itself or under safe_path\n",
    "                    if resolved_target == safe_path:\n",
    "                        return True\n",
    "                    if safe_path.is_dir() and resolved_target.is_relative_to(safe_path):\n",
    "                        return True\n",
    "                except (ValueError, OSError):\n",
    "                    continue\n",
    "            return False\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def _read_file_content(self, filepath: Path, max_chars: int = 2000) -> str:\n",
    "        \"\"\"Safely read file content with size limit\"\"\"\n",
    "        try:\n",
    "            if filepath.stat().st_size > 1024 * 1024:  # 1MB limit\n",
    "                return \"[File too large (>1MB)]\"\n",
    "\n",
    "            # Try different encodings\n",
    "            for encoding in [\"utf-8\", \"utf-8-sig\", \"gbk\", \"big5\"]:\n",
    "                try:\n",
    "                    with open(filepath, \"r\", encoding=encoding) as f:\n",
    "                        content = f.read(max_chars)\n",
    "                        if len(content) == max_chars:\n",
    "                            content += \"...[truncated]\"\n",
    "                        return content\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "\n",
    "            # If all text encodings fail, try as binary\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                raw = f.read(min(max_chars, 1000))\n",
    "                return f\"[Binary file, {len(raw)} bytes]: \" + str(raw[:100])\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"[Error reading file: {e}]\"\n",
    "\n",
    "    def search_files(\n",
    "        self, pattern: str = \"*\", content_search: str = None\n",
    "    ) -> List[FileInfo]:\n",
    "        \"\"\"Search files by pattern or content\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for safe_dir in self.safe_paths:\n",
    "            if not safe_dir.exists():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Search by filename pattern\n",
    "                if safe_dir.is_file():\n",
    "                    files = [safe_dir] if safe_dir.match(pattern) else []\n",
    "                else:\n",
    "                    files = list(safe_dir.rglob(pattern))\n",
    "\n",
    "                for filepath in files:\n",
    "                    if not filepath.is_file():\n",
    "                        continue\n",
    "\n",
    "                    # Check content search if specified\n",
    "                    if content_search:\n",
    "                        content = self._read_file_content(filepath, max_chars=5000)\n",
    "                        if content_search.lower() not in content.lower():\n",
    "                            continue\n",
    "\n",
    "                    # Build file info\n",
    "                    stat = filepath.stat()\n",
    "                    file_info = FileInfo(\n",
    "                        path=str(filepath),\n",
    "                        name=filepath.name,\n",
    "                        size=stat.st_size,\n",
    "                        type=detect_file_type(filepath),\n",
    "                        modified=datetime.fromtimestamp(stat.st_mtime).isoformat(),\n",
    "                        preview=self._read_file_content(filepath, max_chars=200),\n",
    "                    )\n",
    "                    results.append(file_info)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Search error in {safe_dir}: {e}\")\n",
    "\n",
    "        return sorted(results, key=lambda x: x.modified, reverse=True)\n",
    "\n",
    "\n",
    "# Initialize lookup tool\n",
    "file_lookup = SafeFileLookup()\n",
    "print(\"‚úÖ SafeFileLookup initialized\")\n",
    "print(\"üìÅ Whitelist paths:\", [str(p) for p in file_lookup.safe_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Function Calling Interface\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def file_lookup_tool(args_dict: dict) -> dict:\n",
    "    \"\"\"Main file lookup tool function for agent calling\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Validate arguments\n",
    "        args = FileLookupArgs(**args_dict)\n",
    "\n",
    "        if args.action == \"list\":\n",
    "            # List files in whitelist directories\n",
    "            files = file_lookup.search_files(\"*\")\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"action\": \"list\",\n",
    "                \"count\": len(files),\n",
    "                \"files\": [f.dict() for f in files[: args.max_results]],\n",
    "            }\n",
    "\n",
    "        elif args.action == \"search\":\n",
    "            # Search by pattern or content\n",
    "            if not args.pattern:\n",
    "                return {\"status\": \"error\", \"message\": \"Pattern required for search\"}\n",
    "\n",
    "            files = file_lookup.search_files(pattern=args.pattern)\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"action\": \"search\",\n",
    "                \"pattern\": args.pattern,\n",
    "                \"count\": len(files),\n",
    "                \"files\": [f.dict() for f in files[: args.max_results]],\n",
    "            }\n",
    "\n",
    "        elif args.action == \"read\":\n",
    "            # Read specific file\n",
    "            if not args.path:\n",
    "                return {\"status\": \"error\", \"message\": \"Path required for read\"}\n",
    "\n",
    "            target_path = Path(args.path)\n",
    "            if not file_lookup._is_path_safe(target_path):\n",
    "                return {\"status\": \"error\", \"message\": \"Path not in whitelist\"}\n",
    "\n",
    "            if not target_path.exists():\n",
    "                return {\"status\": \"error\", \"message\": \"File not found\"}\n",
    "\n",
    "            content = file_lookup._read_file_content(target_path)\n",
    "            stat = target_path.stat()\n",
    "\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"action\": \"read\",\n",
    "                \"path\": str(target_path),\n",
    "                \"size\": stat.st_size,\n",
    "                \"type\": detect_file_type(target_path),\n",
    "                \"content\": content,\n",
    "            }\n",
    "\n",
    "        elif args.action == \"info\":\n",
    "            # Get file information only\n",
    "            if not args.path:\n",
    "                return {\"status\": \"error\", \"message\": \"Path required for info\"}\n",
    "\n",
    "            target_path = Path(args.path)\n",
    "            if not file_lookup._is_path_safe(target_path):\n",
    "                return {\"status\": \"error\", \"message\": \"Path not in whitelist\"}\n",
    "\n",
    "            if not target_path.exists():\n",
    "                return {\"status\": \"error\", \"message\": \"File not found\"}\n",
    "\n",
    "            stat = target_path.stat()\n",
    "            file_info = FileInfo(\n",
    "                path=str(target_path),\n",
    "                name=target_path.name,\n",
    "                size=stat.st_size,\n",
    "                type=detect_file_type(target_path),\n",
    "                modified=datetime.fromtimestamp(stat.st_mtime).isoformat(),\n",
    "                hash=hashlib.md5(target_path.read_bytes()).hexdigest()[:16],\n",
    "            )\n",
    "\n",
    "            return {\"status\": \"success\", \"action\": \"info\", \"file\": file_info.dict()}\n",
    "\n",
    "        else:\n",
    "            return {\"status\": \"error\", \"message\": f\"Unknown action: {args.action}\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Tool error: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Register tool for agent framework\n",
    "TOOL_REGISTRY = {\n",
    "    \"file_lookup\": {\n",
    "        \"function\": file_lookup_tool,\n",
    "        \"schema\": FileLookupArgs,\n",
    "        \"description\": \"Search, read, and get info about files in whitelisted directories\",\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ File lookup tool registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: Create Sample Data for Testing\n",
    "# ============================================================================\n",
    "\n",
    "# Create sample files for testing\n",
    "sample_dir = Path(\"data/docs\")\n",
    "sample_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sample 1: README\n",
    "readme_content = \"\"\"# Â∞àÊ°àÊñáÊ™î\n",
    "\n",
    "## Á∞°‰ªã\n",
    "ÈÄôÊòØ‰∏ÄÂÄã LLM √ó RAG √ó Agent ÁöÑÊ∏¨Ë©¶Â∞àÊ°à„ÄÇ\n",
    "\n",
    "## ‰∏ªË¶ÅÂäüËÉΩ\n",
    "- ÊñáÊ™îËôïÁêÜËàáÁ¥¢Âºï\n",
    "- Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê\n",
    "- Â§ö‰ª£ÁêÜÂçî‰Ωú\n",
    "\n",
    "## ‰ΩøÁî®ÊñπÊ≥ï\n",
    "1. Ë®≠ÂÆöÁí∞Â¢ÉËÆäÊï∏\n",
    "2. ËºâÂÖ•Ê®°Âûã\n",
    "3. Âª∫Á´ãÁ¥¢Âºï\n",
    "4. ÈñãÂßãÂ∞çË©±\n",
    "\n",
    "## Ê≥®ÊÑè‰∫ãÈ†Ö\n",
    "- Á¢∫‰øù GPU Ë®òÊÜ∂È´îÂÖÖË∂≥\n",
    "- Ê®°ÂûãÊ™îÊ°àÂ≠òÊîæÂú® cache ÁõÆÈåÑ\n",
    "\"\"\"\n",
    "\n",
    "with open(sample_dir / \"README.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "# Sample 2: Config YAML\n",
    "config_content = \"\"\"\n",
    "model:\n",
    "  name: \"Qwen2.5-7B-Instruct\"\n",
    "  max_tokens: 2048\n",
    "  temperature: 0.7\n",
    "\n",
    "rag:\n",
    "  chunk_size: 800\n",
    "  overlap: 80\n",
    "  top_k: 5\n",
    "\n",
    "agent:\n",
    "  roles: [\"researcher\", \"planner\", \"writer\", \"reviewer\"]\n",
    "  max_iterations: 5\n",
    "\"\"\"\n",
    "\n",
    "with open(sample_dir / \"config.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "# Sample 3: Sample data CSV\n",
    "import csv\n",
    "\n",
    "csv_path = sample_dir / \"sample_data.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"name\", \"type\", \"score\", \"description\"])\n",
    "    writer.writerow([\"RAG\", \"ÊäÄË°ì\", \"95\", \"Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê\"])\n",
    "    writer.writerow([\"Agent\", \"Êû∂Êßã\", \"90\", \"Â§ö‰ª£ÁêÜÁ≥ªÁµ±\"])\n",
    "    writer.writerow([\"LLM\", \"Ê®°Âûã\", \"88\", \"Â§ßÂûãË™ûË®ÄÊ®°Âûã\"])\n",
    "\n",
    "print(\"‚úÖ Sample files created:\")\n",
    "for file in sample_dir.iterdir():\n",
    "    print(f\"  üìÑ {file.name} ({file.stat().st_size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Smoke Test - Basic Tool Operations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üß™ Smoke Test: File Lookup Tool\")\n",
    "\n",
    "# Test 1: List all files\n",
    "print(\"\\n=== Test 1: List Files ===\")\n",
    "result = file_lookup_tool({\"action\": \"list\", \"max_results\": 5})\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Found {result.get('count', 0)} files\")\n",
    "if result[\"status\"] == \"success\":\n",
    "    for file in result[\"files\"][:2]:\n",
    "        print(f\"  üìÑ {file['name']} ({file['size']} bytes, {file['type']})\")\n",
    "\n",
    "# Test 2: Search for markdown files\n",
    "print(\"\\n=== Test 2: Search Markdown ===\")\n",
    "result = file_lookup_tool({\"action\": \"search\", \"pattern\": \"*.md\"})\n",
    "print(f\"Status: {result['status']}\")\n",
    "if result[\"status\"] == \"success\":\n",
    "    print(f\"Found {result['count']} .md files\")\n",
    "    for file in result[\"files\"]:\n",
    "        print(f\"  üìÑ {file['name']}: {file['preview'][:50]}...\")\n",
    "\n",
    "# Test 3: Read specific file\n",
    "print(\"\\n=== Test 3: Read Config ===\")\n",
    "result = file_lookup_tool({\"action\": \"read\", \"path\": \"data/docs/config.yaml\"})\n",
    "print(f\"Status: {result['status']}\")\n",
    "if result[\"status\"] == \"success\":\n",
    "    print(f\"File: {result['path']}\")\n",
    "    print(f\"Type: {result['type']}\")\n",
    "    print(f\"Content preview:\\n{result['content'][:200]}...\")\n",
    "\n",
    "# Test 4: Security test (should fail)\n",
    "print(\"\\n=== Test 4: Security Check ===\")\n",
    "result = file_lookup_tool({\"action\": \"read\", \"path\": \"../../../etc/passwd\"})\n",
    "print(f\"Status: {result['status']} (should be 'error')\")\n",
    "print(f\"Message: {result.get('message', 'N/A')}\")\n",
    "\n",
    "print(\"\\n‚úÖ All smoke tests completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e2972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 8: Integration with ReAct Agent Pattern\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def simple_react_with_file_lookup(query: str, max_iterations: int = 3) -> str:\n",
    "    \"\"\"Simple ReAct pattern with file lookup capability\"\"\"\n",
    "\n",
    "    # Mock LLM response generator (replace with real LLM)\n",
    "    def mock_llm_response(prompt: str) -> str:\n",
    "        \"\"\"Mock LLM that recognizes file lookup needs\"\"\"\n",
    "        if \"Ê™îÊ°à\" in query or \"Êñá‰ª∂\" in query or \"file\" in query.lower():\n",
    "            return \"\"\"Thought: User is asking about files. I should search for relevant files first.\n",
    "\n",
    "Action: file_lookup\n",
    "Args: {\"action\": \"search\", \"pattern\": \"*\", \"max_results\": 5}\"\"\"\n",
    "\n",
    "        elif \"ËÆÄÂèñ\" in query or \"read\" in query.lower():\n",
    "            return \"\"\"Thought: User wants to read a specific file. I should list available files first.\n",
    "\n",
    "Action: file_lookup\n",
    "Args: {\"action\": \"list\", \"max_results\": 10}\"\"\"\n",
    "\n",
    "        else:\n",
    "            return f\"Answer: I can help you with file operations. Available actions: search, read, list, info.\"\n",
    "\n",
    "    conversation = f\"User Query: {query}\\n\\n\"\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Get LLM response\n",
    "        llm_output = mock_llm_response(query)\n",
    "        conversation += f\"Iteration {i+1}:\\n{llm_output}\\n\\n\"\n",
    "\n",
    "        # Parse action if present\n",
    "        if \"Action: file_lookup\" in llm_output:\n",
    "            # Extract args (simple parsing)\n",
    "            import re\n",
    "\n",
    "            args_match = re.search(r\"Args: ({.*?})\", llm_output, re.DOTALL)\n",
    "            if args_match:\n",
    "                try:\n",
    "                    args = json.loads(args_match.group(1))\n",
    "                    result = file_lookup_tool(args)\n",
    "                    conversation += f\"Observation: {json.dumps(result, ensure_ascii=False, indent=2)}\\n\\n\"\n",
    "\n",
    "                    # Simple follow-up logic\n",
    "                    if result[\"status\"] == \"success\" and result.get(\"files\"):\n",
    "                        files_summary = []\n",
    "                        for file in result[\"files\"][:3]:\n",
    "                            files_summary.append(f\"- {file['name']} ({file['type']})\")\n",
    "\n",
    "                        answer = f\"ÊâæÂà∞‰ª•‰∏ãÊ™îÊ°àÔºö\\n\" + \"\\n\".join(files_summary)\n",
    "                        if len(result[\"files\"]) > 3:\n",
    "                            answer += f\"\\n... ÈÇÑÊúâ {len(result['files']) - 3} ÂÄãÊ™îÊ°à\"\n",
    "\n",
    "                        conversation += f\"Answer: {answer}\\n\"\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    conversation += f\"Observation: Error parsing args: {e}\\n\\n\"\n",
    "        else:\n",
    "            # No action, return answer\n",
    "            break\n",
    "\n",
    "    return conversation\n",
    "\n",
    "\n",
    "# Test ReAct integration\n",
    "print(\"ü§ñ Testing ReAct + File Lookup Integration\")\n",
    "\n",
    "test_query = \"Âπ´ÊàëÊâæ‰∏Ä‰∏ãÂ∞àÊ°à‰∏≠ÊúâÂì™‰∫õÊñá‰ª∂\"\n",
    "result = simple_react_with_file_lookup(test_query)\n",
    "print(\"Query:\", test_query)\n",
    "print(\"\\nReAct Process:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: Key Parameters & Low-VRAM Considerations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"‚öôÔ∏è Key Parameters & Low-VRAM Options\")\n",
    "\n",
    "# File lookup configuration\n",
    "FILE_LOOKUP_CONFIG = {\n",
    "    # Security settings\n",
    "    \"whitelist_dirs\": [\"data/docs\", \"data/samples\", \"outs/reports\", \"configs\"],\n",
    "    # Performance settings\n",
    "    \"max_file_size_mb\": 1,  # Max file size to read\n",
    "    \"max_content_chars\": 2000,  # Max characters to read per file\n",
    "    \"max_search_results\": 10,  # Max files to return in search\n",
    "    # Memory optimization\n",
    "    \"use_streaming_read\": True,  # For large files\n",
    "    \"cache_file_info\": False,  # Don't cache to save RAM\n",
    "    \"lazy_content_loading\": True,  # Only load content when needed\n",
    "}\n",
    "\n",
    "print(\"Configuration:\", json.dumps(FILE_LOOKUP_CONFIG, indent=2))\n",
    "\n",
    "# Low-VRAM considerations:\n",
    "print(\"\\nüíæ Low-VRAM Considerations:\")\n",
    "print(\"- File content is read in chunks, not loaded entirely into memory\")\n",
    "print(\"- Large files (>1MB) are automatically truncated or skipped\")\n",
    "print(\"- No persistent caching to minimize RAM usage\")\n",
    "print(\"- Content preview is limited to first 200 chars\")\n",
    "print(\"- Use streaming reads for CSV/JSON parsing when possible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 10: When to Use This & Next Steps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üìã When to Use File Lookup Tool:\")\n",
    "print()\n",
    "print(\"‚úÖ Suitable scenarios:\")\n",
    "print(\"- Reading configuration files (YAML, JSON)\")\n",
    "print(\"- Searching project documentation\")\n",
    "print(\"- Loading sample data for processing\")\n",
    "print(\"- Accessing structured data files (CSV, logs)\")\n",
    "print(\"- Building knowledge bases from local files\")\n",
    "print()\n",
    "print(\"‚ö†Ô∏è Limitations:\")\n",
    "print(\"- Only works with whitelisted directories (security)\")\n",
    "print(\"- Large files (>1MB) are truncated\")\n",
    "print(\"- No real-time file watching\")\n",
    "print(\"- Limited to text-based formats\")\n",
    "print()\n",
    "print(\"üîÑ Integration points:\")\n",
    "print(\"- RAG systems: Load documents for indexing\")\n",
    "print(\"- Agent workflows: Access configuration and data\")\n",
    "print(\"- Research tasks: Find and read relevant documents\")\n",
    "print(\"- File-based knowledge retrieval\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps (nb25 onwards):\")\n",
    "print(\"- nb25: ReAct Pattern Implementation\")\n",
    "print(\"- nb26: Tool Router & Security Guards\")\n",
    "print(\"- nb27: Schema Validation & Auto-Retry\")\n",
    "print(\"- nb28: Multi-step Plan-Execute with File Access\")\n",
    "\n",
    "# Save notebook state summary\n",
    "summary = {\n",
    "    \"notebook\": \"nb24_file_lookup_tool\",\n",
    "    \"completed_features\": [\n",
    "        \"Safe file lookup with whitelist protection\",\n",
    "        \"Multiple file formats support (txt/md/json/yaml/csv)\",\n",
    "        \"Function calling integration\",\n",
    "        \"Security validation against directory traversal\",\n",
    "        \"ReAct pattern integration demo\",\n",
    "    ],\n",
    "    \"files_created\": [\n",
    "        \"data/docs/README.md\",\n",
    "        \"data/docs/config.yaml\",\n",
    "        \"data/docs/sample_data.csv\",\n",
    "    ],\n",
    "    \"next_notebook\": \"nb25_react_pattern_minimal\",\n",
    "}\n",
    "\n",
    "print(f\"\\nüìù Notebook Summary: {json.dumps(summary, ensure_ascii=False, indent=2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
