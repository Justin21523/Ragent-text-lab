{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9272c8",
   "metadata": {},
   "source": [
    "\n",
    "# Stage 3-1: Function Calling Format & Minimal ReAct\n",
    "\n",
    "**Goals:**\n",
    "- Implement OpenAI-style function calling JSON output\n",
    "- Build tool registry with pydantic schema validation\n",
    "- Design minimal ReAct pattern (Thoughtâ†’Actionâ†’Observation)\n",
    "- Ensure safe tool execution with whitelist\n",
    "\n",
    "**Prerequisites:**\n",
    "- Stage 1 LLMAdapter working\n",
    "- Basic understanding of JSON schema and pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Function Calling Format & Minimal ReAct\n",
    "# nb20_function_calling_format.ipynb\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (è¤‡è£½åˆ°æ¯æœ¬ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ad0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Import and Setup\n",
    "import json, re, ast, operator\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Initialize LLM (lightweight for demo)\n",
    "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "print(f\"Loading {MODEL_ID}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    load_in_4bit=True,  # Low VRAM option\n",
    ")\n",
    "print(f\"Model loaded on: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Tool Schema Definition with Pydantic\n",
    "class CalculatorArgs(BaseModel):\n",
    "    \"\"\"Safe arithmetic calculator tool arguments\"\"\"\n",
    "\n",
    "    expression: str = Field(\n",
    "        ..., description=\"Mathematical expression to evaluate (safe operators only)\"\n",
    "    )\n",
    "\n",
    "    @validator(\"expression\")\n",
    "    def validate_expression(cls, v):\n",
    "        # Basic safety: only allow numbers, basic operators, parentheses\n",
    "        allowed_chars = set(\"0123456789+-*/().,e \")\n",
    "        if not all(c in allowed_chars for c in v.replace(\" \", \"\")):\n",
    "            raise ValueError(\"Expression contains unsafe characters\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class SearchArgs(BaseModel):\n",
    "    \"\"\"Web search tool arguments\"\"\"\n",
    "\n",
    "    query: str = Field(..., description=\"Search query string\")\n",
    "    max_results: int = Field(5, description=\"Maximum number of results to return\")\n",
    "\n",
    "\n",
    "class FileReadArgs(BaseModel):\n",
    "    \"\"\"File reading tool arguments\"\"\"\n",
    "\n",
    "    filepath: str = Field(..., description=\"Path to file to read\")\n",
    "\n",
    "    @validator(\"filepath\")\n",
    "    def validate_filepath(cls, v):\n",
    "        # Security: only allow certain paths\n",
    "        if not v.startswith((\"data/\", \"configs/\", \"outs/\")):\n",
    "            raise ValueError(\"File path not in allowed directories\")\n",
    "        return v\n",
    "\n",
    "\n",
    "# Tool registry mapping\n",
    "TOOL_SCHEMAS = {\n",
    "    \"calculator\": CalculatorArgs,\n",
    "    \"web_search\": SearchArgs,\n",
    "    \"file_read\": FileReadArgs,\n",
    "}\n",
    "\n",
    "print(\"âœ“ Tool schemas registered:\", list(TOOL_SCHEMAS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Tool Implementation Functions\n",
    "def execute_calculator(expression: str) -> str:\n",
    "    \"\"\"Execute safe arithmetic calculation\"\"\"\n",
    "    try:\n",
    "        # Parse and validate AST for safety\n",
    "        tree = ast.parse(expression, mode=\"eval\")\n",
    "\n",
    "        # Only allow safe operations\n",
    "        allowed_nodes = (\n",
    "            ast.Expression,\n",
    "            ast.Num,\n",
    "            ast.BinOp,\n",
    "            ast.UnaryOp,\n",
    "            ast.operator,\n",
    "            ast.unaryop,\n",
    "            ast.cmpop,\n",
    "            ast.Constant,\n",
    "        )\n",
    "        allowed_ops = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Pow, ast.USub, ast.UAdd)\n",
    "\n",
    "        for node in ast.walk(tree):\n",
    "            if not isinstance(node, allowed_nodes + allowed_ops):\n",
    "                raise ValueError(f\"Unsafe operation: {type(node).__name__}\")\n",
    "\n",
    "        # Evaluate safely\n",
    "        result = eval(compile(tree, \"<string>\", \"eval\"))\n",
    "        return f\"Result: {result}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def execute_web_search(query: str, max_results: int = 5) -> str:\n",
    "    \"\"\"Mock web search (replace with real implementation)\"\"\"\n",
    "    # This is a placeholder - in real implementation use duckduckgo-search\n",
    "    mock_results = [\n",
    "        f\"Result {i+1}: {query} related content...\" for i in range(min(max_results, 3))\n",
    "    ]\n",
    "    return f\"Search results for '{query}':\\n\" + \"\\n\".join(mock_results)\n",
    "\n",
    "\n",
    "def execute_file_read(filepath: str) -> str:\n",
    "    \"\"\"Read file content safely\"\"\"\n",
    "    try:\n",
    "        # Additional security check\n",
    "        if not filepath.startswith((\"data/\", \"configs/\", \"outs/\")):\n",
    "            return \"Error: File path not allowed\"\n",
    "\n",
    "        # Mock file reading (replace with actual file operations)\n",
    "        return f\"Content of {filepath}: [Mock file content...]\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "\n",
    "# Tool execution registry\n",
    "TOOL_EXECUTORS = {\n",
    "    \"calculator\": execute_calculator,\n",
    "    \"web_search\": execute_web_search,\n",
    "    \"file_read\": execute_file_read,\n",
    "}\n",
    "\n",
    "print(\"âœ“ Tool executors registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c207c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Function Calling Prompt Template\n",
    "def create_function_calling_prompt(user_query: str, available_tools: List[str]) -> str:\n",
    "    \"\"\"Create prompt for function calling with specific JSON format\"\"\"\n",
    "\n",
    "    tool_descriptions = []\n",
    "    for tool_name in available_tools:\n",
    "        if tool_name == \"calculator\":\n",
    "            tool_descriptions.append(\n",
    "                \"\"\"\n",
    "- calculator: Perform mathematical calculations\n",
    "  Parameters: {\"expression\": \"math expression using +,-,*,/,(),numbers\"}\"\"\"\n",
    "            )\n",
    "        elif tool_name == \"web_search\":\n",
    "            tool_descriptions.append(\n",
    "                \"\"\"\n",
    "- web_search: Search the web for information\n",
    "  Parameters: {\"query\": \"search terms\", \"max_results\": 5}\"\"\"\n",
    "            )\n",
    "        elif tool_name == \"file_read\":\n",
    "            tool_descriptions.append(\n",
    "                \"\"\"\n",
    "- file_read: Read file contents\n",
    "  Parameters: {\"filepath\": \"path/to/file\"}\"\"\"\n",
    "            )\n",
    "\n",
    "    tools_text = \"\\n\".join(tool_descriptions)\n",
    "\n",
    "    prompt = f\"\"\"You are a helpful assistant that can use tools to answer questions.\n",
    "\n",
    "Available tools:\n",
    "{tools_text}\n",
    "\n",
    "When you need to use a tool, respond ONLY with valid JSON in this exact format:\n",
    "{{\"tool\": \"tool_name\", \"args\": {{\"param1\": \"value1\", \"param2\": \"value2\"}}}}\n",
    "\n",
    "If you don't need tools, respond normally.\n",
    "\n",
    "User question: {user_query}\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a63074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: JSON Parsing and Validation\n",
    "def parse_tool_call(response: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Extract and validate tool call from LLM response\"\"\"\n",
    "\n",
    "    # Try to find JSON in response\n",
    "    json_match = re.search(r\"\\{.*\\}\", response, re.DOTALL)\n",
    "    if not json_match:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Parse JSON\n",
    "        tool_call = json.loads(json_match.group())\n",
    "\n",
    "        # Validate structure\n",
    "        if not isinstance(tool_call, dict):\n",
    "            return None\n",
    "        if \"tool\" not in tool_call or \"args\" not in tool_call:\n",
    "            return None\n",
    "\n",
    "        tool_name = tool_call[\"tool\"]\n",
    "        args = tool_call[\"args\"]\n",
    "\n",
    "        # Validate tool exists\n",
    "        if tool_name not in TOOL_SCHEMAS:\n",
    "            return None\n",
    "\n",
    "        # Validate arguments with pydantic\n",
    "        schema_class = TOOL_SCHEMAS[tool_name]\n",
    "        validated_args = schema_class(**args)\n",
    "\n",
    "        return {\"tool\": tool_name, \"args\": validated_args.dict()}\n",
    "\n",
    "    except (json.JSONDecodeError, ValueError, TypeError) as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91608297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: Tool Execution with Safety\n",
    "def execute_tool_safely(tool_call: Dict[str, Any]) -> str:\n",
    "    \"\"\"Execute tool call with safety checks\"\"\"\n",
    "\n",
    "    tool_name = tool_call[\"tool\"]\n",
    "    args = tool_call[\"args\"]\n",
    "\n",
    "    # Check if tool exists in whitelist\n",
    "    if tool_name not in TOOL_EXECUTORS:\n",
    "        return f\"Error: Tool '{tool_name}' not found in whitelist\"\n",
    "\n",
    "    # Get executor function\n",
    "    executor = TOOL_EXECUTORS[tool_name]\n",
    "\n",
    "    try:\n",
    "        # Execute with unpacked arguments\n",
    "        if tool_name == \"calculator\":\n",
    "            result = executor(args[\"expression\"])\n",
    "        elif tool_name == \"web_search\":\n",
    "            result = executor(args[\"query\"], args.get(\"max_results\", 5))\n",
    "        elif tool_name == \"file_read\":\n",
    "            result = executor(args[\"filepath\"])\n",
    "        else:\n",
    "            result = \"Error: Unknown tool execution pattern\"\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Tool execution error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 8: Minimal ReAct Loop\n",
    "def minimal_react_loop(user_query: str, max_iterations: int = 3) -> str:\n",
    "    \"\"\"Minimal ReAct: Thought â†’ Action â†’ Observation loop\"\"\"\n",
    "\n",
    "    available_tools = [\"calculator\", \"web_search\", \"file_read\"]\n",
    "    conversation_history = []\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "\n",
    "        # Create prompt with context\n",
    "        if conversation_history:\n",
    "            context = \"\\n\".join(conversation_history)\n",
    "            full_prompt = (\n",
    "                f\"Previous context:\\n{context}\\n\\n\"\n",
    "                + create_function_calling_prompt(user_query, available_tools)\n",
    "            )\n",
    "        else:\n",
    "            full_prompt = create_function_calling_prompt(user_query, available_tools)\n",
    "\n",
    "        # Generate response\n",
    "        messages = [{\"role\": \"user\", \"content\": full_prompt}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, return_tensors=\"pt\", add_generation_prompt=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs,\n",
    "                max_new_tokens=256,\n",
    "                temperature=0.3,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "\n",
    "        response = tokenizer.decode(\n",
    "            outputs[0][inputs.shape[1] :], skip_special_tokens=True\n",
    "        )\n",
    "        print(f\"LLM Response: {response}\")\n",
    "\n",
    "        # Check if response contains tool call\n",
    "        tool_call = parse_tool_call(response)\n",
    "\n",
    "        if tool_call:\n",
    "            print(f\"Tool Call Detected: {tool_call}\")\n",
    "\n",
    "            # Execute tool\n",
    "            observation = execute_tool_safely(tool_call)\n",
    "            print(f\"Tool Result: {observation}\")\n",
    "\n",
    "            # Add to conversation history\n",
    "            conversation_history.append(f\"Action: {tool_call}\")\n",
    "            conversation_history.append(f\"Observation: {observation}\")\n",
    "\n",
    "            # Continue loop for potential follow-up\n",
    "            continue\n",
    "        else:\n",
    "            # No tool call - this might be the final answer\n",
    "            print(f\"Final Answer: {response}\")\n",
    "            return response\n",
    "\n",
    "    return \"Maximum iterations reached. Please try a simpler query.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 9: Smoke Test\n",
    "print(\"=== Function Calling Smoke Test ===\")\n",
    "\n",
    "# Test 1: Simple calculation\n",
    "print(\"\\n1. Testing Calculator:\")\n",
    "calc_prompt = create_function_calling_prompt(\"What is 25 * 4 + 17?\", [\"calculator\"])\n",
    "print(\"Prompt:\", calc_prompt[:100] + \"...\")\n",
    "\n",
    "# Test tool call parsing\n",
    "sample_json = '{\"tool\": \"calculator\", \"args\": {\"expression\": \"25 * 4 + 17\"}}'\n",
    "parsed = parse_tool_call(sample_json)\n",
    "print(\"Parsed tool call:\", parsed)\n",
    "\n",
    "if parsed:\n",
    "    result = execute_tool_safely(parsed)\n",
    "    print(\"Execution result:\", result)\n",
    "\n",
    "# Test 2: Invalid tool call handling\n",
    "print(\"\\n2. Testing Invalid JSON:\")\n",
    "invalid_json = '{\"invalid\": \"format\"}'\n",
    "parsed_invalid = parse_tool_call(invalid_json)\n",
    "print(\"Invalid parse result:\", parsed_invalid)\n",
    "\n",
    "# Test 3: Mini ReAct loop\n",
    "print(\"\\n3. Testing Mini ReAct Loop:\")\n",
    "try:\n",
    "    react_result = minimal_react_loop(\n",
    "        \"Calculate 15 + 27 and tell me if it's greater than 40\"\n",
    "    )\n",
    "    print(f\"ReAct Final Result: {react_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"ReAct Error: {e}\")\n",
    "\n",
    "print(\"\\nâœ“ Smoke test completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b73a0",
   "metadata": {},
   "source": [
    "## Key Parameters & Low-VRAM Options\n",
    "\n",
    "**Model Loading:**\n",
    "- `load_in_4bit=True` - Reduces VRAM by ~50%\n",
    "- `device_map=\"auto\"` - Automatic GPU/CPU distribution\n",
    "- Alternative: Use `llama.cpp` with GGUF for even lower memory\n",
    "\n",
    "**Generation Parameters:**\n",
    "- `max_new_tokens=256` - Short responses for tool calls\n",
    "- `temperature=0.3` - More deterministic for JSON generation\n",
    "- `do_sample=True` - Slight randomness to avoid repetition\n",
    "\n",
    "**Safety Features:**\n",
    "- AST parsing for calculator expressions\n",
    "- File path whitelist validation\n",
    "- Tool name whitelist checking\n",
    "- JSON schema validation with pydantic\n",
    "\n",
    "## When to Use This\n",
    "\n",
    "- **Function Calling Applications**: When LLM needs to interact with external tools\n",
    "- **Agent Systems**: As building block for ReAct/Plan-Execute patterns  \n",
    "- **API Integration**: Structured way to call external services\n",
    "- **Code Generation**: When LLM needs to generate executable commands\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Add more sophisticated tools (web search, file operations)\n",
    "- Implement retry mechanisms for failed tool calls\n",
    "- Add conversation memory and context management\n",
    "- Build proper error handling and logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb260c9",
   "metadata": {},
   "source": [
    "## Core Code Highlights\n",
    "\n",
    "**1. Pydantic Schema é©—è­‰**\n",
    "```python\n",
    "class CalculatorArgs(BaseModel):\n",
    "    expression: str = Field(..., description=\"Mathematical expression\")\n",
    "    \n",
    "    @validator('expression')\n",
    "    def validate_expression(cls, v):\n",
    "        allowed_chars = set('0123456789+-*/().,e ')\n",
    "        if not all(c in allowed_chars for c in v.replace(' ', '')):\n",
    "            raise ValueError(\"Expression contains unsafe characters\")\n",
    "        return v\n",
    "```\n",
    "\n",
    "**2. å·¥å…·èª¿ç”¨ JSON è§£æ**\n",
    "```python\n",
    "def parse_tool_call(response: str) -> Optional[Dict[str, Any]]:\n",
    "    json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    if not json_match:\n",
    "        return None\n",
    "    \n",
    "    tool_call = json.loads(json_match.group())\n",
    "    schema_class = TOOL_SCHEMAS[tool_name]\n",
    "    validated_args = schema_class(**args)\n",
    "    return {\"tool\": tool_name, \"args\": validated_args.dict()}\n",
    "```\n",
    "\n",
    "**3. æœ€å° ReAct å¾ªç’°**\n",
    "```python\n",
    "def minimal_react_loop(user_query: str, max_iterations: int = 3):\n",
    "    for iteration in range(max_iterations):\n",
    "        # Generate â†’ Parse â†’ Execute â†’ Observe â†’ Continue\n",
    "        response = model.generate(...)\n",
    "        tool_call = parse_tool_call(response)\n",
    "        if tool_call:\n",
    "            observation = execute_tool_safely(tool_call)\n",
    "            conversation_history.append(f\"Observation: {observation}\")\n",
    "```\n",
    "\n",
    "## Smoke Test Cell\n",
    "\n",
    "å®Œæ•´çš„å·¥å…·èª¿ç”¨æµç¨‹æ¸¬è©¦ï¼š\n",
    "1. è¨ˆç®—å™¨å·¥å…·èª¿ç”¨èˆ‡åŸ·è¡Œ\n",
    "2. ç„¡æ•ˆ JSON è™•ç†æ¸¬è©¦  \n",
    "3. ç°¡åŒ–ç‰ˆ ReAct å¾ªç’°é‹è¡Œ\n",
    "\n",
    "\n",
    "\n",
    "## Stage 3-1 Summary\n",
    "\n",
    "**âœ… Completed:**\n",
    "- OpenAI é¢¨æ ¼ function calling JSON æ ¼å¼å¯¦ä½œ\n",
    "- Pydantic å·¥å…·åƒæ•¸é©—è­‰èˆ‡å®‰å…¨æª¢æŸ¥\n",
    "- åŸºç¤å·¥å…·è¨»å†Šè¡¨èˆ‡åŸ·è¡Œæ¡†æ¶\n",
    "- æœ€å° ReAct æ¨¡å¼ï¼ˆæ€è€ƒâ†’è¡Œå‹•â†’è§€å¯Ÿï¼‰\n",
    "\n",
    "**ğŸ”‘ Core Concepts:**\n",
    "- **JSON Schema Validation**: ä½¿ç”¨ pydantic ç¢ºä¿å·¥å…·åƒæ•¸æ­£ç¢ºæ€§\n",
    "- **Tool Registry Pattern**: å¯æ“´å±•çš„å·¥å…·è¨»å†Šèˆ‡åˆ†æ´¾æ©Ÿåˆ¶\n",
    "- **Safe Execution**: AST è§£æã€è·¯å¾‘ç™½åå–®ç­‰å®‰å…¨æªæ–½\n",
    "- **ReAct Loop**: å¾ªç’°å¼æ¨ç†èˆ‡è¡Œå‹•æ¨¡å¼\n",
    "\n",
    "**âš ï¸ Pitfalls:**\n",
    "- JSON è§£æå¤±æ•—è™•ç†ï¼šLLM è¼¸å‡ºæ ¼å¼ä¸ç©©å®š\n",
    "- å·¥å…·åŸ·è¡Œå®‰å…¨ï¼šæƒ¡æ„è¼¸å…¥å¯èƒ½å°è‡´ç³»çµ±é¢¨éšª\n",
    "- è¨˜æ†¶é«”ç®¡ç†ï¼šReAct å¾ªç’°ä¸­çš„å°è©±æ­·å²ç´¯ç©\n",
    "\n",
    "**â¡ï¸ Next Actions:**\n",
    "- **nb21**: å¯¦ä½œå®‰å…¨è¨ˆç®—å™¨ï¼ˆAST é™åˆ¶èˆ‡æ•¸å­¸å‡½æ•¸ï¼‰\n",
    "- **nb22**: DuckDuckGo æœå°‹å·¥å…·èˆ‡é€Ÿç‡é™åˆ¶\n",
    "- **nb23**: HTML å…§å®¹æŠ½å–ï¼ˆtrafilatura æ•´åˆï¼‰\n",
    "\n",
    "æ‚¨å¸Œæœ›ç¹¼çºŒ **nb21_safe_calculator.ipynb** é‚„æ˜¯å…ˆé‡å° nb20 é€²è¡Œèª¿æ•´æˆ–å„ªåŒ–ï¼Ÿ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
