{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef3bf49",
   "metadata": {},
   "source": [
    "# Goals (目標)\n",
    " 1. Implement pydantic schema validation for LLM JSON outputs\n",
    " 2. Build automatic retry with repair mechanisms (90%+ success rate)\n",
    " 3. Handle common JSON parsing errors and malformed structures\n",
    " 4. Create robust tool-calling with graceful degradation\n",
    " 5. Demonstrate JSON repair strategies for Chinese LLM outputs\n",
    "\n",
    "# Prerequisites (前置需求)\n",
    " - nb20_function_calling_format.ipynb completed\n",
    " - Basic understanding of pydantic BaseModel\n",
    " - JSON parsing and error handling concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Validation & Retry Mechanisms\n",
    "# nb27_schema_validation_retry.ipynb\n",
    "# 結構化輸出驗證與自動修復機制\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (複製到每本 notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: Dependencies and Imports\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field, ValidationError, validator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: Tool Schema Definitions (Pydantic Models)\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class CalculatorArgs(BaseModel):\n",
    "    \"\"\"Safe calculator tool arguments\"\"\"\n",
    "\n",
    "    expression: str = Field(\n",
    "        ...,\n",
    "        description=\"Mathematical expression to evaluate\",\n",
    "        min_length=1,\n",
    "        max_length=200,\n",
    "    )\n",
    "\n",
    "    @validator(\"expression\")\n",
    "    def validate_expression(cls, v):\n",
    "        # Allow only safe characters for math expressions\n",
    "        allowed_chars = set(\"0123456789+-*/().,e \")\n",
    "        if not all(c in allowed_chars for c in v):\n",
    "            raise ValueError(\"Expression contains invalid characters\")\n",
    "        return v.strip()\n",
    "\n",
    "\n",
    "class WebSearchArgs(BaseModel):\n",
    "    \"\"\"Web search tool arguments\"\"\"\n",
    "\n",
    "    query: str = Field(..., description=\"Search query\", min_length=1, max_length=500)\n",
    "    max_results: int = Field(\n",
    "        default=5, ge=1, le=20, description=\"Number of results to return\"\n",
    "    )\n",
    "\n",
    "\n",
    "class FileReadArgs(BaseModel):\n",
    "    \"\"\"File reading tool arguments\"\"\"\n",
    "\n",
    "    filepath: str = Field(..., description=\"Path to file to read\", min_length=1)\n",
    "    max_lines: int = Field(\n",
    "        default=100, ge=1, le=1000, description=\"Maximum lines to read\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    \"\"\"Complete tool call structure\"\"\"\n",
    "\n",
    "    tool: str = Field(..., description=\"Tool name to call\")\n",
    "    args: Dict[str, Any] = Field(..., description=\"Tool arguments\")\n",
    "    reasoning: Optional[str] = Field(None, description=\"Why this tool is needed\")\n",
    "\n",
    "\n",
    "# Tool registry mapping\n",
    "TOOL_SCHEMAS = {\n",
    "    \"calculator\": CalculatorArgs,\n",
    "    \"web_search\": WebSearchArgs,\n",
    "    \"file_read\": FileReadArgs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63950d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 4: JSON Repair Utilities\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class JSONRepair:\n",
    "    \"\"\"Utilities for repairing common JSON formatting issues\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_json_from_text(text: str) -> str:\n",
    "        \"\"\"Extract JSON from text that may contain extra content\"\"\"\n",
    "        # Look for JSON-like patterns\n",
    "        patterns = [\n",
    "            r\"\\{[^{}]*\\}\",  # Simple object\n",
    "            r\"\\{.*?\\}\",  # Greedy object match\n",
    "            r\"```json\\s*(\\{.*?\\})\\s*```\",  # Markdown code block\n",
    "            r\"```\\s*(\\{.*?\\})\\s*```\",  # Code block without json tag\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text, re.DOTALL)\n",
    "            if matches:\n",
    "                return matches[0] if isinstance(matches[0], str) else matches[0]\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_common_issues(json_str: str) -> str:\n",
    "        \"\"\"Fix common JSON formatting issues\"\"\"\n",
    "        # Remove trailing commas\n",
    "        json_str = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", json_str)\n",
    "\n",
    "        # Fix unquoted keys (common in LLM outputs)\n",
    "        json_str = re.sub(r\"(\\w+):\", r'\"\\1\":', json_str)\n",
    "\n",
    "        # Fix single quotes to double quotes\n",
    "        json_str = json_str.replace(\"'\", '\"')\n",
    "\n",
    "        # Remove extra whitespace\n",
    "        json_str = re.sub(r\"\\s+\", \" \", json_str).strip()\n",
    "\n",
    "        # Ensure proper quotes around string values\n",
    "        json_str = re.sub(r':\\s*([^\",{\\[\\]}\\s]+)(?=\\s*[,}])', r': \"\\1\"', json_str)\n",
    "\n",
    "        return json_str\n",
    "\n",
    "    @staticmethod\n",
    "    def attempt_repair(broken_json: str) -> Optional[Dict]:\n",
    "        \"\"\"Attempt multiple repair strategies\"\"\"\n",
    "        repair_strategies = [\n",
    "            lambda x: x,  # Try as-is first\n",
    "            JSONRepair.extract_json_from_text,\n",
    "            JSONRepair.fix_common_issues,\n",
    "            lambda x: JSONRepair.fix_common_issues(\n",
    "                JSONRepair.extract_json_from_text(x)\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        for strategy in repair_strategies:\n",
    "            try:\n",
    "                repaired = strategy(broken_json)\n",
    "                return json.loads(repaired)\n",
    "            except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "                continue\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Validation and Retry Logic\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    \"\"\"Result of validation attempt\"\"\"\n",
    "\n",
    "    success: bool\n",
    "    data: Optional[Dict] = None\n",
    "    errors: List[str] = None\n",
    "    repaired: bool = False\n",
    "    attempts: int = 1\n",
    "\n",
    "\n",
    "class SchemaValidator:\n",
    "    \"\"\"Handles schema validation with retry and repair\"\"\"\n",
    "\n",
    "    def __init__(self, max_retries: int = 3, repair_enabled: bool = True):\n",
    "        self.max_retries = max_retries\n",
    "        self.repair_enabled = repair_enabled\n",
    "        self.repair_stats = {\"attempts\": 0, \"successes\": 0}\n",
    "\n",
    "    def validate_tool_call(\n",
    "        self, raw_output: str, allow_repair: bool = True\n",
    "    ) -> ValidationResult:\n",
    "        \"\"\"Validate and potentially repair tool call output\"\"\"\n",
    "        errors = []\n",
    "\n",
    "        for attempt in range(1, self.max_retries + 1):\n",
    "            try:\n",
    "                # Try direct JSON parsing first\n",
    "                if attempt == 1:\n",
    "                    data = json.loads(raw_output)\n",
    "                else:\n",
    "                    # Use repair on subsequent attempts\n",
    "                    if self.repair_enabled and allow_repair:\n",
    "                        self.repair_stats[\"attempts\"] += 1\n",
    "                        data = JSONRepair.attempt_repair(raw_output)\n",
    "                        if data is None:\n",
    "                            errors.append(f\"Attempt {attempt}: JSON repair failed\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        errors.append(f\"Attempt {attempt}: Repair disabled, skipping\")\n",
    "                        continue\n",
    "\n",
    "                # Validate against ToolCall schema\n",
    "                tool_call = ToolCall(**data)\n",
    "\n",
    "                # Validate specific tool args\n",
    "                if tool_call.tool in TOOL_SCHEMAS:\n",
    "                    tool_schema = TOOL_SCHEMAS[tool_call.tool]\n",
    "                    validated_args = tool_schema(**tool_call.args)\n",
    "                    tool_call.args = validated_args.dict()\n",
    "\n",
    "                # Success!\n",
    "                if attempt > 1:\n",
    "                    self.repair_stats[\"successes\"] += 1\n",
    "\n",
    "                return ValidationResult(\n",
    "                    success=True,\n",
    "                    data=tool_call.dict(),\n",
    "                    repaired=(attempt > 1),\n",
    "                    attempts=attempt,\n",
    "                )\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                errors.append(f\"Attempt {attempt}: JSON decode error: {str(e)}\")\n",
    "            except ValidationError as e:\n",
    "                errors.append(f\"Attempt {attempt}: Schema validation error: {str(e)}\")\n",
    "            except Exception as e:\n",
    "                errors.append(f\"Attempt {attempt}: Unexpected error: {str(e)}\")\n",
    "\n",
    "        return ValidationResult(success=False, errors=errors, attempts=self.max_retries)\n",
    "\n",
    "    def get_repair_success_rate(self) -> float:\n",
    "        \"\"\"Get current repair success rate\"\"\"\n",
    "        if self.repair_stats[\"attempts\"] == 0:\n",
    "            return 0.0\n",
    "        return self.repair_stats[\"successes\"] / self.repair_stats[\"attempts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: LLM Integration with Retry\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class LLMWithRetry:\n",
    "    \"\"\"LLM adapter with built-in validation and retry\"\"\"\n",
    "\n",
    "    def __init__(self, model_id: str = \"Qwen/Qwen2.5-7B-Instruct\"):\n",
    "        print(f\"Loading model: {model_id}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            load_in_4bit=True,  # Low VRAM option\n",
    "        )\n",
    "        self.validator = SchemaValidator(max_retries=3)\n",
    "\n",
    "        # Add padding token if missing\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def generate_tool_call(\n",
    "        self, user_query: str, available_tools: List[str]\n",
    "    ) -> ValidationResult:\n",
    "        \"\"\"Generate and validate tool call with automatic retry\"\"\"\n",
    "\n",
    "        # Create prompt for tool calling\n",
    "        tools_desc = \"\\n\".join(\n",
    "            [f\"- {tool}: {TOOL_SCHEMAS[tool].__doc__}\" for tool in available_tools]\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"You are a helpful assistant that can call tools. Given a user query, output a JSON object with tool name and arguments.\n",
    "\n",
    "Available tools:\n",
    "{tools_desc}\n",
    "\n",
    "Output format (JSON only):\n",
    "{{\"tool\": \"tool_name\", \"args\": {{\"param\": \"value\"}}, \"reasoning\": \"why this tool\"}}\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "JSON response:\"\"\"\n",
    "\n",
    "        max_attempts = 3\n",
    "        for attempt in range(1, max_attempts + 1):\n",
    "            try:\n",
    "                # Generate response\n",
    "                inputs = self.tokenizer(\n",
    "                    prompt, return_tensors=\"pt\", truncation=True, max_length=2048\n",
    "                )\n",
    "                inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=200,\n",
    "                        temperature=0.3,\n",
    "                        do_sample=True,\n",
    "                        pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    )\n",
    "\n",
    "                # Decode response\n",
    "                response = self.tokenizer.decode(\n",
    "                    outputs[0][inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True\n",
    "                )\n",
    "                response = response.strip()\n",
    "\n",
    "                logger.info(f\"Attempt {attempt} raw output: {response}\")\n",
    "\n",
    "                # Validate with repair\n",
    "                result = self.validator.validate_tool_call(response, allow_repair=True)\n",
    "\n",
    "                if result.success:\n",
    "                    logger.info(f\"✅ Validation successful on attempt {attempt}\")\n",
    "                    return result\n",
    "                else:\n",
    "                    logger.warning(f\"❌ Attempt {attempt} failed: {result.errors}\")\n",
    "                    if attempt < max_attempts:\n",
    "                        # Modify prompt for retry\n",
    "                        prompt += f\"\\n\\nPrevious attempt failed. Please output valid JSON only:\"\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Generation error on attempt {attempt}: {str(e)}\")\n",
    "\n",
    "        # All attempts failed\n",
    "        return ValidationResult(\n",
    "            success=False,\n",
    "            errors=[f\"All {max_attempts} generation attempts failed\"],\n",
    "            attempts=max_attempts,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Demo Functions and Tool Execution\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def execute_tool_call(tool_call_data: Dict) -> Dict:\n",
    "    \"\"\"Execute validated tool call (mock implementation)\"\"\"\n",
    "    tool_name = tool_call_data[\"tool\"]\n",
    "    args = tool_call_data[\"args\"]\n",
    "\n",
    "    if tool_name == \"calculator\":\n",
    "        try:\n",
    "            # Safe eval for demo (real implementation should use ast.literal_eval)\n",
    "            result = eval(args[\"expression\"])\n",
    "            return {\"status\": \"success\", \"result\": result}\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "    elif tool_name == \"web_search\":\n",
    "        # Mock search results\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"results\": [\n",
    "                {\"title\": f\"搜尋結果：{args['query']}\", \"url\": \"https://example.com\"},\n",
    "                {\"title\": f\"相關文章：{args['query']}\", \"url\": \"https://example2.com\"},\n",
    "            ][: args.get(\"max_results\", 5)],\n",
    "        }\n",
    "\n",
    "    elif tool_name == \"file_read\":\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"content\": f\"Mock file content from {args['filepath']} (max {args.get('max_lines', 100)} lines)\",\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error\": f\"Unknown tool: {tool_name}\"}\n",
    "\n",
    "\n",
    "def demo_query_with_retry(llm: LLMWithRetry, query: str, tools: List[str]):\n",
    "    \"\"\"Demo complete flow: query -> generate -> validate -> execute\"\"\"\n",
    "    print(f\"\\n🔍 Query: {query}\")\n",
    "    print(f\"📋 Available tools: {tools}\")\n",
    "\n",
    "    # Generate and validate tool call\n",
    "    result = llm.generate_tool_call(query, tools)\n",
    "\n",
    "    if result.success:\n",
    "        print(\n",
    "            f\"✅ Validation successful (attempts: {result.attempts}, repaired: {result.repaired})\"\n",
    "        )\n",
    "        print(f\"📝 Tool call: {json.dumps(result.data, ensure_ascii=False, indent=2)}\")\n",
    "\n",
    "        # Execute tool\n",
    "        execution_result = execute_tool_call(result.data)\n",
    "        print(\n",
    "            f\"🔧 Execution result: {json.dumps(execution_result, ensure_ascii=False, indent=2)}\"\n",
    "        )\n",
    "\n",
    "        return result.data, execution_result\n",
    "    else:\n",
    "        print(f\"❌ Validation failed after {result.attempts} attempts\")\n",
    "        for error in result.errors:\n",
    "            print(f\"   - {error}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 8: MVP Test Cases\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize LLM (low VRAM settings)\n",
    "print(\"🚀 Initializing LLM with retry capabilities...\")\n",
    "llm = LLMWithRetry(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    (\"計算 25 * 4 + 10 的結果\", [\"calculator\"]),\n",
    "    (\"搜尋關於 RAG 檢索增強生成的資料\", [\"web_search\"]),\n",
    "    (\"讀取 config.yaml 檔案的前 50 行\", [\"file_read\"]),\n",
    "    (\"我想要計算 (100 + 200) / 3\", [\"calculator\", \"web_search\"]),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for query, tools in test_queries:\n",
    "    tool_call, execution = demo_query_with_retry(llm, query, tools)\n",
    "    results.append(\n",
    "        {\n",
    "            \"query\": query,\n",
    "            \"success\": tool_call is not None,\n",
    "            \"tool_call\": tool_call,\n",
    "            \"execution\": execution,\n",
    "        }\n",
    "    )\n",
    "    time.sleep(1)  # Brief pause between requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: JSON Repair Testing\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔧 Testing JSON repair capabilities...\")\n",
    "\n",
    "# Test cases with deliberately broken JSON\n",
    "broken_json_examples = [\n",
    "    '{\"tool\": \"calculator\", \"args\": {\"expression\": \"2+3\"}}',  # Valid (control)\n",
    "    '{tool: \"calculator\", args: {expression: \"2+3\"}}',  # Unquoted keys\n",
    "    \"{'tool': 'calculator', 'args': {'expression': '2+3'}}\",  # Single quotes\n",
    "    '{\"tool\": \"calculator\", \"args\": {\"expression\": \"2+3\",},}',  # Trailing commas\n",
    "    '```json\\n{\"tool\": \"web_search\", \"args\": {\"query\": \"test\"}}\\n```',  # Markdown\n",
    "    '{\"tool\": \"calculator\", \"args\": {\"expression\": 2+3}}',  # Unquoted value\n",
    "]\n",
    "\n",
    "validator = SchemaValidator()\n",
    "repair_test_results = []\n",
    "\n",
    "for i, broken_json in enumerate(broken_json_examples):\n",
    "    print(f\"\\n📝 Test case {i+1}: {broken_json}\")\n",
    "    result = validator.validate_tool_call(broken_json)\n",
    "    repair_test_results.append(\n",
    "        {\n",
    "            \"input\": broken_json,\n",
    "            \"success\": result.success,\n",
    "            \"repaired\": result.repaired,\n",
    "            \"attempts\": result.attempts,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        print(f\"   ✅ Success (repaired: {result.repaired})\")\n",
    "        print(f\"   📋 Parsed: {json.dumps(result.data, ensure_ascii=False)}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"   ❌ Failed: {result.errors[-1] if result.errors else 'Unknown error'}\"\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 10: Smoke Test & Success Rate Analysis\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate overall success rates\n",
    "total_tests = len(results) + len(repair_test_results)\n",
    "successful_tests = sum(1 for r in results if r[\"success\"]) + sum(\n",
    "    1 for r in repair_test_results if r[\"success\"]\n",
    ")\n",
    "success_rate = successful_tests / total_tests if total_tests > 0 else 0\n",
    "\n",
    "repair_success_rate = llm.validator.get_repair_success_rate()\n",
    "\n",
    "print(f\"\\n📊 SMOKE TEST RESULTS\")\n",
    "print(f\"═══════════════════════════════════════\")\n",
    "print(f\"Overall success rate: {success_rate:.1%} ({successful_tests}/{total_tests})\")\n",
    "print(f\"JSON repair success rate: {repair_success_rate:.1%}\")\n",
    "print(\n",
    "    f\"Tool execution tests: {len([r for r in results if r['success']])}/{len(results)} passed\"\n",
    ")\n",
    "print(\n",
    "    f\"JSON repair tests: {len([r for r in repair_test_results if r['success']])}/{len(repair_test_results)} passed\"\n",
    ")\n",
    "\n",
    "# Detailed repair statistics\n",
    "repair_stats = llm.validator.repair_stats\n",
    "print(f\"\\n🔧 Repair Statistics:\")\n",
    "print(f\"   Repair attempts: {repair_stats['attempts']}\")\n",
    "print(f\"   Repair successes: {repair_stats['successes']}\")\n",
    "\n",
    "# Assert minimum success rate for smoke test\n",
    "assert success_rate >= 0.7, f\"Success rate {success_rate:.1%} below minimum 70%\"\n",
    "assert (\n",
    "    len([r for r in results if r[\"success\"]]) >= 2\n",
    "), \"At least 2 tool executions should succeed\"\n",
    "\n",
    "print(f\"\\n✅ SMOKE TEST PASSED!\")\n",
    "print(f\"   - Schema validation working\")\n",
    "print(f\"   - JSON repair functional\")\n",
    "print(f\"   - Tool execution pipeline complete\")\n",
    "print(f\"   - Success rate: {success_rate:.1%} ≥ 70% ✓\")\n",
    "\n",
    "# ============================================================================\n",
    "# When to use this notebook:\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "📚 使用時機 (When to use this):\n",
    "\n",
    "1. **LLM 結構化輸出驗證**: 當需要確保 LLM 輸出符合特定 JSON schema 時\n",
    "2. **工具調用容錯**: 在 ReAct/Function-calling 中需要穩定的工具調用成功率\n",
    "3. **JSON 格式修復**: 處理 LLM 常見的 JSON 格式錯誤（缺引號、逗號等）\n",
    "4. **生產環境穩定性**: 需要 90%+ 成功率的結構化輸出場景\n",
    "5. **多語言 LLM 適配**: 中文 LLM 在 JSON 輸出上的特殊處理需求\n",
    "\n",
    "Key benefits:\n",
    "- 自動 JSON 修復與重試機制\n",
    "- Pydantic schema 驗證與型別安全\n",
    "- 詳細的錯誤追蹤與統計\n",
    "- 低 VRAM 友善的實作\n",
    "- 90%+ 工具調用成功率目標\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    tool: str = Field(..., description=\"Tool name to call\")\n",
    "    args: Dict[str, Any] = Field(..., description=\"Tool arguments\")\n",
    "    reasoning: Optional[str] = Field(None, description=\"Why this tool is needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
