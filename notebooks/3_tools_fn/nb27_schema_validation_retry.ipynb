{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef3bf49",
   "metadata": {},
   "source": [
    "# Goals (ç›®æ¨™)\n",
    " 1. Implement pydantic schema validation for LLM JSON outputs\n",
    " 2. Build automatic retry with repair mechanisms (90%+ success rate)\n",
    " 3. Handle common JSON parsing errors and malformed structures\n",
    " 4. Create robust tool-calling with graceful degradation\n",
    " 5. Demonstrate JSON repair strategies for Chinese LLM outputs\n",
    "\n",
    "# Prerequisites (å‰ç½®éœ€æ±‚)\n",
    " - nb20_function_calling_format.ipynb completed\n",
    " - Basic understanding of pydantic BaseModel\n",
    " - JSON parsing and error handling concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Validation & Retry Mechanisms\n",
    "# nb27_schema_validation_retry.ipynb\n",
    "# çµæ§‹åŒ–è¼¸å‡ºé©—è­‰èˆ‡è‡ªå‹•ä¿®å¾©æ©Ÿåˆ¶\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (è¤‡è£½åˆ°æ¯æœ¬ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: Dependencies and Imports\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field, ValidationError, validator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: Tool Schema Definitions (Pydantic Models)\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class CalculatorArgs(BaseModel):\n",
    "    \"\"\"Safe calculator tool arguments\"\"\"\n",
    "\n",
    "    expression: str = Field(\n",
    "        ...,\n",
    "        description=\"Mathematical expression to evaluate\",\n",
    "        min_length=1,\n",
    "        max_length=200,\n",
    "    )\n",
    "\n",
    "    @validator(\"expression\")\n",
    "    def validate_expression(cls, v):\n",
    "        # Allow only safe characters for math expressions\n",
    "        allowed_chars = set(\"0123456789+-*/().,e \")\n",
    "        if not all(c in allowed_chars for c in v):\n",
    "            raise ValueError(\"Expression contains invalid characters\")\n",
    "        return v.strip()\n",
    "\n",
    "\n",
    "class WebSearchArgs(BaseModel):\n",
    "    \"\"\"Web search tool arguments\"\"\"\n",
    "\n",
    "    query: str = Field(..., description=\"Search query\", min_length=1, max_length=500)\n",
    "    max_results: int = Field(\n",
    "        default=5, ge=1, le=20, description=\"Number of results to return\"\n",
    "    )\n",
    "\n",
    "\n",
    "class FileReadArgs(BaseModel):\n",
    "    \"\"\"File reading tool arguments\"\"\"\n",
    "\n",
    "    filepath: str = Field(..., description=\"Path to file to read\", min_length=1)\n",
    "    max_lines: int = Field(\n",
    "        default=100, ge=1, le=1000, description=\"Maximum lines to read\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    \"\"\"Complete tool call structure\"\"\"\n",
    "\n",
    "    tool: str = Field(..., description=\"Tool name to call\")\n",
    "    args: Dict[str, Any] = Field(..., description=\"Tool arguments\")\n",
    "    reasoning: Optional[str] = Field(None, description=\"Why this tool is needed\")\n",
    "\n",
    "\n",
    "# Tool registry mapping\n",
    "TOOL_SCHEMAS = {\n",
    "    \"calculator\": CalculatorArgs,\n",
    "    \"web_search\": WebSearchArgs,\n",
    "    \"file_read\": FileReadArgs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63950d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 4: JSON Repair Utilities\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class JSONRepair:\n",
    "    \"\"\"Utilities for repairing common JSON formatting issues\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_json_from_text(text: str) -> str:\n",
    "        \"\"\"Extract JSON from text that may contain extra content\"\"\"\n",
    "        # Look for JSON-like patterns\n",
    "        patterns = [\n",
    "            r\"\\{[^{}]*\\}\",  # Simple object\n",
    "            r\"\\{.*?\\}\",  # Greedy object match\n",
    "            r\"```json\\s*(\\{.*?\\})\\s*```\",  # Markdown code block\n",
    "            r\"```\\s*(\\{.*?\\})\\s*```\",  # Code block without json tag\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text, re.DOTALL)\n",
    "            if matches:\n",
    "                return matches[0] if isinstance(matches[0], str) else matches[0]\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_common_issues(json_str: str) -> str:\n",
    "        \"\"\"Fix common JSON formatting issues\"\"\"\n",
    "        # Remove trailing commas\n",
    "        json_str = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", json_str)\n",
    "\n",
    "        # Fix unquoted keys (common in LLM outputs)\n",
    "        json_str = re.sub(r\"(\\w+):\", r'\"\\1\":', json_str)\n",
    "\n",
    "        # Fix single quotes to double quotes\n",
    "        json_str = json_str.replace(\"'\", '\"')\n",
    "\n",
    "        # Remove extra whitespace\n",
    "        json_str = re.sub(r\"\\s+\", \" \", json_str).strip()\n",
    "\n",
    "        # Ensure proper quotes around string values\n",
    "        json_str = re.sub(r':\\s*([^\",{\\[\\]}\\s]+)(?=\\s*[,}])', r': \"\\1\"', json_str)\n",
    "\n",
    "        return json_str\n",
    "\n",
    "    @staticmethod\n",
    "    def attempt_repair(broken_json: str) -> Optional[Dict]:\n",
    "        \"\"\"Attempt multiple repair strategies\"\"\"\n",
    "        repair_strategies = [\n",
    "            lambda x: x,  # Try as-is first\n",
    "            JSONRepair.extract_json_from_text,\n",
    "            JSONRepair.fix_common_issues,\n",
    "            lambda x: JSONRepair.fix_common_issues(\n",
    "                JSONRepair.extract_json_from_text(x)\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        for strategy in repair_strategies:\n",
    "            try:\n",
    "                repaired = strategy(broken_json)\n",
    "                return json.loads(repaired)\n",
    "            except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "                continue\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Validation and Retry Logic\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    \"\"\"Result of validation attempt\"\"\"\n",
    "\n",
    "    success: bool\n",
    "    data: Optional[Dict] = None\n",
    "    errors: List[str] = None\n",
    "    repaired: bool = False\n",
    "    attempts: int = 1\n",
    "\n",
    "\n",
    "class SchemaValidator:\n",
    "    \"\"\"Handles schema validation with retry and repair\"\"\"\n",
    "\n",
    "    def __init__(self, max_retries: int = 3, repair_enabled: bool = True):\n",
    "        self.max_retries = max_retries\n",
    "        self.repair_enabled = repair_enabled\n",
    "        self.repair_stats = {\"attempts\": 0, \"successes\": 0}\n",
    "\n",
    "    def validate_tool_call(\n",
    "        self, raw_output: str, allow_repair: bool = True\n",
    "    ) -> ValidationResult:\n",
    "        \"\"\"Validate and potentially repair tool call output\"\"\"\n",
    "        errors = []\n",
    "\n",
    "        for attempt in range(1, self.max_retries + 1):\n",
    "            try:\n",
    "                # Try direct JSON parsing first\n",
    "                if attempt == 1:\n",
    "                    data = json.loads(raw_output)\n",
    "                else:\n",
    "                    # Use repair on subsequent attempts\n",
    "                    if self.repair_enabled and allow_repair:\n",
    "                        self.repair_stats[\"attempts\"] += 1\n",
    "                        data = JSONRepair.attempt_repair(raw_output)\n",
    "                        if data is None:\n",
    "                            errors.append(f\"Attempt {attempt}: JSON repair failed\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        errors.append(f\"Attempt {attempt}: Repair disabled, skipping\")\n",
    "                        continue\n",
    "\n",
    "                # Validate against ToolCall schema\n",
    "                tool_call = ToolCall(**data)\n",
    "\n",
    "                # Validate specific tool args\n",
    "                if tool_call.tool in TOOL_SCHEMAS:\n",
    "                    tool_schema = TOOL_SCHEMAS[tool_call.tool]\n",
    "                    validated_args = tool_schema(**tool_call.args)\n",
    "                    tool_call.args = validated_args.dict()\n",
    "\n",
    "                # Success!\n",
    "                if attempt > 1:\n",
    "                    self.repair_stats[\"successes\"] += 1\n",
    "\n",
    "                return ValidationResult(\n",
    "                    success=True,\n",
    "                    data=tool_call.dict(),\n",
    "                    repaired=(attempt > 1),\n",
    "                    attempts=attempt,\n",
    "                )\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                errors.append(f\"Attempt {attempt}: JSON decode error: {str(e)}\")\n",
    "            except ValidationError as e:\n",
    "                errors.append(f\"Attempt {attempt}: Schema validation error: {str(e)}\")\n",
    "            except Exception as e:\n",
    "                errors.append(f\"Attempt {attempt}: Unexpected error: {str(e)}\")\n",
    "\n",
    "        return ValidationResult(success=False, errors=errors, attempts=self.max_retries)\n",
    "\n",
    "    def get_repair_success_rate(self) -> float:\n",
    "        \"\"\"Get current repair success rate\"\"\"\n",
    "        if self.repair_stats[\"attempts\"] == 0:\n",
    "            return 0.0\n",
    "        return self.repair_stats[\"successes\"] / self.repair_stats[\"attempts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: LLM Integration with Retry\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class LLMWithRetry:\n",
    "    \"\"\"LLM adapter with built-in validation and retry\"\"\"\n",
    "\n",
    "    def __init__(self, model_id: str = \"Qwen/Qwen2.5-7B-Instruct\"):\n",
    "        print(f\"Loading model: {model_id}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            load_in_4bit=True,  # Low VRAM option\n",
    "        )\n",
    "        self.validator = SchemaValidator(max_retries=3)\n",
    "\n",
    "        # Add padding token if missing\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def generate_tool_call(\n",
    "        self, user_query: str, available_tools: List[str]\n",
    "    ) -> ValidationResult:\n",
    "        \"\"\"Generate and validate tool call with automatic retry\"\"\"\n",
    "\n",
    "        # Create prompt for tool calling\n",
    "        tools_desc = \"\\n\".join(\n",
    "            [f\"- {tool}: {TOOL_SCHEMAS[tool].__doc__}\" for tool in available_tools]\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"You are a helpful assistant that can call tools. Given a user query, output a JSON object with tool name and arguments.\n",
    "\n",
    "Available tools:\n",
    "{tools_desc}\n",
    "\n",
    "Output format (JSON only):\n",
    "{{\"tool\": \"tool_name\", \"args\": {{\"param\": \"value\"}}, \"reasoning\": \"why this tool\"}}\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "JSON response:\"\"\"\n",
    "\n",
    "        max_attempts = 3\n",
    "        for attempt in range(1, max_attempts + 1):\n",
    "            try:\n",
    "                # Generate response\n",
    "                inputs = self.tokenizer(\n",
    "                    prompt, return_tensors=\"pt\", truncation=True, max_length=2048\n",
    "                )\n",
    "                inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=200,\n",
    "                        temperature=0.3,\n",
    "                        do_sample=True,\n",
    "                        pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    )\n",
    "\n",
    "                # Decode response\n",
    "                response = self.tokenizer.decode(\n",
    "                    outputs[0][inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True\n",
    "                )\n",
    "                response = response.strip()\n",
    "\n",
    "                logger.info(f\"Attempt {attempt} raw output: {response}\")\n",
    "\n",
    "                # Validate with repair\n",
    "                result = self.validator.validate_tool_call(response, allow_repair=True)\n",
    "\n",
    "                if result.success:\n",
    "                    logger.info(f\"âœ… Validation successful on attempt {attempt}\")\n",
    "                    return result\n",
    "                else:\n",
    "                    logger.warning(f\"âŒ Attempt {attempt} failed: {result.errors}\")\n",
    "                    if attempt < max_attempts:\n",
    "                        # Modify prompt for retry\n",
    "                        prompt += f\"\\n\\nPrevious attempt failed. Please output valid JSON only:\"\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Generation error on attempt {attempt}: {str(e)}\")\n",
    "\n",
    "        # All attempts failed\n",
    "        return ValidationResult(\n",
    "            success=False,\n",
    "            errors=[f\"All {max_attempts} generation attempts failed\"],\n",
    "            attempts=max_attempts,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Demo Functions and Tool Execution\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def execute_tool_call(tool_call_data: Dict) -> Dict:\n",
    "    \"\"\"Execute validated tool call (mock implementation)\"\"\"\n",
    "    tool_name = tool_call_data[\"tool\"]\n",
    "    args = tool_call_data[\"args\"]\n",
    "\n",
    "    if tool_name == \"calculator\":\n",
    "        try:\n",
    "            # Safe eval for demo (real implementation should use ast.literal_eval)\n",
    "            result = eval(args[\"expression\"])\n",
    "            return {\"status\": \"success\", \"result\": result}\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "    elif tool_name == \"web_search\":\n",
    "        # Mock search results\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"results\": [\n",
    "                {\"title\": f\"æœå°‹çµæœï¼š{args['query']}\", \"url\": \"https://example.com\"},\n",
    "                {\"title\": f\"ç›¸é—œæ–‡ç« ï¼š{args['query']}\", \"url\": \"https://example2.com\"},\n",
    "            ][: args.get(\"max_results\", 5)],\n",
    "        }\n",
    "\n",
    "    elif tool_name == \"file_read\":\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"content\": f\"Mock file content from {args['filepath']} (max {args.get('max_lines', 100)} lines)\",\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error\": f\"Unknown tool: {tool_name}\"}\n",
    "\n",
    "\n",
    "def demo_query_with_retry(llm: LLMWithRetry, query: str, tools: List[str]):\n",
    "    \"\"\"Demo complete flow: query -> generate -> validate -> execute\"\"\"\n",
    "    print(f\"\\nğŸ” Query: {query}\")\n",
    "    print(f\"ğŸ“‹ Available tools: {tools}\")\n",
    "\n",
    "    # Generate and validate tool call\n",
    "    result = llm.generate_tool_call(query, tools)\n",
    "\n",
    "    if result.success:\n",
    "        print(\n",
    "            f\"âœ… Validation successful (attempts: {result.attempts}, repaired: {result.repaired})\"\n",
    "        )\n",
    "        print(f\"ğŸ“ Tool call: {json.dumps(result.data, ensure_ascii=False, indent=2)}\")\n",
    "\n",
    "        # Execute tool\n",
    "        execution_result = execute_tool_call(result.data)\n",
    "        print(\n",
    "            f\"ğŸ”§ Execution result: {json.dumps(execution_result, ensure_ascii=False, indent=2)}\"\n",
    "        )\n",
    "\n",
    "        return result.data, execution_result\n",
    "    else:\n",
    "        print(f\"âŒ Validation failed after {result.attempts} attempts\")\n",
    "        for error in result.errors:\n",
    "            print(f\"   - {error}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 8: MVP Test Cases\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize LLM (low VRAM settings)\n",
    "print(\"ğŸš€ Initializing LLM with retry capabilities...\")\n",
    "llm = LLMWithRetry(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    (\"è¨ˆç®— 25 * 4 + 10 çš„çµæœ\", [\"calculator\"]),\n",
    "    (\"æœå°‹é—œæ–¼ RAG æª¢ç´¢å¢å¼·ç”Ÿæˆçš„è³‡æ–™\", [\"web_search\"]),\n",
    "    (\"è®€å– config.yaml æª”æ¡ˆçš„å‰ 50 è¡Œ\", [\"file_read\"]),\n",
    "    (\"æˆ‘æƒ³è¦è¨ˆç®— (100 + 200) / 3\", [\"calculator\", \"web_search\"]),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for query, tools in test_queries:\n",
    "    tool_call, execution = demo_query_with_retry(llm, query, tools)\n",
    "    results.append(\n",
    "        {\n",
    "            \"query\": query,\n",
    "            \"success\": tool_call is not None,\n",
    "            \"tool_call\": tool_call,\n",
    "            \"execution\": execution,\n",
    "        }\n",
    "    )\n",
    "    time.sleep(1)  # Brief pause between requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: JSON Repair Testing\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸ”§ Testing JSON repair capabilities...\")\n",
    "\n",
    "# Test cases with deliberately broken JSON\n",
    "broken_json_examples = [\n",
    "    '{\"tool\": \"calculator\", \"args\": {\"expression\": \"2+3\"}}',  # Valid (control)\n",
    "    '{tool: \"calculator\", args: {expression: \"2+3\"}}',  # Unquoted keys\n",
    "    \"{'tool': 'calculator', 'args': {'expression': '2+3'}}\",  # Single quotes\n",
    "    '{\"tool\": \"calculator\", \"args\": {\"expression\": \"2+3\",},}',  # Trailing commas\n",
    "    '```json\\n{\"tool\": \"web_search\", \"args\": {\"query\": \"test\"}}\\n```',  # Markdown\n",
    "    '{\"tool\": \"calculator\", \"args\": {\"expression\": 2+3}}',  # Unquoted value\n",
    "]\n",
    "\n",
    "validator = SchemaValidator()\n",
    "repair_test_results = []\n",
    "\n",
    "for i, broken_json in enumerate(broken_json_examples):\n",
    "    print(f\"\\nğŸ“ Test case {i+1}: {broken_json}\")\n",
    "    result = validator.validate_tool_call(broken_json)\n",
    "    repair_test_results.append(\n",
    "        {\n",
    "            \"input\": broken_json,\n",
    "            \"success\": result.success,\n",
    "            \"repaired\": result.repaired,\n",
    "            \"attempts\": result.attempts,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        print(f\"   âœ… Success (repaired: {result.repaired})\")\n",
    "        print(f\"   ğŸ“‹ Parsed: {json.dumps(result.data, ensure_ascii=False)}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"   âŒ Failed: {result.errors[-1] if result.errors else 'Unknown error'}\"\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 10: Smoke Test & Success Rate Analysis\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate overall success rates\n",
    "total_tests = len(results) + len(repair_test_results)\n",
    "successful_tests = sum(1 for r in results if r[\"success\"]) + sum(\n",
    "    1 for r in repair_test_results if r[\"success\"]\n",
    ")\n",
    "success_rate = successful_tests / total_tests if total_tests > 0 else 0\n",
    "\n",
    "repair_success_rate = llm.validator.get_repair_success_rate()\n",
    "\n",
    "print(f\"\\nğŸ“Š SMOKE TEST RESULTS\")\n",
    "print(f\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(f\"Overall success rate: {success_rate:.1%} ({successful_tests}/{total_tests})\")\n",
    "print(f\"JSON repair success rate: {repair_success_rate:.1%}\")\n",
    "print(\n",
    "    f\"Tool execution tests: {len([r for r in results if r['success']])}/{len(results)} passed\"\n",
    ")\n",
    "print(\n",
    "    f\"JSON repair tests: {len([r for r in repair_test_results if r['success']])}/{len(repair_test_results)} passed\"\n",
    ")\n",
    "\n",
    "# Detailed repair statistics\n",
    "repair_stats = llm.validator.repair_stats\n",
    "print(f\"\\nğŸ”§ Repair Statistics:\")\n",
    "print(f\"   Repair attempts: {repair_stats['attempts']}\")\n",
    "print(f\"   Repair successes: {repair_stats['successes']}\")\n",
    "\n",
    "# Assert minimum success rate for smoke test\n",
    "assert success_rate >= 0.7, f\"Success rate {success_rate:.1%} below minimum 70%\"\n",
    "assert (\n",
    "    len([r for r in results if r[\"success\"]]) >= 2\n",
    "), \"At least 2 tool executions should succeed\"\n",
    "\n",
    "print(f\"\\nâœ… SMOKE TEST PASSED!\")\n",
    "print(f\"   - Schema validation working\")\n",
    "print(f\"   - JSON repair functional\")\n",
    "print(f\"   - Tool execution pipeline complete\")\n",
    "print(f\"   - Success rate: {success_rate:.1%} â‰¥ 70% âœ“\")\n",
    "\n",
    "# ============================================================================\n",
    "# When to use this notebook:\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "ğŸ“š ä½¿ç”¨æ™‚æ©Ÿ (When to use this):\n",
    "\n",
    "1. **LLM çµæ§‹åŒ–è¼¸å‡ºé©—è­‰**: ç•¶éœ€è¦ç¢ºä¿ LLM è¼¸å‡ºç¬¦åˆç‰¹å®š JSON schema æ™‚\n",
    "2. **å·¥å…·èª¿ç”¨å®¹éŒ¯**: åœ¨ ReAct/Function-calling ä¸­éœ€è¦ç©©å®šçš„å·¥å…·èª¿ç”¨æˆåŠŸç‡\n",
    "3. **JSON æ ¼å¼ä¿®å¾©**: è™•ç† LLM å¸¸è¦‹çš„ JSON æ ¼å¼éŒ¯èª¤ï¼ˆç¼ºå¼•è™Ÿã€é€—è™Ÿç­‰ï¼‰\n",
    "4. **ç”Ÿç”¢ç’°å¢ƒç©©å®šæ€§**: éœ€è¦ 90%+ æˆåŠŸç‡çš„çµæ§‹åŒ–è¼¸å‡ºå ´æ™¯\n",
    "5. **å¤šèªè¨€ LLM é©é…**: ä¸­æ–‡ LLM åœ¨ JSON è¼¸å‡ºä¸Šçš„ç‰¹æ®Šè™•ç†éœ€æ±‚\n",
    "\n",
    "Key benefits:\n",
    "- è‡ªå‹• JSON ä¿®å¾©èˆ‡é‡è©¦æ©Ÿåˆ¶\n",
    "- Pydantic schema é©—è­‰èˆ‡å‹åˆ¥å®‰å…¨\n",
    "- è©³ç´°çš„éŒ¯èª¤è¿½è¹¤èˆ‡çµ±è¨ˆ\n",
    "- ä½ VRAM å‹å–„çš„å¯¦ä½œ\n",
    "- 90%+ å·¥å…·èª¿ç”¨æˆåŠŸç‡ç›®æ¨™\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    tool: str = Field(..., description=\"Tool name to call\")\n",
    "    args: Dict[str, Any] = Field(..., description=\"Tool arguments\")\n",
    "    reasoning: Optional[str] = Field(None, description=\"Why this tool is needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
