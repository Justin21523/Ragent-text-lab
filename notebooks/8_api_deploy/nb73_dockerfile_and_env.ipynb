{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d847c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Stage 8 - API & Deploy: nb73_dockerfile_and_env.ipynb\n",
    "# Topic: Docker containerization + environment management + CORS + production ready\n",
    "# =============================================================================\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (複製到每本 notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Environment Variables Design & .env.example\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_env_example():\n",
    "    \"\"\"Create .env.example template with all required environment variables\"\"\"\n",
    "\n",
    "    env_template = \"\"\"# ragent-text-lab Environment Configuration\n",
    "# ===========================================\n",
    "\n",
    "# AI Cache & Model Configuration\n",
    "AI_CACHE_ROOT=/mnt/ai/cache\n",
    "MODEL_ID=Qwen/Qwen2.5-7B-Instruct\n",
    "BACKEND=transformers\n",
    "DEVICE_MAP=auto\n",
    "TORCH_DTYPE=auto\n",
    "QUANTIZATION=none\n",
    "\n",
    "# RAG Configuration\n",
    "EMBEDDING_MODEL=BAAI/bge-m3\n",
    "RERANKER_MODEL=BAAI/bge-reranker-base\n",
    "INDEX_PATH=indices/general.faiss\n",
    "RAG_CHUNK_SIZE=800\n",
    "RAG_OVERLAP=80\n",
    "\n",
    "# API Server Configuration\n",
    "API_HOST=0.0.0.0\n",
    "API_PORT=8000\n",
    "API_WORKERS=1\n",
    "DEBUG=false\n",
    "\n",
    "# CORS Configuration\n",
    "CORS_ORIGINS=*\n",
    "CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS\n",
    "CORS_HEADERS=*\n",
    "CORS_CREDENTIALS=true\n",
    "\n",
    "# Rate Limiting\n",
    "RATE_LIMIT_REQUESTS=100\n",
    "RATE_LIMIT_WINDOW=3600\n",
    "RATE_LIMIT_STORAGE=memory\n",
    "\n",
    "# Security Configuration\n",
    "MAX_PROMPT_LENGTH=4096\n",
    "MAX_RESPONSE_LENGTH=2048\n",
    "SAFETY_CHECK=true\n",
    "ALLOWED_HOSTS=*\n",
    "\n",
    "# Tool Configuration\n",
    "WEB_SEARCH_ENABLED=true\n",
    "CALCULATOR_ENABLED=true\n",
    "FILE_LOOKUP_ENABLED=true\n",
    "FILE_LOOKUP_WHITELIST=data/,outs/\n",
    "\n",
    "# Logging Configuration\n",
    "LOG_LEVEL=info\n",
    "LOG_FORMAT=json\n",
    "LOG_FILE=logs/ragent.log\n",
    "\n",
    "# Database Configuration (if needed)\n",
    "# DATABASE_URL=sqlite:///./ragent.db\n",
    "\n",
    "# External Services (optional)\n",
    "# OPENAI_API_KEY=your_openai_key_here\n",
    "# ANTHROPIC_API_KEY=your_anthropic_key_here\n",
    "\"\"\"\n",
    "\n",
    "    # Write to project root\n",
    "    env_path = pathlib.Path(\".env.example\")\n",
    "    env_path.write_text(env_template.strip(), encoding=\"utf-8\")\n",
    "    print(\n",
    "        f\"✅ Created {env_path} with {len(env_template.split('='))} configuration items\"\n",
    "    )\n",
    "\n",
    "    return env_template\n",
    "\n",
    "\n",
    "# Create environment template\n",
    "env_content = create_env_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Dockerfile Multi-stage Build\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_dockerfile():\n",
    "    \"\"\"Create optimized multi-stage Dockerfile for production deployment\"\"\"\n",
    "\n",
    "    dockerfile_content = \"\"\"# ragent-text-lab Dockerfile\n",
    "# Multi-stage build for optimized production image\n",
    "\n",
    "# ===========================================\n",
    "# Stage 1: Base Python Environment\n",
    "# ===========================================\n",
    "FROM python:3.11-slim as base\n",
    "\n",
    "# Set environment variables\n",
    "ENV PYTHONUNBUFFERED=1 \\\n",
    "    PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PIP_NO_CACHE_DIR=1 \\\n",
    "    PIP_DISABLE_PIP_VERSION_CHECK=1\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    gcc \\\n",
    "    g++ \\\n",
    "    git \\\n",
    "    curl \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Create app user for security\n",
    "RUN useradd --create-home --shell /bin/bash app\n",
    "\n",
    "# ===========================================\n",
    "# Stage 2: Dependencies Installation\n",
    "# ===========================================\n",
    "FROM base as deps\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements first for better layer caching\n",
    "COPY requirements.txt requirements-dev.txt ./\n",
    "\n",
    "# Install Python dependencies\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# ===========================================\n",
    "# Stage 3: Application Build\n",
    "# ===========================================\n",
    "FROM deps as app\n",
    "\n",
    "# Copy application code\n",
    "COPY --chown=app:app . .\n",
    "\n",
    "# Create necessary directories\n",
    "RUN mkdir -p logs outs indices data && \\\n",
    "    chown -R app:app /app\n",
    "\n",
    "# Switch to app user\n",
    "USER app\n",
    "\n",
    "# Set cache directory\n",
    "ENV AI_CACHE_ROOT=/app/cache\n",
    "RUN mkdir -p /app/cache/{hf,torch}\n",
    "\n",
    "# ===========================================\n",
    "# Stage 4: Production Image\n",
    "# ===========================================\n",
    "FROM app as production\n",
    "\n",
    "# Expose API port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n",
    "    CMD curl -f http://localhost:8000/health || exit 1\n",
    "\n",
    "# Default command\n",
    "CMD [\"python\", \"-m\", \"uvicorn\", \"apps.api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\"\"\"\n",
    "\n",
    "    dockerfile_path = pathlib.Path(\"Dockerfile\")\n",
    "    dockerfile_path.write_text(dockerfile_content.strip(), encoding=\"utf-8\")\n",
    "    print(f\"✅ Created {dockerfile_path}\")\n",
    "\n",
    "    return dockerfile_content\n",
    "\n",
    "\n",
    "# Create Dockerfile\n",
    "dockerfile_content = create_dockerfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: docker-compose.yml Complete Service Orchestration\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_docker_compose():\n",
    "    \"\"\"Create docker-compose.yml for complete service orchestration\"\"\"\n",
    "\n",
    "    compose_content = \"\"\"# ragent-text-lab Docker Compose Configuration\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # ===========================================\n",
    "  # Main API Service\n",
    "  # ===========================================\n",
    "  ragent-api:\n",
    "    build:\n",
    "      context: .\n",
    "      target: production\n",
    "    container_name: ragent-api\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"${API_PORT:-8000}:8000\"\n",
    "    environment:\n",
    "      - AI_CACHE_ROOT=/app/cache\n",
    "      - MODEL_ID=${MODEL_ID:-Qwen/Qwen2.5-7B-Instruct}\n",
    "      - BACKEND=${BACKEND:-transformers}\n",
    "      - API_HOST=0.0.0.0\n",
    "      - API_PORT=8000\n",
    "      - DEBUG=${DEBUG:-false}\n",
    "      - LOG_LEVEL=${LOG_LEVEL:-info}\n",
    "      - CORS_ORIGINS=${CORS_ORIGINS:-*}\n",
    "      - RATE_LIMIT_REQUESTS=${RATE_LIMIT_REQUESTS:-100}\n",
    "      - MAX_PROMPT_LENGTH=${MAX_PROMPT_LENGTH:-4096}\n",
    "      - SAFETY_CHECK=${SAFETY_CHECK:-true}\n",
    "    volumes:\n",
    "      - ./data:/app/data:ro\n",
    "      - ./outs:/app/outs\n",
    "      - ./indices:/app/indices\n",
    "      - ./logs:/app/logs\n",
    "      - ai-cache:/app/cache\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    depends_on:\n",
    "      - redis\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 8G\n",
    "        reservations:\n",
    "          memory: 4G\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 40s\n",
    "\n",
    "  # ===========================================\n",
    "  # Gradio UI Service\n",
    "  # ===========================================\n",
    "  ragent-ui:\n",
    "    build:\n",
    "      context: .\n",
    "      target: production\n",
    "    container_name: ragent-ui\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"${UI_PORT:-7860}:7860\"\n",
    "    environment:\n",
    "      - API_URL=http://ragent-api:8000\n",
    "      - GRADIO_SERVER_NAME=0.0.0.0\n",
    "      - GRADIO_SERVER_PORT=7860\n",
    "    command: [\"python\", \"apps/gradio_app/app.py\"]\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    depends_on:\n",
    "      - ragent-api\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 2G\n",
    "\n",
    "  # ===========================================\n",
    "  # Redis for Rate Limiting & Caching\n",
    "  # ===========================================\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    container_name: ragent-redis\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis-data:/data\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    command: redis-server --appendonly yes\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 512M\n",
    "\n",
    "  # ===========================================\n",
    "  # Nginx Reverse Proxy (Optional)\n",
    "  # ===========================================\n",
    "  nginx:\n",
    "    image: nginx:alpine\n",
    "    container_name: ragent-nginx\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "      - \"443:443\"\n",
    "    volumes:\n",
    "      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n",
    "      - ./ssl:/etc/nginx/ssl:ro\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    depends_on:\n",
    "      - ragent-api\n",
    "      - ragent-ui\n",
    "    profiles:\n",
    "      - production\n",
    "\n",
    "# ===========================================\n",
    "# Named Volumes\n",
    "# ===========================================\n",
    "volumes:\n",
    "  ai-cache:\n",
    "    driver: local\n",
    "  redis-data:\n",
    "    driver: local\n",
    "\n",
    "# ===========================================\n",
    "# Networks\n",
    "# ===========================================\n",
    "networks:\n",
    "  ragent-network:\n",
    "    driver: bridge\n",
    "    ipam:\n",
    "      config:\n",
    "        - subnet: 172.20.0.0/16\n",
    "\"\"\"\n",
    "\n",
    "    compose_path = pathlib.Path(\"docker-compose.yml\")\n",
    "    compose_path.write_text(compose_content.strip(), encoding=\"utf-8\")\n",
    "    print(f\"✅ Created {compose_path}\")\n",
    "\n",
    "    return compose_content\n",
    "\n",
    "\n",
    "# Create docker-compose configuration\n",
    "compose_content = create_docker_compose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ff3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: CORS & Security Middleware Enhancement\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_security_middleware():\n",
    "    \"\"\"Enhanced security middleware for production deployment\"\"\"\n",
    "\n",
    "    middleware_code = '''from fastapi import FastAPI, Request, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.middleware.trustedhost import TrustedHostMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "import time\n",
    "import asyncio\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===========================================\n",
    "# Rate Limiting Middleware\n",
    "# ===========================================\n",
    "class RateLimitMiddleware:\n",
    "    def __init__(self, requests_per_window: int = 100, window_seconds: int = 3600):\n",
    "        self.requests_per_window = requests_per_window\n",
    "        self.window_seconds = window_seconds\n",
    "        self.client_requests = defaultdict(list)\n",
    "\n",
    "    async def __call__(self, request: Request, call_next):\n",
    "        client_ip = request.client.host\n",
    "        now = time.time()\n",
    "\n",
    "        # Clean old requests\n",
    "        self.client_requests[client_ip] = [\n",
    "            req_time for req_time in self.client_requests[client_ip]\n",
    "            if now - req_time < self.window_seconds\n",
    "        ]\n",
    "\n",
    "        # Check rate limit\n",
    "        if len(self.client_requests[client_ip]) >= self.requests_per_window:\n",
    "            return JSONResponse(\n",
    "                status_code=429,\n",
    "                content={\"error\": \"Rate limit exceeded\", \"retry_after\": self.window_seconds}\n",
    "            )\n",
    "\n",
    "        # Record request\n",
    "        self.client_requests[client_ip].append(now)\n",
    "\n",
    "        response = await call_next(request)\n",
    "        return response\n",
    "\n",
    "# ===========================================\n",
    "# Security Headers Middleware\n",
    "# ===========================================\n",
    "class SecurityHeadersMiddleware:\n",
    "    async def __call__(self, request: Request, call_next):\n",
    "        response = await call_next(request)\n",
    "\n",
    "        # Security headers\n",
    "        response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n",
    "        response.headers[\"X-Frame-Options\"] = \"DENY\"\n",
    "        response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n",
    "        response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains\"\n",
    "        response.headers[\"Referrer-Policy\"] = \"strict-origin-when-cross-origin\"\n",
    "        response.headers[\"Content-Security-Policy\"] = \"default-src 'self'\"\n",
    "\n",
    "        return response\n",
    "\n",
    "# ===========================================\n",
    "# Setup Security for FastAPI App\n",
    "# ===========================================\n",
    "def setup_security(app: FastAPI):\n",
    "    \"\"\"Configure comprehensive security for production\"\"\"\n",
    "\n",
    "    # CORS Configuration\n",
    "    cors_origins = os.getenv(\"CORS_ORIGINS\", \"*\").split(\",\")\n",
    "    if cors_origins == [\"*\"]:\n",
    "        logger.warning(\"CORS允許所有來源 - 生產環境建議限制\")\n",
    "\n",
    "    app.add_middleware(\n",
    "        CORSMiddleware,\n",
    "        allow_origins=cors_origins,\n",
    "        allow_credentials=True,\n",
    "        allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n",
    "        allow_headers=[\"*\"],\n",
    "    )\n",
    "\n",
    "    # Trusted Host Middleware\n",
    "    allowed_hosts = os.getenv(\"ALLOWED_HOSTS\", \"*\").split(\",\")\n",
    "    if allowed_hosts != [\"*\"]:\n",
    "        app.add_middleware(\n",
    "            TrustedHostMiddleware,\n",
    "            allowed_hosts=allowed_hosts\n",
    "        )\n",
    "\n",
    "    # Rate Limiting\n",
    "    rate_limit_requests = int(os.getenv(\"RATE_LIMIT_REQUESTS\", \"100\"))\n",
    "    rate_limit_window = int(os.getenv(\"RATE_LIMIT_WINDOW\", \"3600\"))\n",
    "\n",
    "    app.middleware(\"http\")(\n",
    "        RateLimitMiddleware(rate_limit_requests, rate_limit_window)\n",
    "    )\n",
    "\n",
    "    # Security Headers\n",
    "    app.middleware(\"http\")(SecurityHeadersMiddleware())\n",
    "\n",
    "    logger.info(f\"🔒 安全設定完成: CORS={len(cors_origins)} origins, Rate={rate_limit_requests}/hr\")\n",
    "\n",
    "    return app\n",
    "\n",
    "# ===========================================\n",
    "# Health Check Endpoint\n",
    "# ===========================================\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Comprehensive health check for container orchestration\"\"\"\n",
    "    import psutil\n",
    "    import torch\n",
    "\n",
    "    try:\n",
    "        # System metrics\n",
    "        cpu_percent = psutil.cpu_percent(interval=1)\n",
    "        memory = psutil.virtual_memory()\n",
    "        disk = psutil.disk_usage('/')\n",
    "\n",
    "        # GPU check\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        gpu_memory = None\n",
    "        if gpu_available:\n",
    "            gpu_memory = {\n",
    "                \"allocated\": torch.cuda.memory_allocated(),\n",
    "                \"cached\": torch.cuda.memory_reserved(),\n",
    "                \"total\": torch.cuda.get_device_properties(0).total_memory\n",
    "            }\n",
    "\n",
    "        health_data = {\n",
    "            \"status\": \"healthy\",\n",
    "            \"timestamp\": time.time(),\n",
    "            \"system\": {\n",
    "                \"cpu_percent\": cpu_percent,\n",
    "                \"memory_percent\": memory.percent,\n",
    "                \"disk_percent\": disk.percent,\n",
    "                \"gpu_available\": gpu_available,\n",
    "                \"gpu_memory\": gpu_memory\n",
    "            },\n",
    "            \"services\": {\n",
    "                \"api\": \"running\",\n",
    "                \"model_loaded\": hasattr(app.state, 'llm_adapter'),\n",
    "                \"rag_index\": os.path.exists(\"indices/general.faiss\")\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return health_data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Health check failed: {e}\")\n",
    "        return JSONResponse(\n",
    "            status_code=503,\n",
    "            content={\"status\": \"unhealthy\", \"error\": str(e)}\n",
    "        )\n",
    "\n",
    "# ===========================================\n",
    "# Metrics Endpoint\n",
    "# ===========================================\n",
    "@app.get(\"/metrics\")\n",
    "async def metrics():\n",
    "    \"\"\"Prometheus-compatible metrics endpoint\"\"\"\n",
    "\n",
    "    metrics_text = f\"\"\"# HELP ragent_requests_total Total requests processed\n",
    "# TYPE ragent_requests_total counter\n",
    "ragent_requests_total {{method=\"GET\"}} {getattr(app.state, 'get_requests', 0)}\n",
    "ragent_requests_total {{method=\"POST\"}} {getattr(app.state, 'post_requests', 0)}\n",
    "\n",
    "# HELP ragent_response_duration_seconds Response duration\n",
    "# TYPE ragent_response_duration_seconds histogram\n",
    "ragent_response_duration_seconds_bucket {{le=\"0.1\"}} {getattr(app.state, 'fast_responses', 0)}\n",
    "ragent_response_duration_seconds_bucket {{le=\"1.0\"}} {getattr(app.state, 'medium_responses', 0)}\n",
    "ragent_response_duration_seconds_bucket {{le=\"10.0\"}} {getattr(app.state, 'slow_responses', 0)}\n",
    "\n",
    "# HELP ragent_model_inference_duration_seconds Model inference time\n",
    "# TYPE ragent_model_inference_duration_seconds histogram\n",
    "ragent_model_inference_duration_seconds_sum {getattr(app.state, 'total_inference_time', 0)}\n",
    "ragent_model_inference_duration_seconds_count {getattr(app.state, 'inference_count', 0)}\n",
    "\"\"\"\n",
    "\n",
    "    return Response(content=metrics_text, media_type=\"text/plain\")\n",
    "'''\n",
    "\n",
    "    # Write middleware to shared_utils\n",
    "    middleware_path = pathlib.Path(\"shared_utils/api/security.py\")\n",
    "    middleware_path.parent.mkdir(exist_ok=True)\n",
    "    middleware_path.write_text(middleware_code, encoding=\"utf-8\")\n",
    "    print(f\"✅ Created security middleware at {middleware_path}\")\n",
    "\n",
    "    return middleware_code\n",
    "\n",
    "\n",
    "# Create security middleware\n",
    "security_code = create_security_middleware()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Startup Scripts & Environment Validation\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_startup_scripts():\n",
    "    \"\"\"Create startup and validation scripts for deployment\"\"\"\n",
    "\n",
    "    # Startup script\n",
    "    startup_script = \"\"\"#!/bin/bash\n",
    "# ragent-text-lab startup script\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"🚀 Starting ragent-text-lab deployment...\"\n",
    "\n",
    "# ===========================================\n",
    "# Environment Validation\n",
    "# ===========================================\n",
    "validate_env() {\n",
    "    echo \"📋 Validating environment variables...\"\n",
    "\n",
    "    required_vars=(\n",
    "        \"MODEL_ID\"\n",
    "        \"BACKEND\"\n",
    "        \"API_PORT\"\n",
    "        \"AI_CACHE_ROOT\"\n",
    "    )\n",
    "\n",
    "    for var in \"${required_vars[@]}\"; do\n",
    "        if [[ -z \"${!var}\" ]]; then\n",
    "            echo \"❌ Required environment variable $var is not set\"\n",
    "            exit 1\n",
    "        fi\n",
    "    done\n",
    "\n",
    "    echo \"✅ Environment validation passed\"\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Docker Setup\n",
    "# ===========================================\n",
    "setup_docker() {\n",
    "    echo \"🐳 Setting up Docker environment...\"\n",
    "\n",
    "    # Create necessary directories\n",
    "    mkdir -p data outs indices logs\n",
    "\n",
    "    # Set permissions\n",
    "    chmod 755 data outs indices logs\n",
    "\n",
    "    echo \"✅ Docker setup completed\"\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Model Download\n",
    "# ===========================================\n",
    "download_models() {\n",
    "    echo \"📥 Downloading required models...\"\n",
    "\n",
    "    python3 -c \"\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download LLM tokenizer (lightweight check)\n",
    "model_id = os.getenv('MODEL_ID', 'Qwen/Qwen2.5-7B-Instruct')\n",
    "print(f'Checking {model_id}...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "print(f'✅ {model_id} tokenizer ready')\n",
    "\n",
    "# Download embedding model\n",
    "embed_model = os.getenv('EMBEDDING_MODEL', 'BAAI/bge-m3')\n",
    "print(f'Downloading {embed_model}...')\n",
    "embedder = SentenceTransformer(embed_model)\n",
    "print(f'✅ {embed_model} ready')\n",
    "\n",
    "print('🎯 All models downloaded successfully')\n",
    "\"\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Health Check\n",
    "# ===========================================\n",
    "health_check() {\n",
    "    echo \"🔍 Running health checks...\"\n",
    "\n",
    "    # Wait for service to start\n",
    "    sleep 10\n",
    "\n",
    "    # Check API health\n",
    "    if curl -f http://localhost:${API_PORT:-8000}/health > /dev/null 2>&1; then\n",
    "        echo \"✅ API health check passed\"\n",
    "    else\n",
    "        echo \"❌ API health check failed\"\n",
    "        return 1\n",
    "    fi\n",
    "\n",
    "    # Check model loading\n",
    "    if curl -f http://localhost:${API_PORT:-8000}/v1/models > /dev/null 2>&1; then\n",
    "        echo \"✅ Model endpoint accessible\"\n",
    "    else\n",
    "        echo \"⚠️  Model endpoint not ready (may still be loading)\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Main Execution\n",
    "# ===========================================\n",
    "main() {\n",
    "    validate_env\n",
    "    setup_docker\n",
    "\n",
    "    if [[ \"${DOWNLOAD_MODELS:-true}\" == \"true\" ]]; then\n",
    "        download_models\n",
    "    fi\n",
    "\n",
    "    echo \"🚀 Starting services with docker-compose...\"\n",
    "    docker-compose up -d\n",
    "\n",
    "    health_check\n",
    "\n",
    "    echo \"🎉 ragent-text-lab deployment completed!\"\n",
    "    echo \"📊 API: http://localhost:${API_PORT:-8000}\"\n",
    "    echo \"🎨 UI: http://localhost:${UI_PORT:-7860}\"\n",
    "    echo \"📈 Health: http://localhost:${API_PORT:-8000}/health\"\n",
    "}\n",
    "\n",
    "# Run main function\n",
    "main \"$@\"\n",
    "\"\"\"\n",
    "\n",
    "    startup_path = pathlib.Path(\"scripts/startup.sh\")\n",
    "    startup_path.parent.mkdir(exist_ok=True)\n",
    "    startup_path.write_text(startup_script, encoding=\"utf-8\")\n",
    "    startup_path.chmod(0o755)\n",
    "    print(f\"✅ Created startup script at {startup_path}\")\n",
    "\n",
    "    # Environment validation script\n",
    "    validate_script = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ragent-text-lab environment validation script\n",
    "Checks all dependencies and configurations before deployment\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import subprocess\n",
    "import pathlib\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class EnvironmentValidator:\n",
    "    def __init__(self):\n",
    "        self.errors = []\n",
    "        self.warnings = []\n",
    "        self.success = []\n",
    "\n",
    "    def check_python_version(self) -> bool:\n",
    "        \"\"\"Check Python version compatibility\"\"\"\n",
    "        version = sys.version_info\n",
    "        if version.major == 3 and version.minor >= 8:\n",
    "            self.success.append(f\"✅ Python {version.major}.{version.minor}.{version.micro}\")\n",
    "            return True\n",
    "        else:\n",
    "            self.errors.append(f\"❌ Python {version.major}.{version.minor} not supported (需要 ≥ 3.8)\")\n",
    "            return False\n",
    "\n",
    "    def check_required_packages(self) -> bool:\n",
    "        \"\"\"Check required Python packages\"\"\"\n",
    "        required_packages = [\n",
    "            \"torch\", \"transformers\", \"sentence_transformers\",\n",
    "            \"faiss\", \"fastapi\", \"uvicorn\", \"gradio\",\n",
    "            \"pydantic\", \"opencc\", \"trafilatura\"\n",
    "        ]\n",
    "\n",
    "        missing = []\n",
    "        for package in required_packages:\n",
    "            try:\n",
    "                importlib.import_module(package.replace(\"-\", \"_\"))\n",
    "                self.success.append(f\"✅ {package}\")\n",
    "            except ImportError:\n",
    "                missing.append(package)\n",
    "\n",
    "        if missing:\n",
    "            self.errors.append(f\"❌ Missing packages: {', '.join(missing)}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def check_environment_variables(self) -> bool:\n",
    "        \"\"\"Check required environment variables\"\"\"\n",
    "        required_vars = {\n",
    "            \"MODEL_ID\": \"LLM model identifier\",\n",
    "            \"BACKEND\": \"LLM backend (transformers/llama_cpp/ollama)\",\n",
    "            \"AI_CACHE_ROOT\": \"Cache directory path\",\n",
    "            \"API_PORT\": \"API server port\"\n",
    "        }\n",
    "\n",
    "        missing = []\n",
    "        for var, desc in required_vars.items():\n",
    "            value = os.getenv(var)\n",
    "            if value:\n",
    "                self.success.append(f\"✅ {var}={value}\")\n",
    "            else:\n",
    "                missing.append(f\"{var} ({desc})\")\n",
    "\n",
    "        if missing:\n",
    "            self.errors.append(f\"❌ Missing env vars: {', '.join(missing)}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def check_docker_availability(self) -> bool:\n",
    "        \"\"\"Check Docker and docker-compose availability\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run([\"docker\", \"--version\"],\n",
    "                                  capture_output=True, text=True, check=True)\n",
    "            self.success.append(f\"✅ {result.stdout.strip()}\")\n",
    "\n",
    "            result = subprocess.run([\"docker-compose\", \"--version\"],\n",
    "                                  capture_output=True, text=True, check=True)\n",
    "            self.success.append(f\"✅ {result.stdout.strip()}\")\n",
    "            return True\n",
    "\n",
    "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "            self.errors.append(\"❌ Docker or docker-compose not available\")\n",
    "            return False\n",
    "\n",
    "    def check_file_structure(self) -> bool:\n",
    "        \"\"\"Check required file structure\"\"\"\n",
    "        required_files = [\n",
    "            \"Dockerfile\",\n",
    "            \"docker-compose.yml\",\n",
    "            \".env.example\",\n",
    "            \"requirements.txt\",\n",
    "            \"shared_utils/__init__.py\",\n",
    "            \"apps/api/main.py\"\n",
    "        ]\n",
    "\n",
    "        missing = []\n",
    "        for file_path in required_files:\n",
    "            if pathlib.Path(file_path).exists():\n",
    "                self.success.append(f\"✅ {file_path}\")\n",
    "            else:\n",
    "                missing.append(file_path)\n",
    "\n",
    "        if missing:\n",
    "            self.errors.append(f\"❌ Missing files: {', '.join(missing)}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def check_gpu_availability(self) -> bool:\n",
    "        \"\"\"Check GPU availability and CUDA\"\"\"\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_count = torch.cuda.device_count()\n",
    "                gpu_name = torch.cuda.get_device_name(0)\n",
    "                memory_mb = torch.cuda.get_device_properties(0).total_memory // 1024**2\n",
    "\n",
    "                self.success.append(f\"✅ GPU: {gpu_name} ({memory_mb}MB)\")\n",
    "\n",
    "                if memory_mb < 8192:  # 8GB\n",
    "                    self.warnings.append(f\"⚠️  GPU memory ({memory_mb}MB) may be insufficient for large models\")\n",
    "\n",
    "                return True\n",
    "            else:\n",
    "                self.warnings.append(\"⚠️  No GPU available - will use CPU (slower)\")\n",
    "                return True\n",
    "\n",
    "        except ImportError:\n",
    "            self.errors.append(\"❌ PyTorch not available for GPU check\")\n",
    "            return False\n",
    "\n",
    "    def generate_report(self) -> Dict:\n",
    "        \"\"\"Generate comprehensive validation report\"\"\"\n",
    "        report = {\n",
    "            \"timestamp\": __import__(\"time\").time(),\n",
    "            \"python_version\": f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "            \"success_count\": len(self.success),\n",
    "            \"warning_count\": len(self.warnings),\n",
    "            \"error_count\": len(self.errors),\n",
    "            \"success\": self.success,\n",
    "            \"warnings\": self.warnings,\n",
    "            \"errors\": self.errors,\n",
    "            \"deployment_ready\": len(self.errors) == 0\n",
    "        }\n",
    "\n",
    "        return report\n",
    "\n",
    "    def run_all_checks(self) -> bool:\n",
    "        \"\"\"Run all validation checks\"\"\"\n",
    "        print(\"🔍 Running ragent-text-lab environment validation...\\n\")\n",
    "\n",
    "        checks = [\n",
    "            (\"Python Version\", self.check_python_version),\n",
    "            (\"Required Packages\", self.check_required_packages),\n",
    "            (\"Environment Variables\", self.check_environment_variables),\n",
    "            (\"File Structure\", self.check_file_structure),\n",
    "            (\"GPU Availability\", self.check_gpu_availability),\n",
    "            (\"Docker Availability\", self.check_docker_availability),\n",
    "        ]\n",
    "\n",
    "        all_passed = True\n",
    "        for check_name, check_func in checks:\n",
    "            print(f\"📋 {check_name}...\")\n",
    "            try:\n",
    "                passed = check_func()\n",
    "                if not passed:\n",
    "                    all_passed = False\n",
    "            except Exception as e:\n",
    "                self.errors.append(f\"❌ {check_name} check failed: {e}\")\n",
    "                all_passed = False\n",
    "            print()\n",
    "\n",
    "        return all_passed\n",
    "\n",
    "def main():\n",
    "    validator = EnvironmentValidator()\n",
    "    success = validator.run_all_checks()\n",
    "\n",
    "    # Generate report\n",
    "    report = validator.generate_report()\n",
    "\n",
    "    # Print summary\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📊 VALIDATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for item in report[\"success\"]:\n",
    "        print(item)\n",
    "\n",
    "    for item in report[\"warnings\"]:\n",
    "        print(item)\n",
    "\n",
    "    for item in report[\"errors\"]:\n",
    "        print(item)\n",
    "\n",
    "    print(f\"\\n🎯 Result: {'READY FOR DEPLOYMENT' if success else 'NEEDS ATTENTION'}\")\n",
    "\n",
    "    # Save report\n",
    "    report_path = pathlib.Path(\"outs/validation_report.json\")\n",
    "    report_path.parent.mkdir(exist_ok=True)\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"📄 Detailed report saved to {report_path}\")\n",
    "\n",
    "    return 0 if success else 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())\n",
    "'''\n",
    "\n",
    "    validate_path = pathlib.Path(\"scripts/validate_env.py\")\n",
    "    validate_path.write_text(validate_script, encoding=\"utf-8\")\n",
    "    validate_path.chmod(0o755)\n",
    "    print(f\"✅ Created validation script at {validate_path}\")\n",
    "\n",
    "    return startup_script, validate_script\n",
    "\n",
    "\n",
    "# Create startup and validation scripts\n",
    "startup_content, validate_content = create_startup_scripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 7: Nginx Configuration for Production\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_nginx_config():\n",
    "    \"\"\"Create nginx configuration for production deployment\"\"\"\n",
    "\n",
    "    nginx_config = \"\"\"# ragent-text-lab Nginx Configuration\n",
    "# Production-ready reverse proxy with SSL support\n",
    "\n",
    "events {\n",
    "    worker_connections 1024;\n",
    "}\n",
    "\n",
    "http {\n",
    "    # Basic Settings\n",
    "    sendfile on;\n",
    "    tcp_nopush on;\n",
    "    tcp_nodelay on;\n",
    "    keepalive_timeout 65;\n",
    "    types_hash_max_size 2048;\n",
    "\n",
    "    # MIME Types\n",
    "    include /etc/nginx/mime.types;\n",
    "    default_type application/octet-stream;\n",
    "\n",
    "    # Logging\n",
    "    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "                    '$status $body_bytes_sent \"$http_referer\" '\n",
    "                    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n",
    "\n",
    "    access_log /var/log/nginx/access.log main;\n",
    "    error_log /var/log/nginx/error.log;\n",
    "\n",
    "    # Gzip Compression\n",
    "    gzip on;\n",
    "    gzip_vary on;\n",
    "    gzip_min_length 10240;\n",
    "    gzip_proxied expired no-cache no-store private must-revalidate auth;\n",
    "    gzip_types\n",
    "        text/plain\n",
    "        text/css\n",
    "        text/xml\n",
    "        text/javascript\n",
    "        application/json\n",
    "        application/javascript\n",
    "        application/xml+rss\n",
    "        application/atom+xml\n",
    "        image/svg+xml;\n",
    "\n",
    "    # Rate Limiting\n",
    "    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n",
    "    limit_req_zone $binary_remote_addr zone=ui:10m rate=5r/s;\n",
    "\n",
    "    # Upstream Services\n",
    "    upstream ragent_api {\n",
    "        server ragent-api:8000;\n",
    "        keepalive 32;\n",
    "    }\n",
    "\n",
    "    upstream ragent_ui {\n",
    "        server ragent-ui:7860;\n",
    "        keepalive 16;\n",
    "    }\n",
    "\n",
    "    # ===========================================\n",
    "    # HTTP to HTTPS Redirect\n",
    "    # ===========================================\n",
    "    server {\n",
    "        listen 80;\n",
    "        server_name _;\n",
    "        return 301 https://$host$request_uri;\n",
    "    }\n",
    "\n",
    "    # ===========================================\n",
    "    # Main HTTPS Server\n",
    "    # ===========================================\n",
    "    server {\n",
    "        listen 443 ssl http2;\n",
    "        server_name _;\n",
    "\n",
    "        # SSL Configuration\n",
    "        ssl_certificate /etc/nginx/ssl/cert.pem;\n",
    "        ssl_certificate_key /etc/nginx/ssl/key.pem;\n",
    "        ssl_protocols TLSv1.2 TLSv1.3;\n",
    "        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;\n",
    "        ssl_prefer_server_ciphers off;\n",
    "\n",
    "        # Security Headers\n",
    "        add_header Strict-Transport-Security \"max-age=63072000\" always;\n",
    "        add_header X-Frame-Options DENY;\n",
    "        add_header X-Content-Type-Options nosniff;\n",
    "        add_header X-XSS-Protection \"1; mode=block\";\n",
    "        add_header Referrer-Policy \"strict-origin-when-cross-origin\";\n",
    "\n",
    "        # ===========================================\n",
    "        # API Routes\n",
    "        # ===========================================\n",
    "        location /api/ {\n",
    "            limit_req zone=api burst=20 nodelay;\n",
    "\n",
    "            proxy_pass http://ragent_api/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "\n",
    "            # Timeouts\n",
    "            proxy_connect_timeout 60s;\n",
    "            proxy_send_timeout 300s;\n",
    "            proxy_read_timeout 300s;\n",
    "\n",
    "            # Buffering\n",
    "            proxy_buffering on;\n",
    "            proxy_buffer_size 4k;\n",
    "            proxy_buffers 8 4k;\n",
    "            proxy_busy_buffers_size 8k;\n",
    "\n",
    "            # WebSocket Support\n",
    "            proxy_http_version 1.1;\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "        }\n",
    "\n",
    "        # Health Check (no rate limit)\n",
    "        location /health {\n",
    "            proxy_pass http://ragent_api/health;\n",
    "            proxy_set_header Host $host;\n",
    "            access_log off;\n",
    "        }\n",
    "\n",
    "        # Metrics (restrict access)\n",
    "        location /metrics {\n",
    "            allow 127.0.0.1;\n",
    "            allow 10.0.0.0/8;\n",
    "            allow 172.16.0.0/12;\n",
    "            allow 192.168.0.0/16;\n",
    "            deny all;\n",
    "\n",
    "            proxy_pass http://ragent_api/metrics;\n",
    "            proxy_set_header Host $host;\n",
    "        }\n",
    "\n",
    "        # ===========================================\n",
    "        # UI Routes\n",
    "        # ===========================================\n",
    "        location / {\n",
    "            limit_req zone=ui burst=10 nodelay;\n",
    "\n",
    "            proxy_pass http://ragent_ui/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "\n",
    "            # WebSocket Support for Gradio\n",
    "            proxy_http_version 1.1;\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "\n",
    "            # Timeouts\n",
    "            proxy_connect_timeout 60s;\n",
    "            proxy_send_timeout 60s;\n",
    "            proxy_read_timeout 60s;\n",
    "        }\n",
    "\n",
    "        # Static Files (if any)\n",
    "        location /static/ {\n",
    "            expires 1y;\n",
    "            add_header Cache-Control \"public, immutable\";\n",
    "            try_files $uri =404;\n",
    "        }\n",
    "\n",
    "        # Favicon\n",
    "        location = /favicon.ico {\n",
    "            access_log off;\n",
    "            log_not_found off;\n",
    "            expires 1y;\n",
    "        }\n",
    "\n",
    "        # Security.txt\n",
    "        location = /.well-known/security.txt {\n",
    "            return 200 \"Contact: security@yourcompany.com\\nExpires: 2025-12-31T23:59:59.000Z\\n\";\n",
    "            add_header Content-Type text/plain;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    nginx_path = pathlib.Path(\"nginx.conf\")\n",
    "    nginx_path.write_text(nginx_config.strip(), encoding=\"utf-8\")\n",
    "    print(f\"✅ Created nginx configuration at {nginx_path}\")\n",
    "\n",
    "    return nginx_config\n",
    "\n",
    "\n",
    "# Create nginx configuration\n",
    "nginx_content = create_nginx_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 8: Smoke Test - Container Startup & Validation\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def run_deployment_smoke_test():\n",
    "    \"\"\"Comprehensive smoke test for deployment setup\"\"\"\n",
    "\n",
    "    print(\"🧪 Running Deployment Smoke Test\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Test 1: Environment validation\n",
    "    print(\"\\n📋 Test 1: Environment Validation\")\n",
    "    try:\n",
    "        # Load environment from .env.example\n",
    "        env_vars = {}\n",
    "        env_example_path = pathlib.Path(\".env.example\")\n",
    "        if env_example_path.exists():\n",
    "            for line in env_example_path.read_text().split(\"\\n\"):\n",
    "                if \"=\" in line and not line.startswith(\"#\"):\n",
    "                    key, value = line.split(\"=\", 1)\n",
    "                    env_vars[key.strip()] = value.strip()\n",
    "\n",
    "        required_keys = [\"MODEL_ID\", \"BACKEND\", \"API_PORT\", \"AI_CACHE_ROOT\"]\n",
    "        missing = [k for k in required_keys if k not in env_vars]\n",
    "\n",
    "        if missing:\n",
    "            print(f\"❌ Missing environment variables: {missing}\")\n",
    "        else:\n",
    "            print(\"✅ Environment template validation passed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Environment validation failed: {e}\")\n",
    "\n",
    "    # Test 2: Docker files validation\n",
    "    print(\"\\n🐳 Test 2: Docker Configuration\")\n",
    "    docker_files = [\"Dockerfile\", \"docker-compose.yml\"]\n",
    "    for file_name in docker_files:\n",
    "        file_path = pathlib.Path(file_name)\n",
    "        if file_path.exists():\n",
    "            size_kb = file_path.stat().st_size / 1024\n",
    "            print(f\"✅ {file_name} ({size_kb:.1f}KB)\")\n",
    "        else:\n",
    "            print(f\"❌ Missing {file_name}\")\n",
    "\n",
    "    # Test 3: Security configuration test\n",
    "    print(\"\\n🔒 Test 3: Security Configuration\")\n",
    "    try:\n",
    "        security_path = pathlib.Path(\"shared_utils/api/security.py\")\n",
    "        if security_path.exists():\n",
    "            security_content = security_path.read_text()\n",
    "            security_features = [\n",
    "                \"RateLimitMiddleware\",\n",
    "                \"SecurityHeadersMiddleware\",\n",
    "                \"CORSMiddleware\",\n",
    "                \"TrustedHostMiddleware\",\n",
    "            ]\n",
    "\n",
    "            found_features = [f for f in security_features if f in security_content]\n",
    "            print(\n",
    "                f\"✅ Security features: {len(found_features)}/{len(security_features)}\"\n",
    "            )\n",
    "\n",
    "            if len(found_features) < len(security_features):\n",
    "                missing = set(security_features) - set(found_features)\n",
    "                print(f\"⚠️  Missing security features: {missing}\")\n",
    "        else:\n",
    "            print(\"❌ Security middleware not found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Security validation failed: {e}\")\n",
    "\n",
    "    # Test 4: Startup scripts validation\n",
    "    print(\"\\n🚀 Test 4: Startup Scripts\")\n",
    "    scripts = [\n",
    "        (\"scripts/startup.sh\", \"startup script\"),\n",
    "        (\"scripts/validate_env.py\", \"environment validator\"),\n",
    "    ]\n",
    "\n",
    "    for script_path, description in scripts:\n",
    "        path = pathlib.Path(script_path)\n",
    "        if path.exists():\n",
    "            # Check if executable\n",
    "            is_executable = path.stat().st_mode & 0o111\n",
    "            status = \"✅\" if is_executable else \"⚠️ \"\n",
    "            print(f\"{status} {description}: {script_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Missing {description}: {script_path}\")\n",
    "\n",
    "    # Test 5: Production readiness checklist\n",
    "    print(\"\\n🎯 Test 5: Production Readiness\")\n",
    "    production_items = [\n",
    "        (\"Health check endpoint\", \"/health\"),\n",
    "        (\"Metrics endpoint\", \"/metrics\"),\n",
    "        (\"CORS configuration\", \"CORS_ORIGINS\"),\n",
    "        (\"Rate limiting\", \"RATE_LIMIT_REQUESTS\"),\n",
    "        (\"Security headers\", \"SecurityHeadersMiddleware\"),\n",
    "        (\"Nginx configuration\", \"nginx.conf\"),\n",
    "        (\"SSL support\", \"ssl_certificate\"),\n",
    "        (\"Docker multi-stage\", \"FROM.*as.*production\"),\n",
    "    ]\n",
    "\n",
    "    ready_count = 0\n",
    "    for item, check in production_items:\n",
    "        # Simple existence checks for production features\n",
    "        found = False\n",
    "\n",
    "        if check.startswith(\"/\"):\n",
    "            # Check if endpoint exists in security.py\n",
    "            security_path = pathlib.Path(\"shared_utils/api/security.py\")\n",
    "            if security_path.exists() and check in security_path.read_text():\n",
    "                found = True\n",
    "        elif check.endswith(\".conf\"):\n",
    "            # Check if config file exists\n",
    "            found = pathlib.Path(check).exists()\n",
    "        elif \"=\" not in check and check in globals().get(\"security_code\", \"\"):\n",
    "            # Check for middleware/feature in security code\n",
    "            found = True\n",
    "        elif check in env_vars:\n",
    "            # Check for environment variable\n",
    "            found = True\n",
    "        elif \"FROM\" in check:\n",
    "            # Check Dockerfile for multi-stage\n",
    "            dockerfile = pathlib.Path(\"Dockerfile\")\n",
    "            if dockerfile.exists() and \"as production\" in dockerfile.read_text():\n",
    "                found = True\n",
    "\n",
    "        if found:\n",
    "            ready_count += 1\n",
    "            print(f\"✅ {item}\")\n",
    "        else:\n",
    "            print(f\"❌ {item}\")\n",
    "\n",
    "    # Final assessment\n",
    "    print(f\"\\n📊 Production Readiness: {ready_count}/{len(production_items)} items\")\n",
    "\n",
    "    if ready_count >= len(production_items) * 0.8:  # 80% threshold\n",
    "        print(\"🎉 DEPLOYMENT READY - 可以進行生產部署\")\n",
    "        deployment_status = \"READY\"\n",
    "    else:\n",
    "        print(\"⚠️  NEEDS ATTENTION - 需要完善配置後部署\")\n",
    "        deployment_status = \"NEEDS_WORK\"\n",
    "\n",
    "    # Generate deployment report\n",
    "    report = {\n",
    "        \"timestamp\": __import__(\"time\").time(),\n",
    "        \"deployment_status\": deployment_status,\n",
    "        \"readiness_score\": f\"{ready_count}/{len(production_items)}\",\n",
    "        \"environment_vars_count\": len(env_vars),\n",
    "        \"docker_files_ready\": len(\n",
    "            [f for f in docker_files if pathlib.Path(f).exists()]\n",
    "        ),\n",
    "        \"security_features\": len(found_features) if \"found_features\" in locals() else 0,\n",
    "        \"production_readiness\": ready_count / len(production_items),\n",
    "    }\n",
    "\n",
    "    report_path = pathlib.Path(\"outs/deployment_report.json\")\n",
    "    report_path.parent.mkdir(exist_ok=True)\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        __import__(\"json\").dump(report, f, indent=2)\n",
    "\n",
    "    print(f\"\\n📄 Deployment report saved to {report_path}\")\n",
    "\n",
    "    return deployment_status == \"READY\"\n",
    "\n",
    "\n",
    "# Run comprehensive smoke test\n",
    "deployment_ready = run_deployment_smoke_test()\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "\n",
    "🎯 **Stage 8 Complete: Docker Deployment & Production Setup**\n",
    "\n",
    "## 完成項目 Completed Features\n",
    "✅ **環境配置**: .env.example 模板與變數管理\n",
    "✅ **容器化**: 多階段 Dockerfile 與 docker-compose 編排\n",
    "✅ **安全防護**: CORS、速率限制、安全標頭中介軟體\n",
    "✅ **監控健檢**: /health 與 /metrics 端點\n",
    "✅ **生產部署**: Nginx 反向代理與 SSL 支援\n",
    "✅ **自動化腳本**: 啟動與環境驗證腳本\n",
    "\n",
    "## 核心概念 Key Concepts\n",
    "- **Multi-stage Docker builds** 最佳化映像檔大小與安全性\n",
    "- **Environment-driven configuration** 環境變數驅動的配置管理\n",
    "- **Production security middleware** 生產級安全防護機制\n",
    "- **Container orchestration** 多服務容器編排\n",
    "- **Health monitoring & metrics** 服務健康監控與指標\n",
    "\n",
    "## 常見陷阱 Pitfalls\n",
    "⚠️ **記憶體限制**: 容器記憶體配置需考慮模型大小 (建議 ≥8GB)\n",
    "⚠️ **快取掛載**: AI_CACHE_ROOT 需正確掛載避免重複下載\n",
    "⚠️ **權限問題**: 容器內檔案權限與主機用戶映射\n",
    "⚠️ **網路配置**: 容器間通訊與外部存取端口設定\n",
    "⚠️ **SSL 憑證**: 生產環境需配置有效 SSL 憑證\n",
    "\n",
    "## 使用時機 When to Use\n",
    "🎯 **生產部署**: 正式環境的容器化部署\n",
    "🎯 **開發環境**: 統一的開發環境配置\n",
    "🎯 **CI/CD**: 自動化建構與部署流程\n",
    "🎯 **擴展部署**: 多實例負載均衡部署\n",
    "🎯 **雲端部署**: 雲平台容器服務部署\n",
    "\n",
    "## 下一步 Next Steps\n",
    "🚀 設定 SSL 憑證與域名\n",
    "🚀 配置監控告警系統 (Prometheus + Grafana)\n",
    "🚀 建立 CI/CD 自動化流程\n",
    "🚀 效能調優與擴展策略\n",
    "🚀 備份與災害復原計畫\n",
    "\n",
    "部署狀態: {'🎉 READY FOR PRODUCTION' if deployment_ready else '⚠️ NEEDS CONFIGURATION'}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 🎯 End of nb73_dockerfile_and_env.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
