{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d847c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Stage 8 - API & Deploy: nb73_dockerfile_and_env.ipynb\n",
    "# Topic: Docker containerization + environment management + CORS + production ready\n",
    "# =============================================================================\n",
    "\n",
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (Ë§áË£ΩÂà∞ÊØèÊú¨ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Environment Variables Design & .env.example\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_env_example():\n",
    "    \"\"\"Create .env.example template with all required environment variables\"\"\"\n",
    "\n",
    "    env_template = \"\"\"# ragent-text-lab Environment Configuration\n",
    "# ===========================================\n",
    "\n",
    "# AI Cache & Model Configuration\n",
    "AI_CACHE_ROOT=/mnt/ai/cache\n",
    "MODEL_ID=Qwen/Qwen2.5-7B-Instruct\n",
    "BACKEND=transformers\n",
    "DEVICE_MAP=auto\n",
    "TORCH_DTYPE=auto\n",
    "QUANTIZATION=none\n",
    "\n",
    "# RAG Configuration\n",
    "EMBEDDING_MODEL=BAAI/bge-m3\n",
    "RERANKER_MODEL=BAAI/bge-reranker-base\n",
    "INDEX_PATH=indices/general.faiss\n",
    "RAG_CHUNK_SIZE=800\n",
    "RAG_OVERLAP=80\n",
    "\n",
    "# API Server Configuration\n",
    "API_HOST=0.0.0.0\n",
    "API_PORT=8000\n",
    "API_WORKERS=1\n",
    "DEBUG=false\n",
    "\n",
    "# CORS Configuration\n",
    "CORS_ORIGINS=*\n",
    "CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS\n",
    "CORS_HEADERS=*\n",
    "CORS_CREDENTIALS=true\n",
    "\n",
    "# Rate Limiting\n",
    "RATE_LIMIT_REQUESTS=100\n",
    "RATE_LIMIT_WINDOW=3600\n",
    "RATE_LIMIT_STORAGE=memory\n",
    "\n",
    "# Security Configuration\n",
    "MAX_PROMPT_LENGTH=4096\n",
    "MAX_RESPONSE_LENGTH=2048\n",
    "SAFETY_CHECK=true\n",
    "ALLOWED_HOSTS=*\n",
    "\n",
    "# Tool Configuration\n",
    "WEB_SEARCH_ENABLED=true\n",
    "CALCULATOR_ENABLED=true\n",
    "FILE_LOOKUP_ENABLED=true\n",
    "FILE_LOOKUP_WHITELIST=data/,outs/\n",
    "\n",
    "# Logging Configuration\n",
    "LOG_LEVEL=info\n",
    "LOG_FORMAT=json\n",
    "LOG_FILE=logs/ragent.log\n",
    "\n",
    "# Database Configuration (if needed)\n",
    "# DATABASE_URL=sqlite:///./ragent.db\n",
    "\n",
    "# External Services (optional)\n",
    "# OPENAI_API_KEY=your_openai_key_here\n",
    "# ANTHROPIC_API_KEY=your_anthropic_key_here\n",
    "\"\"\"\n",
    "\n",
    "    # Write to project root\n",
    "    env_path = pathlib.Path(\".env.example\")\n",
    "    env_path.write_text(env_template.strip(), encoding=\"utf-8\")\n",
    "    print(\n",
    "        f\"‚úÖ Created {env_path} with {len(env_template.split('='))} configuration items\"\n",
    "    )\n",
    "\n",
    "    return env_template\n",
    "\n",
    "\n",
    "# Create environment template\n",
    "env_content = create_env_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Dockerfile Multi-stage Build\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_dockerfile():\n",
    "    \"\"\"Create optimized multi-stage Dockerfile for production deployment\"\"\"\n",
    "\n",
    "    dockerfile_content = \"\"\"# ragent-text-lab Dockerfile\n",
    "# Multi-stage build for optimized production image\n",
    "\n",
    "# ===========================================\n",
    "# Stage 1: Base Python Environment\n",
    "# ===========================================\n",
    "FROM python:3.11-slim as base\n",
    "\n",
    "# Set environment variables\n",
    "ENV PYTHONUNBUFFERED=1 \\\n",
    "    PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PIP_NO_CACHE_DIR=1 \\\n",
    "    PIP_DISABLE_PIP_VERSION_CHECK=1\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    gcc \\\n",
    "    g++ \\\n",
    "    git \\\n",
    "    curl \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Create app user for security\n",
    "RUN useradd --create-home --shell /bin/bash app\n",
    "\n",
    "# ===========================================\n",
    "# Stage 2: Dependencies Installation\n",
    "# ===========================================\n",
    "FROM base as deps\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements first for better layer caching\n",
    "COPY requirements.txt requirements-dev.txt ./\n",
    "\n",
    "# Install Python dependencies\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# ===========================================\n",
    "# Stage 3: Application Build\n",
    "# ===========================================\n",
    "FROM deps as app\n",
    "\n",
    "# Copy application code\n",
    "COPY --chown=app:app . .\n",
    "\n",
    "# Create necessary directories\n",
    "RUN mkdir -p logs outs indices data && \\\n",
    "    chown -R app:app /app\n",
    "\n",
    "# Switch to app user\n",
    "USER app\n",
    "\n",
    "# Set cache directory\n",
    "ENV AI_CACHE_ROOT=/app/cache\n",
    "RUN mkdir -p /app/cache/{hf,torch}\n",
    "\n",
    "# ===========================================\n",
    "# Stage 4: Production Image\n",
    "# ===========================================\n",
    "FROM app as production\n",
    "\n",
    "# Expose API port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n",
    "    CMD curl -f http://localhost:8000/health || exit 1\n",
    "\n",
    "# Default command\n",
    "CMD [\"python\", \"-m\", \"uvicorn\", \"apps.api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\"\"\"\n",
    "\n",
    "    dockerfile_path = pathlib.Path(\"Dockerfile\")\n",
    "    dockerfile_path.write_text(dockerfile_content.strip(), encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ Created {dockerfile_path}\")\n",
    "\n",
    "    return dockerfile_content\n",
    "\n",
    "\n",
    "# Create Dockerfile\n",
    "dockerfile_content = create_dockerfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: docker-compose.yml Complete Service Orchestration\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_docker_compose():\n",
    "    \"\"\"Create docker-compose.yml for complete service orchestration\"\"\"\n",
    "\n",
    "    compose_content = \"\"\"# ragent-text-lab Docker Compose Configuration\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # ===========================================\n",
    "  # Main API Service\n",
    "  # ===========================================\n",
    "  ragent-api:\n",
    "    build:\n",
    "      context: .\n",
    "      target: production\n",
    "    container_name: ragent-api\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"${API_PORT:-8000}:8000\"\n",
    "    environment:\n",
    "      - AI_CACHE_ROOT=/app/cache\n",
    "      - MODEL_ID=${MODEL_ID:-Qwen/Qwen2.5-7B-Instruct}\n",
    "      - BACKEND=${BACKEND:-transformers}\n",
    "      - API_HOST=0.0.0.0\n",
    "      - API_PORT=8000\n",
    "      - DEBUG=${DEBUG:-false}\n",
    "      - LOG_LEVEL=${LOG_LEVEL:-info}\n",
    "      - CORS_ORIGINS=${CORS_ORIGINS:-*}\n",
    "      - RATE_LIMIT_REQUESTS=${RATE_LIMIT_REQUESTS:-100}\n",
    "      - MAX_PROMPT_LENGTH=${MAX_PROMPT_LENGTH:-4096}\n",
    "      - SAFETY_CHECK=${SAFETY_CHECK:-true}\n",
    "    volumes:\n",
    "      - ./data:/app/data:ro\n",
    "      - ./outs:/app/outs\n",
    "      - ./indices:/app/indices\n",
    "      - ./logs:/app/logs\n",
    "      - ai-cache:/app/cache\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    depends_on:\n",
    "      - redis\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 8G\n",
    "        reservations:\n",
    "          memory: 4G\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 40s\n",
    "\n",
    "  # ===========================================\n",
    "  # Gradio UI Service\n",
    "  # ===========================================\n",
    "  ragent-ui:\n",
    "    build:\n",
    "      context: .\n",
    "      target: production\n",
    "    container_name: ragent-ui\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"${UI_PORT:-7860}:7860\"\n",
    "    environment:\n",
    "      - API_URL=http://ragent-api:8000\n",
    "      - GRADIO_SERVER_NAME=0.0.0.0\n",
    "      - GRADIO_SERVER_PORT=7860\n",
    "    command: [\"python\", \"apps/gradio_app/app.py\"]\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    depends_on:\n",
    "      - ragent-api\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 2G\n",
    "\n",
    "  # ===========================================\n",
    "  # Redis for Rate Limiting & Caching\n",
    "  # ===========================================\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    container_name: ragent-redis\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis-data:/data\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    command: redis-server --appendonly yes\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 512M\n",
    "\n",
    "  # ===========================================\n",
    "  # Nginx Reverse Proxy (Optional)\n",
    "  # ===========================================\n",
    "  nginx:\n",
    "    image: nginx:alpine\n",
    "    container_name: ragent-nginx\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "      - \"443:443\"\n",
    "    volumes:\n",
    "      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n",
    "      - ./ssl:/etc/nginx/ssl:ro\n",
    "    networks:\n",
    "      - ragent-network\n",
    "    depends_on:\n",
    "      - ragent-api\n",
    "      - ragent-ui\n",
    "    profiles:\n",
    "      - production\n",
    "\n",
    "# ===========================================\n",
    "# Named Volumes\n",
    "# ===========================================\n",
    "volumes:\n",
    "  ai-cache:\n",
    "    driver: local\n",
    "  redis-data:\n",
    "    driver: local\n",
    "\n",
    "# ===========================================\n",
    "# Networks\n",
    "# ===========================================\n",
    "networks:\n",
    "  ragent-network:\n",
    "    driver: bridge\n",
    "    ipam:\n",
    "      config:\n",
    "        - subnet: 172.20.0.0/16\n",
    "\"\"\"\n",
    "\n",
    "    compose_path = pathlib.Path(\"docker-compose.yml\")\n",
    "    compose_path.write_text(compose_content.strip(), encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ Created {compose_path}\")\n",
    "\n",
    "    return compose_content\n",
    "\n",
    "\n",
    "# Create docker-compose configuration\n",
    "compose_content = create_docker_compose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ff3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: CORS & Security Middleware Enhancement\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_security_middleware():\n",
    "    \"\"\"Enhanced security middleware for production deployment\"\"\"\n",
    "\n",
    "    middleware_code = '''from fastapi import FastAPI, Request, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.middleware.trustedhost import TrustedHostMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "import time\n",
    "import asyncio\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===========================================\n",
    "# Rate Limiting Middleware\n",
    "# ===========================================\n",
    "class RateLimitMiddleware:\n",
    "    def __init__(self, requests_per_window: int = 100, window_seconds: int = 3600):\n",
    "        self.requests_per_window = requests_per_window\n",
    "        self.window_seconds = window_seconds\n",
    "        self.client_requests = defaultdict(list)\n",
    "\n",
    "    async def __call__(self, request: Request, call_next):\n",
    "        client_ip = request.client.host\n",
    "        now = time.time()\n",
    "\n",
    "        # Clean old requests\n",
    "        self.client_requests[client_ip] = [\n",
    "            req_time for req_time in self.client_requests[client_ip]\n",
    "            if now - req_time < self.window_seconds\n",
    "        ]\n",
    "\n",
    "        # Check rate limit\n",
    "        if len(self.client_requests[client_ip]) >= self.requests_per_window:\n",
    "            return JSONResponse(\n",
    "                status_code=429,\n",
    "                content={\"error\": \"Rate limit exceeded\", \"retry_after\": self.window_seconds}\n",
    "            )\n",
    "\n",
    "        # Record request\n",
    "        self.client_requests[client_ip].append(now)\n",
    "\n",
    "        response = await call_next(request)\n",
    "        return response\n",
    "\n",
    "# ===========================================\n",
    "# Security Headers Middleware\n",
    "# ===========================================\n",
    "class SecurityHeadersMiddleware:\n",
    "    async def __call__(self, request: Request, call_next):\n",
    "        response = await call_next(request)\n",
    "\n",
    "        # Security headers\n",
    "        response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n",
    "        response.headers[\"X-Frame-Options\"] = \"DENY\"\n",
    "        response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n",
    "        response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains\"\n",
    "        response.headers[\"Referrer-Policy\"] = \"strict-origin-when-cross-origin\"\n",
    "        response.headers[\"Content-Security-Policy\"] = \"default-src 'self'\"\n",
    "\n",
    "        return response\n",
    "\n",
    "# ===========================================\n",
    "# Setup Security for FastAPI App\n",
    "# ===========================================\n",
    "def setup_security(app: FastAPI):\n",
    "    \"\"\"Configure comprehensive security for production\"\"\"\n",
    "\n",
    "    # CORS Configuration\n",
    "    cors_origins = os.getenv(\"CORS_ORIGINS\", \"*\").split(\",\")\n",
    "    if cors_origins == [\"*\"]:\n",
    "        logger.warning(\"CORSÂÖÅË®±ÊâÄÊúâ‰æÜÊ∫ê - ÁîüÁî¢Áí∞Â¢ÉÂª∫Ë≠∞ÈôêÂà∂\")\n",
    "\n",
    "    app.add_middleware(\n",
    "        CORSMiddleware,\n",
    "        allow_origins=cors_origins,\n",
    "        allow_credentials=True,\n",
    "        allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n",
    "        allow_headers=[\"*\"],\n",
    "    )\n",
    "\n",
    "    # Trusted Host Middleware\n",
    "    allowed_hosts = os.getenv(\"ALLOWED_HOSTS\", \"*\").split(\",\")\n",
    "    if allowed_hosts != [\"*\"]:\n",
    "        app.add_middleware(\n",
    "            TrustedHostMiddleware,\n",
    "            allowed_hosts=allowed_hosts\n",
    "        )\n",
    "\n",
    "    # Rate Limiting\n",
    "    rate_limit_requests = int(os.getenv(\"RATE_LIMIT_REQUESTS\", \"100\"))\n",
    "    rate_limit_window = int(os.getenv(\"RATE_LIMIT_WINDOW\", \"3600\"))\n",
    "\n",
    "    app.middleware(\"http\")(\n",
    "        RateLimitMiddleware(rate_limit_requests, rate_limit_window)\n",
    "    )\n",
    "\n",
    "    # Security Headers\n",
    "    app.middleware(\"http\")(SecurityHeadersMiddleware())\n",
    "\n",
    "    logger.info(f\"üîí ÂÆâÂÖ®Ë®≠ÂÆöÂÆåÊàê: CORS={len(cors_origins)} origins, Rate={rate_limit_requests}/hr\")\n",
    "\n",
    "    return app\n",
    "\n",
    "# ===========================================\n",
    "# Health Check Endpoint\n",
    "# ===========================================\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Comprehensive health check for container orchestration\"\"\"\n",
    "    import psutil\n",
    "    import torch\n",
    "\n",
    "    try:\n",
    "        # System metrics\n",
    "        cpu_percent = psutil.cpu_percent(interval=1)\n",
    "        memory = psutil.virtual_memory()\n",
    "        disk = psutil.disk_usage('/')\n",
    "\n",
    "        # GPU check\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        gpu_memory = None\n",
    "        if gpu_available:\n",
    "            gpu_memory = {\n",
    "                \"allocated\": torch.cuda.memory_allocated(),\n",
    "                \"cached\": torch.cuda.memory_reserved(),\n",
    "                \"total\": torch.cuda.get_device_properties(0).total_memory\n",
    "            }\n",
    "\n",
    "        health_data = {\n",
    "            \"status\": \"healthy\",\n",
    "            \"timestamp\": time.time(),\n",
    "            \"system\": {\n",
    "                \"cpu_percent\": cpu_percent,\n",
    "                \"memory_percent\": memory.percent,\n",
    "                \"disk_percent\": disk.percent,\n",
    "                \"gpu_available\": gpu_available,\n",
    "                \"gpu_memory\": gpu_memory\n",
    "            },\n",
    "            \"services\": {\n",
    "                \"api\": \"running\",\n",
    "                \"model_loaded\": hasattr(app.state, 'llm_adapter'),\n",
    "                \"rag_index\": os.path.exists(\"indices/general.faiss\")\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return health_data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Health check failed: {e}\")\n",
    "        return JSONResponse(\n",
    "            status_code=503,\n",
    "            content={\"status\": \"unhealthy\", \"error\": str(e)}\n",
    "        )\n",
    "\n",
    "# ===========================================\n",
    "# Metrics Endpoint\n",
    "# ===========================================\n",
    "@app.get(\"/metrics\")\n",
    "async def metrics():\n",
    "    \"\"\"Prometheus-compatible metrics endpoint\"\"\"\n",
    "\n",
    "    metrics_text = f\"\"\"# HELP ragent_requests_total Total requests processed\n",
    "# TYPE ragent_requests_total counter\n",
    "ragent_requests_total {{method=\"GET\"}} {getattr(app.state, 'get_requests', 0)}\n",
    "ragent_requests_total {{method=\"POST\"}} {getattr(app.state, 'post_requests', 0)}\n",
    "\n",
    "# HELP ragent_response_duration_seconds Response duration\n",
    "# TYPE ragent_response_duration_seconds histogram\n",
    "ragent_response_duration_seconds_bucket {{le=\"0.1\"}} {getattr(app.state, 'fast_responses', 0)}\n",
    "ragent_response_duration_seconds_bucket {{le=\"1.0\"}} {getattr(app.state, 'medium_responses', 0)}\n",
    "ragent_response_duration_seconds_bucket {{le=\"10.0\"}} {getattr(app.state, 'slow_responses', 0)}\n",
    "\n",
    "# HELP ragent_model_inference_duration_seconds Model inference time\n",
    "# TYPE ragent_model_inference_duration_seconds histogram\n",
    "ragent_model_inference_duration_seconds_sum {getattr(app.state, 'total_inference_time', 0)}\n",
    "ragent_model_inference_duration_seconds_count {getattr(app.state, 'inference_count', 0)}\n",
    "\"\"\"\n",
    "\n",
    "    return Response(content=metrics_text, media_type=\"text/plain\")\n",
    "'''\n",
    "\n",
    "    # Write middleware to shared_utils\n",
    "    middleware_path = pathlib.Path(\"shared_utils/api/security.py\")\n",
    "    middleware_path.parent.mkdir(exist_ok=True)\n",
    "    middleware_path.write_text(middleware_code, encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ Created security middleware at {middleware_path}\")\n",
    "\n",
    "    return middleware_code\n",
    "\n",
    "\n",
    "# Create security middleware\n",
    "security_code = create_security_middleware()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Startup Scripts & Environment Validation\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_startup_scripts():\n",
    "    \"\"\"Create startup and validation scripts for deployment\"\"\"\n",
    "\n",
    "    # Startup script\n",
    "    startup_script = \"\"\"#!/bin/bash\n",
    "# ragent-text-lab startup script\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"üöÄ Starting ragent-text-lab deployment...\"\n",
    "\n",
    "# ===========================================\n",
    "# Environment Validation\n",
    "# ===========================================\n",
    "validate_env() {\n",
    "    echo \"üìã Validating environment variables...\"\n",
    "\n",
    "    required_vars=(\n",
    "        \"MODEL_ID\"\n",
    "        \"BACKEND\"\n",
    "        \"API_PORT\"\n",
    "        \"AI_CACHE_ROOT\"\n",
    "    )\n",
    "\n",
    "    for var in \"${required_vars[@]}\"; do\n",
    "        if [[ -z \"${!var}\" ]]; then\n",
    "            echo \"‚ùå Required environment variable $var is not set\"\n",
    "            exit 1\n",
    "        fi\n",
    "    done\n",
    "\n",
    "    echo \"‚úÖ Environment validation passed\"\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Docker Setup\n",
    "# ===========================================\n",
    "setup_docker() {\n",
    "    echo \"üê≥ Setting up Docker environment...\"\n",
    "\n",
    "    # Create necessary directories\n",
    "    mkdir -p data outs indices logs\n",
    "\n",
    "    # Set permissions\n",
    "    chmod 755 data outs indices logs\n",
    "\n",
    "    echo \"‚úÖ Docker setup completed\"\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Model Download\n",
    "# ===========================================\n",
    "download_models() {\n",
    "    echo \"üì• Downloading required models...\"\n",
    "\n",
    "    python3 -c \"\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download LLM tokenizer (lightweight check)\n",
    "model_id = os.getenv('MODEL_ID', 'Qwen/Qwen2.5-7B-Instruct')\n",
    "print(f'Checking {model_id}...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "print(f'‚úÖ {model_id} tokenizer ready')\n",
    "\n",
    "# Download embedding model\n",
    "embed_model = os.getenv('EMBEDDING_MODEL', 'BAAI/bge-m3')\n",
    "print(f'Downloading {embed_model}...')\n",
    "embedder = SentenceTransformer(embed_model)\n",
    "print(f'‚úÖ {embed_model} ready')\n",
    "\n",
    "print('üéØ All models downloaded successfully')\n",
    "\"\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Health Check\n",
    "# ===========================================\n",
    "health_check() {\n",
    "    echo \"üîç Running health checks...\"\n",
    "\n",
    "    # Wait for service to start\n",
    "    sleep 10\n",
    "\n",
    "    # Check API health\n",
    "    if curl -f http://localhost:${API_PORT:-8000}/health > /dev/null 2>&1; then\n",
    "        echo \"‚úÖ API health check passed\"\n",
    "    else\n",
    "        echo \"‚ùå API health check failed\"\n",
    "        return 1\n",
    "    fi\n",
    "\n",
    "    # Check model loading\n",
    "    if curl -f http://localhost:${API_PORT:-8000}/v1/models > /dev/null 2>&1; then\n",
    "        echo \"‚úÖ Model endpoint accessible\"\n",
    "    else\n",
    "        echo \"‚ö†Ô∏è  Model endpoint not ready (may still be loading)\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# ===========================================\n",
    "# Main Execution\n",
    "# ===========================================\n",
    "main() {\n",
    "    validate_env\n",
    "    setup_docker\n",
    "\n",
    "    if [[ \"${DOWNLOAD_MODELS:-true}\" == \"true\" ]]; then\n",
    "        download_models\n",
    "    fi\n",
    "\n",
    "    echo \"üöÄ Starting services with docker-compose...\"\n",
    "    docker-compose up -d\n",
    "\n",
    "    health_check\n",
    "\n",
    "    echo \"üéâ ragent-text-lab deployment completed!\"\n",
    "    echo \"üìä API: http://localhost:${API_PORT:-8000}\"\n",
    "    echo \"üé® UI: http://localhost:${UI_PORT:-7860}\"\n",
    "    echo \"üìà Health: http://localhost:${API_PORT:-8000}/health\"\n",
    "}\n",
    "\n",
    "# Run main function\n",
    "main \"$@\"\n",
    "\"\"\"\n",
    "\n",
    "    startup_path = pathlib.Path(\"scripts/startup.sh\")\n",
    "    startup_path.parent.mkdir(exist_ok=True)\n",
    "    startup_path.write_text(startup_script, encoding=\"utf-8\")\n",
    "    startup_path.chmod(0o755)\n",
    "    print(f\"‚úÖ Created startup script at {startup_path}\")\n",
    "\n",
    "    # Environment validation script\n",
    "    validate_script = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ragent-text-lab environment validation script\n",
    "Checks all dependencies and configurations before deployment\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import subprocess\n",
    "import pathlib\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class EnvironmentValidator:\n",
    "    def __init__(self):\n",
    "        self.errors = []\n",
    "        self.warnings = []\n",
    "        self.success = []\n",
    "\n",
    "    def check_python_version(self) -> bool:\n",
    "        \"\"\"Check Python version compatibility\"\"\"\n",
    "        version = sys.version_info\n",
    "        if version.major == 3 and version.minor >= 8:\n",
    "            self.success.append(f\"‚úÖ Python {version.major}.{version.minor}.{version.micro}\")\n",
    "            return True\n",
    "        else:\n",
    "            self.errors.append(f\"‚ùå Python {version.major}.{version.minor} not supported (ÈúÄË¶Å ‚â• 3.8)\")\n",
    "            return False\n",
    "\n",
    "    def check_required_packages(self) -> bool:\n",
    "        \"\"\"Check required Python packages\"\"\"\n",
    "        required_packages = [\n",
    "            \"torch\", \"transformers\", \"sentence_transformers\",\n",
    "            \"faiss\", \"fastapi\", \"uvicorn\", \"gradio\",\n",
    "            \"pydantic\", \"opencc\", \"trafilatura\"\n",
    "        ]\n",
    "\n",
    "        missing = []\n",
    "        for package in required_packages:\n",
    "            try:\n",
    "                importlib.import_module(package.replace(\"-\", \"_\"))\n",
    "                self.success.append(f\"‚úÖ {package}\")\n",
    "            except ImportError:\n",
    "                missing.append(package)\n",
    "\n",
    "        if missing:\n",
    "            self.errors.append(f\"‚ùå Missing packages: {', '.join(missing)}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def check_environment_variables(self) -> bool:\n",
    "        \"\"\"Check required environment variables\"\"\"\n",
    "        required_vars = {\n",
    "            \"MODEL_ID\": \"LLM model identifier\",\n",
    "            \"BACKEND\": \"LLM backend (transformers/llama_cpp/ollama)\",\n",
    "            \"AI_CACHE_ROOT\": \"Cache directory path\",\n",
    "            \"API_PORT\": \"API server port\"\n",
    "        }\n",
    "\n",
    "        missing = []\n",
    "        for var, desc in required_vars.items():\n",
    "            value = os.getenv(var)\n",
    "            if value:\n",
    "                self.success.append(f\"‚úÖ {var}={value}\")\n",
    "            else:\n",
    "                missing.append(f\"{var} ({desc})\")\n",
    "\n",
    "        if missing:\n",
    "            self.errors.append(f\"‚ùå Missing env vars: {', '.join(missing)}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def check_docker_availability(self) -> bool:\n",
    "        \"\"\"Check Docker and docker-compose availability\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run([\"docker\", \"--version\"],\n",
    "                                  capture_output=True, text=True, check=True)\n",
    "            self.success.append(f\"‚úÖ {result.stdout.strip()}\")\n",
    "\n",
    "            result = subprocess.run([\"docker-compose\", \"--version\"],\n",
    "                                  capture_output=True, text=True, check=True)\n",
    "            self.success.append(f\"‚úÖ {result.stdout.strip()}\")\n",
    "            return True\n",
    "\n",
    "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "            self.errors.append(\"‚ùå Docker or docker-compose not available\")\n",
    "            return False\n",
    "\n",
    "    def check_file_structure(self) -> bool:\n",
    "        \"\"\"Check required file structure\"\"\"\n",
    "        required_files = [\n",
    "            \"Dockerfile\",\n",
    "            \"docker-compose.yml\",\n",
    "            \".env.example\",\n",
    "            \"requirements.txt\",\n",
    "            \"shared_utils/__init__.py\",\n",
    "            \"apps/api/main.py\"\n",
    "        ]\n",
    "\n",
    "        missing = []\n",
    "        for file_path in required_files:\n",
    "            if pathlib.Path(file_path).exists():\n",
    "                self.success.append(f\"‚úÖ {file_path}\")\n",
    "            else:\n",
    "                missing.append(file_path)\n",
    "\n",
    "        if missing:\n",
    "            self.errors.append(f\"‚ùå Missing files: {', '.join(missing)}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def check_gpu_availability(self) -> bool:\n",
    "        \"\"\"Check GPU availability and CUDA\"\"\"\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_count = torch.cuda.device_count()\n",
    "                gpu_name = torch.cuda.get_device_name(0)\n",
    "                memory_mb = torch.cuda.get_device_properties(0).total_memory // 1024**2\n",
    "\n",
    "                self.success.append(f\"‚úÖ GPU: {gpu_name} ({memory_mb}MB)\")\n",
    "\n",
    "                if memory_mb < 8192:  # 8GB\n",
    "                    self.warnings.append(f\"‚ö†Ô∏è  GPU memory ({memory_mb}MB) may be insufficient for large models\")\n",
    "\n",
    "                return True\n",
    "            else:\n",
    "                self.warnings.append(\"‚ö†Ô∏è  No GPU available - will use CPU (slower)\")\n",
    "                return True\n",
    "\n",
    "        except ImportError:\n",
    "            self.errors.append(\"‚ùå PyTorch not available for GPU check\")\n",
    "            return False\n",
    "\n",
    "    def generate_report(self) -> Dict:\n",
    "        \"\"\"Generate comprehensive validation report\"\"\"\n",
    "        report = {\n",
    "            \"timestamp\": __import__(\"time\").time(),\n",
    "            \"python_version\": f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "            \"success_count\": len(self.success),\n",
    "            \"warning_count\": len(self.warnings),\n",
    "            \"error_count\": len(self.errors),\n",
    "            \"success\": self.success,\n",
    "            \"warnings\": self.warnings,\n",
    "            \"errors\": self.errors,\n",
    "            \"deployment_ready\": len(self.errors) == 0\n",
    "        }\n",
    "\n",
    "        return report\n",
    "\n",
    "    def run_all_checks(self) -> bool:\n",
    "        \"\"\"Run all validation checks\"\"\"\n",
    "        print(\"üîç Running ragent-text-lab environment validation...\\n\")\n",
    "\n",
    "        checks = [\n",
    "            (\"Python Version\", self.check_python_version),\n",
    "            (\"Required Packages\", self.check_required_packages),\n",
    "            (\"Environment Variables\", self.check_environment_variables),\n",
    "            (\"File Structure\", self.check_file_structure),\n",
    "            (\"GPU Availability\", self.check_gpu_availability),\n",
    "            (\"Docker Availability\", self.check_docker_availability),\n",
    "        ]\n",
    "\n",
    "        all_passed = True\n",
    "        for check_name, check_func in checks:\n",
    "            print(f\"üìã {check_name}...\")\n",
    "            try:\n",
    "                passed = check_func()\n",
    "                if not passed:\n",
    "                    all_passed = False\n",
    "            except Exception as e:\n",
    "                self.errors.append(f\"‚ùå {check_name} check failed: {e}\")\n",
    "                all_passed = False\n",
    "            print()\n",
    "\n",
    "        return all_passed\n",
    "\n",
    "def main():\n",
    "    validator = EnvironmentValidator()\n",
    "    success = validator.run_all_checks()\n",
    "\n",
    "    # Generate report\n",
    "    report = validator.generate_report()\n",
    "\n",
    "    # Print summary\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä VALIDATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for item in report[\"success\"]:\n",
    "        print(item)\n",
    "\n",
    "    for item in report[\"warnings\"]:\n",
    "        print(item)\n",
    "\n",
    "    for item in report[\"errors\"]:\n",
    "        print(item)\n",
    "\n",
    "    print(f\"\\nüéØ Result: {'READY FOR DEPLOYMENT' if success else 'NEEDS ATTENTION'}\")\n",
    "\n",
    "    # Save report\n",
    "    report_path = pathlib.Path(\"outs/validation_report.json\")\n",
    "    report_path.parent.mkdir(exist_ok=True)\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"üìÑ Detailed report saved to {report_path}\")\n",
    "\n",
    "    return 0 if success else 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())\n",
    "'''\n",
    "\n",
    "    validate_path = pathlib.Path(\"scripts/validate_env.py\")\n",
    "    validate_path.write_text(validate_script, encoding=\"utf-8\")\n",
    "    validate_path.chmod(0o755)\n",
    "    print(f\"‚úÖ Created validation script at {validate_path}\")\n",
    "\n",
    "    return startup_script, validate_script\n",
    "\n",
    "\n",
    "# Create startup and validation scripts\n",
    "startup_content, validate_content = create_startup_scripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 7: Nginx Configuration for Production\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_nginx_config():\n",
    "    \"\"\"Create nginx configuration for production deployment\"\"\"\n",
    "\n",
    "    nginx_config = \"\"\"# ragent-text-lab Nginx Configuration\n",
    "# Production-ready reverse proxy with SSL support\n",
    "\n",
    "events {\n",
    "    worker_connections 1024;\n",
    "}\n",
    "\n",
    "http {\n",
    "    # Basic Settings\n",
    "    sendfile on;\n",
    "    tcp_nopush on;\n",
    "    tcp_nodelay on;\n",
    "    keepalive_timeout 65;\n",
    "    types_hash_max_size 2048;\n",
    "\n",
    "    # MIME Types\n",
    "    include /etc/nginx/mime.types;\n",
    "    default_type application/octet-stream;\n",
    "\n",
    "    # Logging\n",
    "    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "                    '$status $body_bytes_sent \"$http_referer\" '\n",
    "                    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n",
    "\n",
    "    access_log /var/log/nginx/access.log main;\n",
    "    error_log /var/log/nginx/error.log;\n",
    "\n",
    "    # Gzip Compression\n",
    "    gzip on;\n",
    "    gzip_vary on;\n",
    "    gzip_min_length 10240;\n",
    "    gzip_proxied expired no-cache no-store private must-revalidate auth;\n",
    "    gzip_types\n",
    "        text/plain\n",
    "        text/css\n",
    "        text/xml\n",
    "        text/javascript\n",
    "        application/json\n",
    "        application/javascript\n",
    "        application/xml+rss\n",
    "        application/atom+xml\n",
    "        image/svg+xml;\n",
    "\n",
    "    # Rate Limiting\n",
    "    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n",
    "    limit_req_zone $binary_remote_addr zone=ui:10m rate=5r/s;\n",
    "\n",
    "    # Upstream Services\n",
    "    upstream ragent_api {\n",
    "        server ragent-api:8000;\n",
    "        keepalive 32;\n",
    "    }\n",
    "\n",
    "    upstream ragent_ui {\n",
    "        server ragent-ui:7860;\n",
    "        keepalive 16;\n",
    "    }\n",
    "\n",
    "    # ===========================================\n",
    "    # HTTP to HTTPS Redirect\n",
    "    # ===========================================\n",
    "    server {\n",
    "        listen 80;\n",
    "        server_name _;\n",
    "        return 301 https://$host$request_uri;\n",
    "    }\n",
    "\n",
    "    # ===========================================\n",
    "    # Main HTTPS Server\n",
    "    # ===========================================\n",
    "    server {\n",
    "        listen 443 ssl http2;\n",
    "        server_name _;\n",
    "\n",
    "        # SSL Configuration\n",
    "        ssl_certificate /etc/nginx/ssl/cert.pem;\n",
    "        ssl_certificate_key /etc/nginx/ssl/key.pem;\n",
    "        ssl_protocols TLSv1.2 TLSv1.3;\n",
    "        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;\n",
    "        ssl_prefer_server_ciphers off;\n",
    "\n",
    "        # Security Headers\n",
    "        add_header Strict-Transport-Security \"max-age=63072000\" always;\n",
    "        add_header X-Frame-Options DENY;\n",
    "        add_header X-Content-Type-Options nosniff;\n",
    "        add_header X-XSS-Protection \"1; mode=block\";\n",
    "        add_header Referrer-Policy \"strict-origin-when-cross-origin\";\n",
    "\n",
    "        # ===========================================\n",
    "        # API Routes\n",
    "        # ===========================================\n",
    "        location /api/ {\n",
    "            limit_req zone=api burst=20 nodelay;\n",
    "\n",
    "            proxy_pass http://ragent_api/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "\n",
    "            # Timeouts\n",
    "            proxy_connect_timeout 60s;\n",
    "            proxy_send_timeout 300s;\n",
    "            proxy_read_timeout 300s;\n",
    "\n",
    "            # Buffering\n",
    "            proxy_buffering on;\n",
    "            proxy_buffer_size 4k;\n",
    "            proxy_buffers 8 4k;\n",
    "            proxy_busy_buffers_size 8k;\n",
    "\n",
    "            # WebSocket Support\n",
    "            proxy_http_version 1.1;\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "        }\n",
    "\n",
    "        # Health Check (no rate limit)\n",
    "        location /health {\n",
    "            proxy_pass http://ragent_api/health;\n",
    "            proxy_set_header Host $host;\n",
    "            access_log off;\n",
    "        }\n",
    "\n",
    "        # Metrics (restrict access)\n",
    "        location /metrics {\n",
    "            allow 127.0.0.1;\n",
    "            allow 10.0.0.0/8;\n",
    "            allow 172.16.0.0/12;\n",
    "            allow 192.168.0.0/16;\n",
    "            deny all;\n",
    "\n",
    "            proxy_pass http://ragent_api/metrics;\n",
    "            proxy_set_header Host $host;\n",
    "        }\n",
    "\n",
    "        # ===========================================\n",
    "        # UI Routes\n",
    "        # ===========================================\n",
    "        location / {\n",
    "            limit_req zone=ui burst=10 nodelay;\n",
    "\n",
    "            proxy_pass http://ragent_ui/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "\n",
    "            # WebSocket Support for Gradio\n",
    "            proxy_http_version 1.1;\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "\n",
    "            # Timeouts\n",
    "            proxy_connect_timeout 60s;\n",
    "            proxy_send_timeout 60s;\n",
    "            proxy_read_timeout 60s;\n",
    "        }\n",
    "\n",
    "        # Static Files (if any)\n",
    "        location /static/ {\n",
    "            expires 1y;\n",
    "            add_header Cache-Control \"public, immutable\";\n",
    "            try_files $uri =404;\n",
    "        }\n",
    "\n",
    "        # Favicon\n",
    "        location = /favicon.ico {\n",
    "            access_log off;\n",
    "            log_not_found off;\n",
    "            expires 1y;\n",
    "        }\n",
    "\n",
    "        # Security.txt\n",
    "        location = /.well-known/security.txt {\n",
    "            return 200 \"Contact: security@yourcompany.com\\nExpires: 2025-12-31T23:59:59.000Z\\n\";\n",
    "            add_header Content-Type text/plain;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    nginx_path = pathlib.Path(\"nginx.conf\")\n",
    "    nginx_path.write_text(nginx_config.strip(), encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ Created nginx configuration at {nginx_path}\")\n",
    "\n",
    "    return nginx_config\n",
    "\n",
    "\n",
    "# Create nginx configuration\n",
    "nginx_content = create_nginx_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 8: Smoke Test - Container Startup & Validation\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def run_deployment_smoke_test():\n",
    "    \"\"\"Comprehensive smoke test for deployment setup\"\"\"\n",
    "\n",
    "    print(\"üß™ Running Deployment Smoke Test\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Test 1: Environment validation\n",
    "    print(\"\\nüìã Test 1: Environment Validation\")\n",
    "    try:\n",
    "        # Load environment from .env.example\n",
    "        env_vars = {}\n",
    "        env_example_path = pathlib.Path(\".env.example\")\n",
    "        if env_example_path.exists():\n",
    "            for line in env_example_path.read_text().split(\"\\n\"):\n",
    "                if \"=\" in line and not line.startswith(\"#\"):\n",
    "                    key, value = line.split(\"=\", 1)\n",
    "                    env_vars[key.strip()] = value.strip()\n",
    "\n",
    "        required_keys = [\"MODEL_ID\", \"BACKEND\", \"API_PORT\", \"AI_CACHE_ROOT\"]\n",
    "        missing = [k for k in required_keys if k not in env_vars]\n",
    "\n",
    "        if missing:\n",
    "            print(f\"‚ùå Missing environment variables: {missing}\")\n",
    "        else:\n",
    "            print(\"‚úÖ Environment template validation passed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Environment validation failed: {e}\")\n",
    "\n",
    "    # Test 2: Docker files validation\n",
    "    print(\"\\nüê≥ Test 2: Docker Configuration\")\n",
    "    docker_files = [\"Dockerfile\", \"docker-compose.yml\"]\n",
    "    for file_name in docker_files:\n",
    "        file_path = pathlib.Path(file_name)\n",
    "        if file_path.exists():\n",
    "            size_kb = file_path.stat().st_size / 1024\n",
    "            print(f\"‚úÖ {file_name} ({size_kb:.1f}KB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Missing {file_name}\")\n",
    "\n",
    "    # Test 3: Security configuration test\n",
    "    print(\"\\nüîí Test 3: Security Configuration\")\n",
    "    try:\n",
    "        security_path = pathlib.Path(\"shared_utils/api/security.py\")\n",
    "        if security_path.exists():\n",
    "            security_content = security_path.read_text()\n",
    "            security_features = [\n",
    "                \"RateLimitMiddleware\",\n",
    "                \"SecurityHeadersMiddleware\",\n",
    "                \"CORSMiddleware\",\n",
    "                \"TrustedHostMiddleware\",\n",
    "            ]\n",
    "\n",
    "            found_features = [f for f in security_features if f in security_content]\n",
    "            print(\n",
    "                f\"‚úÖ Security features: {len(found_features)}/{len(security_features)}\"\n",
    "            )\n",
    "\n",
    "            if len(found_features) < len(security_features):\n",
    "                missing = set(security_features) - set(found_features)\n",
    "                print(f\"‚ö†Ô∏è  Missing security features: {missing}\")\n",
    "        else:\n",
    "            print(\"‚ùå Security middleware not found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Security validation failed: {e}\")\n",
    "\n",
    "    # Test 4: Startup scripts validation\n",
    "    print(\"\\nüöÄ Test 4: Startup Scripts\")\n",
    "    scripts = [\n",
    "        (\"scripts/startup.sh\", \"startup script\"),\n",
    "        (\"scripts/validate_env.py\", \"environment validator\"),\n",
    "    ]\n",
    "\n",
    "    for script_path, description in scripts:\n",
    "        path = pathlib.Path(script_path)\n",
    "        if path.exists():\n",
    "            # Check if executable\n",
    "            is_executable = path.stat().st_mode & 0o111\n",
    "            status = \"‚úÖ\" if is_executable else \"‚ö†Ô∏è \"\n",
    "            print(f\"{status} {description}: {script_path}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Missing {description}: {script_path}\")\n",
    "\n",
    "    # Test 5: Production readiness checklist\n",
    "    print(\"\\nüéØ Test 5: Production Readiness\")\n",
    "    production_items = [\n",
    "        (\"Health check endpoint\", \"/health\"),\n",
    "        (\"Metrics endpoint\", \"/metrics\"),\n",
    "        (\"CORS configuration\", \"CORS_ORIGINS\"),\n",
    "        (\"Rate limiting\", \"RATE_LIMIT_REQUESTS\"),\n",
    "        (\"Security headers\", \"SecurityHeadersMiddleware\"),\n",
    "        (\"Nginx configuration\", \"nginx.conf\"),\n",
    "        (\"SSL support\", \"ssl_certificate\"),\n",
    "        (\"Docker multi-stage\", \"FROM.*as.*production\"),\n",
    "    ]\n",
    "\n",
    "    ready_count = 0\n",
    "    for item, check in production_items:\n",
    "        # Simple existence checks for production features\n",
    "        found = False\n",
    "\n",
    "        if check.startswith(\"/\"):\n",
    "            # Check if endpoint exists in security.py\n",
    "            security_path = pathlib.Path(\"shared_utils/api/security.py\")\n",
    "            if security_path.exists() and check in security_path.read_text():\n",
    "                found = True\n",
    "        elif check.endswith(\".conf\"):\n",
    "            # Check if config file exists\n",
    "            found = pathlib.Path(check).exists()\n",
    "        elif \"=\" not in check and check in globals().get(\"security_code\", \"\"):\n",
    "            # Check for middleware/feature in security code\n",
    "            found = True\n",
    "        elif check in env_vars:\n",
    "            # Check for environment variable\n",
    "            found = True\n",
    "        elif \"FROM\" in check:\n",
    "            # Check Dockerfile for multi-stage\n",
    "            dockerfile = pathlib.Path(\"Dockerfile\")\n",
    "            if dockerfile.exists() and \"as production\" in dockerfile.read_text():\n",
    "                found = True\n",
    "\n",
    "        if found:\n",
    "            ready_count += 1\n",
    "            print(f\"‚úÖ {item}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {item}\")\n",
    "\n",
    "    # Final assessment\n",
    "    print(f\"\\nüìä Production Readiness: {ready_count}/{len(production_items)} items\")\n",
    "\n",
    "    if ready_count >= len(production_items) * 0.8:  # 80% threshold\n",
    "        print(\"üéâ DEPLOYMENT READY - ÂèØ‰ª•ÈÄ≤Ë°åÁîüÁî¢ÈÉ®ÁΩ≤\")\n",
    "        deployment_status = \"READY\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  NEEDS ATTENTION - ÈúÄË¶ÅÂÆåÂñÑÈÖçÁΩÆÂæåÈÉ®ÁΩ≤\")\n",
    "        deployment_status = \"NEEDS_WORK\"\n",
    "\n",
    "    # Generate deployment report\n",
    "    report = {\n",
    "        \"timestamp\": __import__(\"time\").time(),\n",
    "        \"deployment_status\": deployment_status,\n",
    "        \"readiness_score\": f\"{ready_count}/{len(production_items)}\",\n",
    "        \"environment_vars_count\": len(env_vars),\n",
    "        \"docker_files_ready\": len(\n",
    "            [f for f in docker_files if pathlib.Path(f).exists()]\n",
    "        ),\n",
    "        \"security_features\": len(found_features) if \"found_features\" in locals() else 0,\n",
    "        \"production_readiness\": ready_count / len(production_items),\n",
    "    }\n",
    "\n",
    "    report_path = pathlib.Path(\"outs/deployment_report.json\")\n",
    "    report_path.parent.mkdir(exist_ok=True)\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        __import__(\"json\").dump(report, f, indent=2)\n",
    "\n",
    "    print(f\"\\nüìÑ Deployment report saved to {report_path}\")\n",
    "\n",
    "    return deployment_status == \"READY\"\n",
    "\n",
    "\n",
    "# Run comprehensive smoke test\n",
    "deployment_ready = run_deployment_smoke_test()\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "\n",
    "üéØ **Stage 8 Complete: Docker Deployment & Production Setup**\n",
    "\n",
    "## ÂÆåÊàêÈ†ÖÁõÆ Completed Features\n",
    "‚úÖ **Áí∞Â¢ÉÈÖçÁΩÆ**: .env.example Ê®°ÊùøËàáËÆäÊï∏ÁÆ°ÁêÜ\n",
    "‚úÖ **ÂÆπÂô®Âåñ**: Â§öÈöéÊÆµ Dockerfile Ëàá docker-compose Á∑®Êéí\n",
    "‚úÖ **ÂÆâÂÖ®Èò≤Ë≠∑**: CORS„ÄÅÈÄüÁéáÈôêÂà∂„ÄÅÂÆâÂÖ®Ê®ôÈ†≠‰∏≠‰ªãËªüÈ´î\n",
    "‚úÖ **Áõ£ÊéßÂÅ•Ê™¢**: /health Ëàá /metrics Á´ØÈªû\n",
    "‚úÖ **ÁîüÁî¢ÈÉ®ÁΩ≤**: Nginx ÂèçÂêë‰ª£ÁêÜËàá SSL ÊîØÊè¥\n",
    "‚úÖ **Ëá™ÂãïÂåñËÖ≥Êú¨**: ÂïüÂãïËàáÁí∞Â¢ÉÈ©óË≠âËÖ≥Êú¨\n",
    "\n",
    "## Ê†∏ÂøÉÊ¶ÇÂøµ Key Concepts\n",
    "- **Multi-stage Docker builds** ÊúÄ‰Ω≥ÂåñÊò†ÂÉèÊ™îÂ§ßÂ∞èËàáÂÆâÂÖ®ÊÄß\n",
    "- **Environment-driven configuration** Áí∞Â¢ÉËÆäÊï∏È©ÖÂãïÁöÑÈÖçÁΩÆÁÆ°ÁêÜ\n",
    "- **Production security middleware** ÁîüÁî¢Á¥öÂÆâÂÖ®Èò≤Ë≠∑Ê©üÂà∂\n",
    "- **Container orchestration** Â§öÊúçÂãôÂÆπÂô®Á∑®Êéí\n",
    "- **Health monitoring & metrics** ÊúçÂãôÂÅ•Â∫∑Áõ£ÊéßËàáÊåáÊ®ô\n",
    "\n",
    "## Â∏∏Ë¶ãÈô∑Èò± Pitfalls\n",
    "‚ö†Ô∏è **Ë®òÊÜ∂È´îÈôêÂà∂**: ÂÆπÂô®Ë®òÊÜ∂È´îÈÖçÁΩÆÈúÄËÄÉÊÖÆÊ®°ÂûãÂ§ßÂ∞è (Âª∫Ë≠∞ ‚â•8GB)\n",
    "‚ö†Ô∏è **Âø´ÂèñÊéõËºâ**: AI_CACHE_ROOT ÈúÄÊ≠£Á¢∫ÊéõËºâÈÅøÂÖçÈáçË§á‰∏ãËºâ\n",
    "‚ö†Ô∏è **Ê¨äÈôêÂïèÈ°å**: ÂÆπÂô®ÂÖßÊ™îÊ°àÊ¨äÈôêËàá‰∏ªÊ©üÁî®Êà∂Êò†Â∞Ñ\n",
    "‚ö†Ô∏è **Á∂≤Ë∑ØÈÖçÁΩÆ**: ÂÆπÂô®ÈñìÈÄöË®äËàáÂ§ñÈÉ®Â≠òÂèñÁ´ØÂè£Ë®≠ÂÆö\n",
    "‚ö†Ô∏è **SSL ÊÜëË≠â**: ÁîüÁî¢Áí∞Â¢ÉÈúÄÈÖçÁΩÆÊúâÊïà SSL ÊÜëË≠â\n",
    "\n",
    "## ‰ΩøÁî®ÊôÇÊ©ü When to Use\n",
    "üéØ **ÁîüÁî¢ÈÉ®ÁΩ≤**: Ê≠£ÂºèÁí∞Â¢ÉÁöÑÂÆπÂô®ÂåñÈÉ®ÁΩ≤\n",
    "üéØ **ÈñãÁôºÁí∞Â¢É**: Áµ±‰∏ÄÁöÑÈñãÁôºÁí∞Â¢ÉÈÖçÁΩÆ\n",
    "üéØ **CI/CD**: Ëá™ÂãïÂåñÂª∫ÊßãËàáÈÉ®ÁΩ≤ÊµÅÁ®ã\n",
    "üéØ **Êì¥Â±ïÈÉ®ÁΩ≤**: Â§öÂØ¶‰æãË≤†ËºâÂùáË°°ÈÉ®ÁΩ≤\n",
    "üéØ **Èõ≤Á´ØÈÉ®ÁΩ≤**: Èõ≤Âπ≥Âè∞ÂÆπÂô®ÊúçÂãôÈÉ®ÁΩ≤\n",
    "\n",
    "## ‰∏ã‰∏ÄÊ≠• Next Steps\n",
    "üöÄ Ë®≠ÂÆö SSL ÊÜëË≠âËàáÂüüÂêç\n",
    "üöÄ ÈÖçÁΩÆÁõ£ÊéßÂëäË≠¶Á≥ªÁµ± (Prometheus + Grafana)\n",
    "üöÄ Âª∫Á´ã CI/CD Ëá™ÂãïÂåñÊµÅÁ®ã\n",
    "üöÄ ÊïàËÉΩË™øÂÑ™ËàáÊì¥Â±ïÁ≠ñÁï•\n",
    "üöÄ ÂÇô‰ªΩËàáÁÅΩÂÆ≥Âæ©ÂéüË®àÁï´\n",
    "\n",
    "ÈÉ®ÁΩ≤ÁãÄÊÖã: {'üéâ READY FOR PRODUCTION' if deployment_ready else '‚ö†Ô∏è NEEDS CONFIGURATION'}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# üéØ End of nb73_dockerfile_and_env.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
