{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b132a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (複製到每本 notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Dependencies for monitoring and metrics\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Optional, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# GPU monitoring (optional, graceful fallback)\n",
    "try:\n",
    "    import pynvml\n",
    "\n",
    "    pynvml.nvmlInit()\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"[Monitor] GPU monitoring enabled via pynvml\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"[Monitor] GPU monitoring disabled (install nvidia-ml-py3 for VRAM tracking)\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "Path(\"outs\").mkdir(exist_ok=True)\n",
    "print(\"[Setup] Output directory ready: outs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Structured logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(\"outs/llm_metrics.log\", encoding=\"utf-8\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"LLMMetrics\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MetricsSnapshot:\n",
    "    \"\"\"Single measurement snapshot\"\"\"\n",
    "\n",
    "    timestamp: str\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    total_tokens: int\n",
    "    latency_ms: float\n",
    "    tokens_per_second: float\n",
    "    cpu_percent: float\n",
    "    memory_mb: float\n",
    "    gpu_memory_mb: Optional[float] = None\n",
    "    model_id: str = \"\"\n",
    "    backend: str = \"\"\n",
    "    temperature: float = 0.0\n",
    "    max_new_tokens: int = 0\n",
    "\n",
    "\n",
    "class PerformanceProfiler:\n",
    "    \"\"\"Lightweight profiler for LLM inference\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.snapshots: List[MetricsSnapshot] = []\n",
    "        self.process = psutil.Process()\n",
    "\n",
    "    def get_gpu_memory_mb(self) -> Optional[float]:\n",
    "        \"\"\"Get current GPU memory usage in MB\"\"\"\n",
    "        if not GPU_AVAILABLE:\n",
    "            return None\n",
    "        try:\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # First GPU\n",
    "            info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "            return info.used / 1024**2  # Convert to MB\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"GPU memory query failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def start_measurement(self):\n",
    "        \"\"\"Mark start of measurement period\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.start_cpu = self.process.cpu_percent()\n",
    "        self.start_memory = self.process.memory_info().rss / 1024**2\n",
    "        self.start_gpu = self.get_gpu_memory_mb()\n",
    "\n",
    "    def end_measurement(\n",
    "        self,\n",
    "        prompt_tokens: int,\n",
    "        completion_tokens: int,\n",
    "        model_id: str,\n",
    "        backend: str,\n",
    "        temperature: float,\n",
    "        max_new_tokens: int,\n",
    "    ) -> MetricsSnapshot:\n",
    "        \"\"\"End measurement and create snapshot\"\"\"\n",
    "        end_time = time.time()\n",
    "        latency_ms = (end_time - self.start_time) * 1000\n",
    "\n",
    "        # Calculate tokens/sec (avoid division by zero)\n",
    "        total_tokens = prompt_tokens + completion_tokens\n",
    "        tokens_per_second = completion_tokens / max(0.001, (end_time - self.start_time))\n",
    "\n",
    "        snapshot = MetricsSnapshot(\n",
    "            timestamp=datetime.now().isoformat(),\n",
    "            prompt_tokens=prompt_tokens,\n",
    "            completion_tokens=completion_tokens,\n",
    "            total_tokens=total_tokens,\n",
    "            latency_ms=latency_ms,\n",
    "            tokens_per_second=tokens_per_second,\n",
    "            cpu_percent=self.process.cpu_percent(),\n",
    "            memory_mb=self.process.memory_info().rss / 1024**2,\n",
    "            gpu_memory_mb=self.get_gpu_memory_mb(),\n",
    "            model_id=model_id,\n",
    "            backend=backend,\n",
    "            temperature=temperature,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "\n",
    "        self.snapshots.append(snapshot)\n",
    "        logger.info(\n",
    "            f\"Metrics: {latency_ms:.1f}ms | {tokens_per_second:.1f} tok/s | {total_tokens} tokens\"\n",
    "        )\n",
    "        return snapshot\n",
    "\n",
    "\n",
    "profiler = PerformanceProfiler()\n",
    "print(\"[Profiler] Performance profiler initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Enhanced LLMAdapter with metrics integration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "class MetricsLLMAdapter:\n",
    "    \"\"\"LLMAdapter with built-in performance monitoring\"\"\"\n",
    "\n",
    "    def __init__(self, model_id: str, backend: str = \"transformers\", **kwargs):\n",
    "        self.model_id = model_id\n",
    "        self.backend = backend\n",
    "\n",
    "        # Load model with low-VRAM defaults\n",
    "        logger.info(f\"Loading model: {model_id}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "\n",
    "        # Add padding token if missing\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,  # Lower VRAM\n",
    "            low_cpu_mem_usage=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model loaded on device: {self.model.device}\")\n",
    "\n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in text\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "\n",
    "    def generate_with_metrics(\n",
    "        self,\n",
    "        messages: List[Dict],\n",
    "        max_new_tokens: int = 256,\n",
    "        temperature: float = 0.7,\n",
    "        **kwargs,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Generate text with automatic metrics collection\"\"\"\n",
    "\n",
    "        # Convert messages to prompt\n",
    "        prompt = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in messages)\n",
    "        prompt_tokens = self.count_tokens(prompt)\n",
    "\n",
    "        # Start profiling\n",
    "        profiler.start_measurement()\n",
    "\n",
    "        try:\n",
    "            # Tokenize input\n",
    "            inputs = self.tokenizer(\n",
    "                prompt, return_tensors=\"pt\", truncation=True, max_length=3072\n",
    "            )\n",
    "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "\n",
    "            # Generate\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    do_sample=temperature > 0,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    **kwargs,\n",
    "                )\n",
    "\n",
    "            # Decode only the new tokens\n",
    "            new_tokens = outputs[0][len(inputs[\"input_ids\"][0]) :]\n",
    "            completion = self.tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "            completion_tokens = len(new_tokens)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Generation failed: {e}\")\n",
    "            completion = f\"[Error: {str(e)}]\"\n",
    "            completion_tokens = 0\n",
    "\n",
    "        # End profiling\n",
    "        snapshot = profiler.end_measurement(\n",
    "            prompt_tokens=prompt_tokens,\n",
    "            completion_tokens=completion_tokens,\n",
    "            model_id=self.model_id,\n",
    "            backend=self.backend,\n",
    "            temperature=temperature,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "\n",
    "        return {\"completion\": completion, \"metrics\": asdict(snapshot), \"prompt\": prompt}\n",
    "\n",
    "\n",
    "# Test with a small model if available, fallback to demo\n",
    "try:\n",
    "    # Use smaller model for baseline testing\n",
    "    model_id = os.getenv(\n",
    "        \"MODEL_ID\", \"microsoft/DialoGPT-small\"\n",
    "    )  # Fallback to small model\n",
    "    adapter = MetricsLLMAdapter(model_id)\n",
    "    print(f\"[Adapter] Loaded model: {model_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warning] Could not load model: {e}\")\n",
    "    print(\"[Info] Continuing with mock adapter for demo\")\n",
    "    adapter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Enhanced LLMAdapter with metrics integration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "class MetricsLLMAdapter:\n",
    "    \"\"\"LLMAdapter with built-in performance monitoring\"\"\"\n",
    "\n",
    "    def __init__(self, model_id: str, backend: str = \"transformers\", **kwargs):\n",
    "        self.model_id = model_id\n",
    "        self.backend = backend\n",
    "\n",
    "        # Load model with low-VRAM defaults\n",
    "        logger.info(f\"Loading model: {model_id}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "\n",
    "        # Add padding token if missing\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,  # Lower VRAM\n",
    "            low_cpu_mem_usage=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model loaded on device: {self.model.device}\")\n",
    "\n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in text\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "\n",
    "    def generate_with_metrics(\n",
    "        self,\n",
    "        messages: List[Dict],\n",
    "        max_new_tokens: int = 256,\n",
    "        temperature: float = 0.7,\n",
    "        **kwargs,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Generate text with automatic metrics collection\"\"\"\n",
    "\n",
    "        # Convert messages to prompt\n",
    "        prompt = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in messages)\n",
    "        prompt_tokens = self.count_tokens(prompt)\n",
    "\n",
    "        # Start profiling\n",
    "        profiler.start_measurement()\n",
    "\n",
    "        try:\n",
    "            # Tokenize input\n",
    "            inputs = self.tokenizer(\n",
    "                prompt, return_tensors=\"pt\", truncation=True, max_length=3072\n",
    "            )\n",
    "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "\n",
    "            # Generate\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    do_sample=temperature > 0,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    **kwargs,\n",
    "                )\n",
    "\n",
    "            # Decode only the new tokens\n",
    "            new_tokens = outputs[0][len(inputs[\"input_ids\"][0]) :]\n",
    "            completion = self.tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "            completion_tokens = len(new_tokens)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Generation failed: {e}\")\n",
    "            completion = f\"[Error: {str(e)}]\"\n",
    "            completion_tokens = 0\n",
    "\n",
    "        # End profiling\n",
    "        snapshot = profiler.end_measurement(\n",
    "            prompt_tokens=prompt_tokens,\n",
    "            completion_tokens=completion_tokens,\n",
    "            model_id=self.model_id,\n",
    "            backend=self.backend,\n",
    "            temperature=temperature,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "\n",
    "        return {\"completion\": completion, \"metrics\": asdict(snapshot), \"prompt\": prompt}\n",
    "\n",
    "\n",
    "# Test with a small model if available, fallback to demo\n",
    "try:\n",
    "    # Use smaller model for baseline testing\n",
    "    model_id = os.getenv(\n",
    "        \"MODEL_ID\", \"microsoft/DialoGPT-small\"\n",
    "    )  # Fallback to small model\n",
    "    adapter = MetricsLLMAdapter(model_id)\n",
    "    print(f\"[Adapter] Loaded model: {model_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warning] Could not load model: {e}\")\n",
    "    print(\"[Info] Continuing with mock adapter for demo\")\n",
    "    adapter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Baseline test suite\n",
    "test_messages = [\n",
    "    [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n",
    "    [{\"role\": \"user\", \"content\": \"解釋什麼是人工智慧。\"}],\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a short poem about technology.\"},\n",
    "    ],\n",
    "]\n",
    "\n",
    "baseline_results = []\n",
    "\n",
    "if adapter:\n",
    "    print(\"[Baseline] Running performance tests...\")\n",
    "\n",
    "    for i, messages in enumerate(test_messages):\n",
    "        print(f\"\\n--- Test {i+1}/3 ---\")\n",
    "\n",
    "        result = adapter.generate_with_metrics(\n",
    "            messages=messages, max_new_tokens=100, temperature=0.7\n",
    "        )\n",
    "\n",
    "        baseline_results.append(result)\n",
    "        print(f\"Output: {result['completion'][:100]}...\")\n",
    "        print(\n",
    "            f\"Metrics: {result['metrics']['latency_ms']:.1f}ms, {result['metrics']['tokens_per_second']:.1f} tok/s\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[Baseline] Completed {len(baseline_results)} tests\")\n",
    "else:\n",
    "    print(\"[Demo] Creating mock baseline results...\")\n",
    "    for i, messages in enumerate(test_messages):\n",
    "        mock_result = {\n",
    "            \"completion\": f\"Mock response {i+1}\",\n",
    "            \"metrics\": {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"prompt_tokens\": 20,\n",
    "                \"completion_tokens\": 50,\n",
    "                \"total_tokens\": 70,\n",
    "                \"latency_ms\": 1500.0,\n",
    "                \"tokens_per_second\": 33.3,\n",
    "                \"cpu_percent\": 25.0,\n",
    "                \"memory_mb\": 2048.0,\n",
    "                \"gpu_memory_mb\": 1024.0 if GPU_AVAILABLE else None,\n",
    "                \"model_id\": \"mock_model\",\n",
    "                \"backend\": \"transformers\",\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_new_tokens\": 100,\n",
    "            },\n",
    "            \"prompt\": f\"Mock prompt {i+1}\",\n",
    "        }\n",
    "        baseline_results.append(mock_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde526fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Smoke test - quick validation\n",
    "print(\"[Smoke Test] Validating metrics collection...\")\n",
    "\n",
    "if baseline_results:\n",
    "    sample = baseline_results[0][\"metrics\"]\n",
    "\n",
    "    # Validate required fields\n",
    "    required_fields = [\"latency_ms\", \"tokens_per_second\", \"total_tokens\", \"timestamp\"]\n",
    "    missing = [f for f in required_fields if f not in sample or sample[f] is None]\n",
    "\n",
    "    if missing:\n",
    "        print(f\"❌ Missing fields: {missing}\")\n",
    "    else:\n",
    "        print(\"✅ All required metrics present\")\n",
    "        print(f\"✅ Sample latency: {sample['latency_ms']:.1f}ms\")\n",
    "        print(f\"✅ Sample throughput: {sample['tokens_per_second']:.1f} tok/s\")\n",
    "\n",
    "    # Check GPU monitoring\n",
    "    if GPU_AVAILABLE and sample.get(\"gpu_memory_mb\"):\n",
    "        print(f\"✅ GPU monitoring: {sample['gpu_memory_mb']:.1f}MB\")\n",
    "    else:\n",
    "        print(\"⚠️ GPU monitoring unavailable\")\n",
    "else:\n",
    "    print(\"❌ No baseline results to validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Generate standardized baseline report\n",
    "def calculate_summary_stats(results: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Calculate summary statistics from baseline results\"\"\"\n",
    "    if not results:\n",
    "        return {}\n",
    "\n",
    "    metrics = [r[\"metrics\"] for r in results]\n",
    "\n",
    "    # Extract numeric metrics\n",
    "    latencies = [m[\"latency_ms\"] for m in metrics]\n",
    "    throughputs = [m[\"tokens_per_second\"] for m in metrics]\n",
    "    token_counts = [m[\"total_tokens\"] for m in metrics]\n",
    "\n",
    "    return {\n",
    "        \"test_count\": len(results),\n",
    "        \"latency\": {\n",
    "            \"mean_ms\": sum(latencies) / len(latencies),\n",
    "            \"min_ms\": min(latencies),\n",
    "            \"max_ms\": max(latencies),\n",
    "        },\n",
    "        \"throughput\": {\n",
    "            \"mean_tok_per_sec\": sum(throughputs) / len(throughputs),\n",
    "            \"min_tok_per_sec\": min(throughputs),\n",
    "            \"max_tok_per_sec\": max(throughputs),\n",
    "        },\n",
    "        \"tokens\": {\n",
    "            \"mean_total\": sum(token_counts) / len(token_counts),\n",
    "            \"total_generated\": sum(m[\"completion_tokens\"] for m in metrics),\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Create comprehensive baseline report\n",
    "baseline_report = {\n",
    "    \"meta\": {\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"model_id\": adapter.model_id if adapter else \"mock_model\",\n",
    "        \"backend\": \"transformers\",\n",
    "        \"device\": (\n",
    "            str(torch.cuda.get_device_name(0)) if torch.cuda.is_available() else \"CPU\"\n",
    "        ),\n",
    "        \"gpu_available\": torch.cuda.is_available(),\n",
    "        \"gpu_monitoring\": GPU_AVAILABLE,\n",
    "    },\n",
    "    \"summary\": calculate_summary_stats(baseline_results),\n",
    "    \"detailed_results\": baseline_results,\n",
    "    \"system_info\": {\n",
    "        \"python_version\": f\"{psutil.sys.version_info.major}.{psutil.sys.version_info.minor}\",\n",
    "        \"cpu_count\": psutil.cpu_count(),\n",
    "        \"memory_total_gb\": psutil.virtual_memory().total / (1024**3),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "output_path = \"outs/baseline.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(baseline_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"[Report] Baseline saved to: {output_path}\")\n",
    "print(\n",
    "    f\"[Summary] {baseline_report['summary']['test_count']} tests, \"\n",
    "    f\"avg latency: {baseline_report['summary']['latency']['mean_ms']:.1f}ms, \"\n",
    "    f\"avg throughput: {baseline_report['summary']['throughput']['mean_tok_per_sec']:.1f} tok/s\"\n",
    ")\n",
    "\n",
    "# Display key metrics\n",
    "if baseline_report[\"summary\"]:\n",
    "    print(\"\\n=== Baseline Metrics Summary ===\")\n",
    "    print(\n",
    "        f\"平均延遲 (Average Latency): {baseline_report['summary']['latency']['mean_ms']:.1f}ms\"\n",
    "    )\n",
    "    print(\n",
    "        f\"平均吞吐量 (Average Throughput): {baseline_report['summary']['throughput']['mean_tok_per_sec']:.1f} tokens/sec\"\n",
    "    )\n",
    "    print(\n",
    "        f\"總生成詞元 (Total Tokens Generated): {baseline_report['summary']['tokens']['total_generated']}\"\n",
    "    )\n",
    "    print(f\"GPU 監控 (GPU Monitoring): {'啟用' if GPU_AVAILABLE else '未啟用'}\")\n",
    "    print(\"============================\")\n",
    "\n",
    "print(\"\\n[Complete] nb06 baseline metrics collection finished!\")\n",
    "print(\n",
    "    \"Next: Use these metrics to compare different models/settings in future notebooks.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297379f",
   "metadata": {},
   "source": [
    "Smoke Test測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick validation that metrics work\n",
    "assert len(baseline_results) > 0, \"Should have baseline results\"\n",
    "assert \"metrics\" in baseline_results[0], \"Should have metrics in results\"\n",
    "assert baseline_results[0][\"metrics\"][\"latency_ms\"] > 0, \"Should have positive latency\"\n",
    "print(\"✅ Smoke test passed - metrics collection working\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
