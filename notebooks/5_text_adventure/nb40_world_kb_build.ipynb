{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327da18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell1:  Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (複製到每本 notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e380e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: World KB Schema and Sample Data\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from opencc import OpenCC\n",
    "\n",
    "\n",
    "# Game world schema\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    title: Optional[str] = None\n",
    "    description: str\n",
    "    attributes: Dict[str, int] = Field(default_factory=dict)\n",
    "    background: str\n",
    "    relationships: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class Location(BaseModel):\n",
    "    name: str\n",
    "    type: str  # city, dungeon, wilderness, etc.\n",
    "    description: str\n",
    "    connections: List[str] = Field(default_factory=list)\n",
    "    features: List[str] = Field(default_factory=list)\n",
    "    dangers: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    type: str  # weapon, armor, consumable, quest, etc.\n",
    "    description: str\n",
    "    properties: Dict[str, str] = Field(default_factory=dict)\n",
    "    rarity: str = \"common\"\n",
    "\n",
    "\n",
    "class Event(BaseModel):\n",
    "    name: str\n",
    "    type: str  # story, random, quest, etc.\n",
    "    description: str\n",
    "    triggers: List[str] = Field(default_factory=list)\n",
    "    outcomes: List[str] = Field(default_factory=list)\n",
    "    requirements: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "# Create sample world data\n",
    "def create_sample_world_data():\n",
    "    \"\"\"Create sample world KB data for testing\"\"\"\n",
    "\n",
    "    # Characters\n",
    "    characters = [\n",
    "        Character(\n",
    "            name=\"艾莉亞\",\n",
    "            title=\"星空法師\",\n",
    "            description=\"掌握古老星象魔法的年輕法師，擁有預見未來的能力。\",\n",
    "            attributes={\"智力\": 18, \"魔力\": 16, \"體力\": 12},\n",
    "            background=\"出身於古老的星象法師家族，自幼習得觀星占卜之術。在一次意外中獲得了預見未來的能力，但代價是每次使用都會縮短壽命。\",\n",
    "            relationships=[\"導師：賢者萬德\", \"宿敵：暗影領主\"],\n",
    "        ),\n",
    "        Character(\n",
    "            name=\"雷克斯\",\n",
    "            title=\"鋼鐵騎士\",\n",
    "            description=\"身穿重甲的正義騎士，以保護無辜為己任。\",\n",
    "            attributes={\"力量\": 17, \"體力\": 19, \"意志\": 15},\n",
    "            background=\"曾經是王國精銳騎士團的隊長，在一場政變中失去了國王的信任。現在作為獨行俠游走各地，尋找重新證明自己的機會。\",\n",
    "            relationships=[\"舊友：宮廷侍衛長\", \"仇敵：叛變公爵\"],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Locations\n",
    "    locations = [\n",
    "        Location(\n",
    "            name=\"翡翠森林\",\n",
    "            type=\"wilderness\",\n",
    "            description=\"古老而神秘的森林，據說是精靈族的故鄉。樹木高聳入云，陽光透過樹葉灑下斑駁的光影。\",\n",
    "            connections=[\"銀月城\", \"古墓迷宮\", \"水晶湖\"],\n",
    "            features=[\"精靈遺跡\", \"古老智慧樹\", \"魔法泉水\"],\n",
    "            dangers=[\"迷路風險\", \"野生魔獸\", \"精靈陷阱\"],\n",
    "        ),\n",
    "        Location(\n",
    "            name=\"銀月城\",\n",
    "            type=\"city\",\n",
    "            description=\"建立在高山上的雄偉城市，以其銀白色的城牆和尖塔聞名。城中心有一座古老的魔法塔。\",\n",
    "            connections=[\"翡翠森林\", \"荒野平原\", \"地下城\"],\n",
    "            features=[\"魔法學院\", \"冒險者公會\", \"皇家圖書館\"],\n",
    "            dangers=[\"政治陰謀\", \"盜賊公會\", \"魔法實驗意外\"],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Items\n",
    "    items = [\n",
    "        Item(\n",
    "            name=\"星辰法杖\",\n",
    "            type=\"weapon\",\n",
    "            description=\"鑲嵌著古老星石的法杖，能夠引導星空的力量。在夜晚使用時威力倍增。\",\n",
    "            properties={\"魔法攻擊\": \"+15\", \"星象魔法\": \"+3\", \"夜晚加成\": \"雙倍威力\"},\n",
    "            rarity=\"legendary\",\n",
    "        ),\n",
    "        Item(\n",
    "            name=\"鋼鐵意志護符\",\n",
    "            type=\"accessory\",\n",
    "            description=\"古老騎士留下的護符，能夠增強佩戴者的意志力和勇氣。\",\n",
    "            properties={\"意志\": \"+2\", \"恐懼抗性\": \"免疫\", \"正義感\": \"+1\"},\n",
    "            rarity=\"rare\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Events\n",
    "    events = [\n",
    "        Event(\n",
    "            name=\"古老預言的實現\",\n",
    "            type=\"story\",\n",
    "            description=\"星空中出現了古老預言記載的星象，預示著重大變化即將來臨。\",\n",
    "            triggers=[\"進入翡翠森林\", \"與艾莉亞對話\", \"夜晚時刻\"],\n",
    "            outcomes=[\"獲得預言線索\", \"解鎖隱藏任務\", \"提升魔法能力\"],\n",
    "            requirements={\"智力\": \"15+\", \"魔法親和\": \"中等以上\"},\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"characters\": [c.dict() for c in characters],\n",
    "        \"locations\": [l.dict() for l in locations],\n",
    "        \"items\": [i.dict() for i in items],\n",
    "        \"events\": [e.dict() for e in events],\n",
    "    }\n",
    "\n",
    "\n",
    "# Create and save sample data\n",
    "sample_data = create_sample_world_data()\n",
    "Path(\"data/world_kb\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(\"data/world_kb/world_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sample_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✓ Created sample world KB data\")\n",
    "print(f\"Characters: {len(sample_data['characters'])}\")\n",
    "print(f\"Locations: {len(sample_data['locations'])}\")\n",
    "print(f\"Items: {len(sample_data['items'])}\")\n",
    "print(f\"Events: {len(sample_data['events'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: World KB Document Processor\n",
    "class WorldKBProcessor:\n",
    "    \"\"\"Process world KB documents into chunks for RAG indexing\"\"\"\n",
    "\n",
    "    def __init__(self, language=\"zh-tw\"):\n",
    "        self.language = language\n",
    "        self.cc = OpenCC(\"s2t\" if language == \"zh-tw\" else \"t2s\")\n",
    "\n",
    "    def process_character(self, char_data: Dict) -> List[Dict]:\n",
    "        \"\"\"Convert character data to searchable chunks\"\"\"\n",
    "        chunks = []\n",
    "\n",
    "        # Basic info chunk\n",
    "        basic_info = f\"角色：{char_data['name']}\\n\"\n",
    "        if char_data.get(\"title\"):\n",
    "            basic_info += f\"稱號：{char_data['title']}\\n\"\n",
    "        basic_info += f\"描述：{char_data['description']}\\n\"\n",
    "\n",
    "        # Attributes chunk\n",
    "        if char_data.get(\"attributes\"):\n",
    "            attrs = \"屬性：\" + \"、\".join(\n",
    "                [f\"{k}{v}\" for k, v in char_data[\"attributes\"].items()]\n",
    "            )\n",
    "            basic_info += attrs + \"\\n\"\n",
    "\n",
    "        chunks.append(\n",
    "            {\n",
    "                \"text\": basic_info.strip(),\n",
    "                \"meta\": {\n",
    "                    \"type\": \"character\",\n",
    "                    \"name\": char_data[\"name\"],\n",
    "                    \"category\": \"basic_info\",\n",
    "                    \"source\": \"world_kb\",\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Background chunk\n",
    "        if char_data.get(\"background\"):\n",
    "            chunks.append(\n",
    "                {\n",
    "                    \"text\": f\"角色背景：{char_data['name']}\\n{char_data['background']}\",\n",
    "                    \"meta\": {\n",
    "                        \"type\": \"character\",\n",
    "                        \"name\": char_data[\"name\"],\n",
    "                        \"category\": \"background\",\n",
    "                        \"source\": \"world_kb\",\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Relationships chunk\n",
    "        if char_data.get(\"relationships\"):\n",
    "            rel_text = f\"人物關係：{char_data['name']}\\n\" + \"\\n\".join(\n",
    "                char_data[\"relationships\"]\n",
    "            )\n",
    "            chunks.append(\n",
    "                {\n",
    "                    \"text\": rel_text,\n",
    "                    \"meta\": {\n",
    "                        \"type\": \"character\",\n",
    "                        \"name\": char_data[\"name\"],\n",
    "                        \"category\": \"relationships\",\n",
    "                        \"source\": \"world_kb\",\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def process_location(self, loc_data: Dict) -> List[Dict]:\n",
    "        \"\"\"Convert location data to searchable chunks\"\"\"\n",
    "        chunks = []\n",
    "\n",
    "        # Basic info chunk\n",
    "        basic_info = f\"地點：{loc_data['name']}\\n\"\n",
    "        basic_info += f\"類型：{loc_data['type']}\\n\"\n",
    "        basic_info += f\"描述：{loc_data['description']}\\n\"\n",
    "\n",
    "        chunks.append(\n",
    "            {\n",
    "                \"text\": basic_info.strip(),\n",
    "                \"meta\": {\n",
    "                    \"type\": \"location\",\n",
    "                    \"name\": loc_data[\"name\"],\n",
    "                    \"category\": \"basic_info\",\n",
    "                    \"source\": \"world_kb\",\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Connections chunk\n",
    "        if loc_data.get(\"connections\"):\n",
    "            conn_text = f\"地點連接：{loc_data['name']}\\n可前往：\" + \"、\".join(\n",
    "                loc_data[\"connections\"]\n",
    "            )\n",
    "            chunks.append(\n",
    "                {\n",
    "                    \"text\": conn_text,\n",
    "                    \"meta\": {\n",
    "                        \"type\": \"location\",\n",
    "                        \"name\": loc_data[\"name\"],\n",
    "                        \"category\": \"connections\",\n",
    "                        \"source\": \"world_kb\",\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Features and dangers chunk\n",
    "        features_text = f\"地點特色：{loc_data['name']}\\n\"\n",
    "        if loc_data.get(\"features\"):\n",
    "            features_text += \"特色：\" + \"、\".join(loc_data[\"features\"]) + \"\\n\"\n",
    "        if loc_data.get(\"dangers\"):\n",
    "            features_text += \"危險：\" + \"、\".join(loc_data[\"dangers\"])\n",
    "\n",
    "        if len(features_text.strip()) > len(f\"地點特色：{loc_data['name']}\"):\n",
    "            chunks.append(\n",
    "                {\n",
    "                    \"text\": features_text.strip(),\n",
    "                    \"meta\": {\n",
    "                        \"type\": \"location\",\n",
    "                        \"name\": loc_data[\"name\"],\n",
    "                        \"category\": \"features\",\n",
    "                        \"source\": \"world_kb\",\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def process_item(self, item_data: Dict) -> List[Dict]:\n",
    "        \"\"\"Convert item data to searchable chunks\"\"\"\n",
    "        item_text = f\"物品：{item_data['name']}\\n\"\n",
    "        item_text += f\"類型：{item_data['type']}\\n\"\n",
    "        item_text += f\"稀有度：{item_data['rarity']}\\n\"\n",
    "        item_text += f\"描述：{item_data['description']}\\n\"\n",
    "\n",
    "        if item_data.get(\"properties\"):\n",
    "            props = \"屬性：\" + \"、\".join(\n",
    "                [f\"{k}:{v}\" for k, v in item_data[\"properties\"].items()]\n",
    "            )\n",
    "            item_text += props\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"text\": item_text.strip(),\n",
    "                \"meta\": {\n",
    "                    \"type\": \"item\",\n",
    "                    \"name\": item_data[\"name\"],\n",
    "                    \"category\": \"full_info\",\n",
    "                    \"source\": \"world_kb\",\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def process_event(self, event_data: Dict) -> List[Dict]:\n",
    "        \"\"\"Convert event data to searchable chunks\"\"\"\n",
    "        event_text = f\"事件：{event_data['name']}\\n\"\n",
    "        event_text += f\"類型：{event_data['type']}\\n\"\n",
    "        event_text += f\"描述：{event_data['description']}\\n\"\n",
    "\n",
    "        if event_data.get(\"triggers\"):\n",
    "            event_text += \"觸發條件：\" + \"、\".join(event_data[\"triggers\"]) + \"\\n\"\n",
    "        if event_data.get(\"outcomes\"):\n",
    "            event_text += \"可能結果：\" + \"、\".join(event_data[\"outcomes\"]) + \"\\n\"\n",
    "        if event_data.get(\"requirements\"):\n",
    "            reqs = \"需求：\" + \"、\".join(\n",
    "                [f\"{k}:{v}\" for k, v in event_data[\"requirements\"].items()]\n",
    "            )\n",
    "            event_text += reqs\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"text\": event_text.strip(),\n",
    "                \"meta\": {\n",
    "                    \"type\": \"event\",\n",
    "                    \"name\": event_data[\"name\"],\n",
    "                    \"category\": \"full_info\",\n",
    "                    \"source\": \"world_kb\",\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def process_world_data(self, world_data: Dict) -> List[Dict]:\n",
    "        \"\"\"Process complete world data into chunks\"\"\"\n",
    "        all_chunks = []\n",
    "\n",
    "        # Process each category\n",
    "        for char in world_data.get(\"characters\", []):\n",
    "            all_chunks.extend(self.process_character(char))\n",
    "\n",
    "        for loc in world_data.get(\"locations\", []):\n",
    "            all_chunks.extend(self.process_location(loc))\n",
    "\n",
    "        for item in world_data.get(\"items\", []):\n",
    "            all_chunks.extend(self.process_item(item))\n",
    "\n",
    "        for event in world_data.get(\"events\", []):\n",
    "            all_chunks.extend(self.process_event(event))\n",
    "\n",
    "        return all_chunks\n",
    "\n",
    "\n",
    "# Test the processor\n",
    "processor = WorldKBProcessor()\n",
    "chunks = processor.process_world_data(sample_data)\n",
    "\n",
    "print(f\"✓ Processed world data into {len(chunks)} chunks\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1} ({chunk['meta']['type']} - {chunk['meta']['category']}):\")\n",
    "    print(chunk[\"text\"][:100] + \"...\" if len(chunk[\"text\"]) > 100 else chunk[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Build FAISS Index for World KB\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WorldKBIndex:\n",
    "    \"\"\"FAISS index specifically for game world knowledge base\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"BAAI/bge-m3\"):\n",
    "        print(f\"Loading embedding model: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.chunks = []\n",
    "\n",
    "    def build_index(self, chunks: List[Dict]):\n",
    "        \"\"\"Build FAISS index from world KB chunks\"\"\"\n",
    "        print(f\"Building index for {len(chunks)} chunks...\")\n",
    "\n",
    "        # Extract texts and compute embeddings\n",
    "        texts = [chunk[\"text\"] for chunk in chunks]\n",
    "        print(\"Computing embeddings...\")\n",
    "        embeddings = self.model.encode(\n",
    "            texts, normalize_embeddings=True, batch_size=16, show_progress_bar=True\n",
    "        ).astype(\"float32\")\n",
    "\n",
    "        # Create FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(\n",
    "            dimension\n",
    "        )  # Inner product for normalized vectors\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "        # Store chunks for retrieval\n",
    "        self.chunks = chunks\n",
    "\n",
    "        print(\n",
    "            f\"✓ Built index with {self.index.ntotal} vectors (dimension: {dimension})\"\n",
    "        )\n",
    "        return self.index\n",
    "\n",
    "    def search(\n",
    "        self, query: str, k: int = 5, filter_type: Optional[str] = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Search world KB with optional type filtering\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not built yet. Call build_index() first.\")\n",
    "\n",
    "        # Compute query embedding\n",
    "        query_embedding = self.model.encode([query], normalize_embeddings=True).astype(\n",
    "            \"float32\"\n",
    "        )\n",
    "\n",
    "        # Search index\n",
    "        scores, indices = self.index.search(\n",
    "            query_embedding, min(k * 3, len(self.chunks))\n",
    "        )\n",
    "\n",
    "        # Get results with metadata\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            if idx == -1:  # Invalid index\n",
    "                continue\n",
    "\n",
    "            chunk = self.chunks[idx]\n",
    "\n",
    "            # Apply type filter if specified\n",
    "            if filter_type and chunk[\"meta\"][\"type\"] != filter_type:\n",
    "                continue\n",
    "\n",
    "            results.append(\n",
    "                {\"text\": chunk[\"text\"], \"meta\": chunk[\"meta\"], \"score\": float(score)}\n",
    "            )\n",
    "\n",
    "            if len(results) >= k:\n",
    "                break\n",
    "\n",
    "        return results\n",
    "\n",
    "    def save_index(self, index_path: str, chunks_path: str):\n",
    "        \"\"\"Save index and chunks to disk\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"No index to save\")\n",
    "\n",
    "        # Save FAISS index\n",
    "        faiss.write_index(self.index, index_path)\n",
    "\n",
    "        # Save chunks as JSONL\n",
    "        with open(chunks_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for chunk in self.chunks:\n",
    "                f.write(json.dumps(chunk, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        print(f\"✓ Saved index to {index_path}\")\n",
    "        print(f\"✓ Saved chunks to {chunks_path}\")\n",
    "\n",
    "    def load_index(self, index_path: str, chunks_path: str):\n",
    "        \"\"\"Load index and chunks from disk\"\"\"\n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        # Load chunks\n",
    "        self.chunks = []\n",
    "        with open(chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                self.chunks.append(json.loads(line.strip()))\n",
    "\n",
    "        print(f\"✓ Loaded index with {self.index.ntotal} vectors\")\n",
    "        print(f\"✓ Loaded {len(self.chunks)} chunks\")\n",
    "\n",
    "\n",
    "# Build the world KB index\n",
    "kb_index = WorldKBIndex()\n",
    "kb_index.build_index(chunks)\n",
    "\n",
    "# Save to indices folder\n",
    "Path(\"indices\").mkdir(exist_ok=True)\n",
    "kb_index.save_index(\"indices/world_kb.faiss\", \"indices/world_kb_chunks.jsonl\")\n",
    "\n",
    "print(\"\\n=== World KB Index Ready ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: World KB Retrieval System\n",
    "class WorldKBRetriever:\n",
    "    \"\"\"High-level retrieval system for game world knowledge\"\"\"\n",
    "\n",
    "    def __init__(self, index_path: str, chunks_path: str):\n",
    "        self.kb_index = WorldKBIndex()\n",
    "        self.kb_index.load_index(index_path, chunks_path)\n",
    "\n",
    "    def get_character_info(self, character_name: str) -> Dict:\n",
    "        \"\"\"Get comprehensive character information\"\"\"\n",
    "        results = self.kb_index.search(\n",
    "            f\"角色 {character_name}\", k=10, filter_type=\"character\"\n",
    "        )\n",
    "\n",
    "        # Group by category\n",
    "        info = {\"basic_info\": [], \"background\": [], \"relationships\": []}\n",
    "\n",
    "        for result in results:\n",
    "            category = result[\"meta\"][\"category\"]\n",
    "            if category in info:\n",
    "                info[category].append(result)\n",
    "\n",
    "        return info\n",
    "\n",
    "    def get_location_info(self, location_name: str) -> Dict:\n",
    "        \"\"\"Get comprehensive location information\"\"\"\n",
    "        results = self.kb_index.search(\n",
    "            f\"地點 {location_name}\", k=10, filter_type=\"location\"\n",
    "        )\n",
    "\n",
    "        info = {\"basic_info\": [], \"connections\": [], \"features\": []}\n",
    "\n",
    "        for result in results:\n",
    "            category = result[\"meta\"][\"category\"]\n",
    "            if category in info:\n",
    "                info[category].append(result)\n",
    "\n",
    "        return info\n",
    "\n",
    "    def search_items_by_type(self, item_type: str) -> List[Dict]:\n",
    "        \"\"\"Search items by type\"\"\"\n",
    "        return self.kb_index.search(f\"物品 類型 {item_type}\", k=10, filter_type=\"item\")\n",
    "\n",
    "    def find_related_events(self, context: str) -> List[Dict]:\n",
    "        \"\"\"Find events related to given context\"\"\"\n",
    "        return self.kb_index.search(f\"事件 {context}\", k=5, filter_type=\"event\")\n",
    "\n",
    "    def contextual_search(self, query: str, k: int = 5) -> List[Dict]:\n",
    "        \"\"\"General contextual search across all world knowledge\"\"\"\n",
    "        return self.kb_index.search(query, k=k)\n",
    "\n",
    "\n",
    "# Test the retrieval system\n",
    "retriever = WorldKBRetriever(\"indices/world_kb.faiss\", \"indices/world_kb_chunks.jsonl\")\n",
    "\n",
    "print(\"=== Testing World KB Retrieval ===\\n\")\n",
    "\n",
    "# Test character lookup\n",
    "char_info = retriever.get_character_info(\"艾莉亞\")\n",
    "print(\"Character Info for 艾莉亞:\")\n",
    "for category, results in char_info.items():\n",
    "    if results:\n",
    "        print(f\"  {category}: {len(results)} results\")\n",
    "        print(f\"    {results[0]['text'][:80]}...\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test location lookup\n",
    "loc_info = retriever.get_location_info(\"翡翠森林\")\n",
    "print(\"Location Info for 翡翠森林:\")\n",
    "for category, results in loc_info.items():\n",
    "    if results:\n",
    "        print(f\"  {category}: {len(results)} results\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test contextual search\n",
    "context_results = retriever.contextual_search(\"魔法 法師\")\n",
    "print(\"Contextual search for '魔法 法師':\")\n",
    "for i, result in enumerate(context_results[:2]):\n",
    "    print(\n",
    "        f\"  {i+1}. [{result['meta']['type']}] {result['text'][:60]}... (score: {result['score']:.3f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9efb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Game Event Generator with RAG\n",
    "class GameEventGenerator:\n",
    "    \"\"\"Generate dynamic game events using world KB knowledge\"\"\"\n",
    "\n",
    "    def __init__(self, retriever: WorldKBRetriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def generate_location_event(self, location_name: str, player_context: Dict) -> Dict:\n",
    "        \"\"\"Generate an event for a specific location\"\"\"\n",
    "\n",
    "        # Get location info from KB\n",
    "        loc_info = self.retriever.get_location_info(location_name)\n",
    "\n",
    "        # Build context from KB\n",
    "        context_parts = []\n",
    "        for category, results in loc_info.items():\n",
    "            for result in results:\n",
    "                context_parts.append(result[\"text\"])\n",
    "\n",
    "        location_context = \"\\n\".join(context_parts[:3])  # Limit context size\n",
    "\n",
    "        # Find related events\n",
    "        related_events = self.retriever.find_related_events(location_name)\n",
    "        event_context = \"\"\n",
    "        if related_events:\n",
    "            event_context = related_events[0][\"text\"]\n",
    "\n",
    "        # Simple event generation logic (in real game, this would use LLM)\n",
    "        event_data = {\n",
    "            \"location\": location_name,\n",
    "            \"context_used\": {\n",
    "                \"location_info\": len(context_parts),\n",
    "                \"related_events\": len(related_events),\n",
    "            },\n",
    "            \"event_prompt\": f\"\"\"\n",
    "基於以下世界知識生成事件：\n",
    "\n",
    "地點信息：\n",
    "{location_context}\n",
    "\n",
    "相關事件：\n",
    "{event_context}\n",
    "\n",
    "玩家狀態：\n",
    "- 等級：{player_context.get('level', 1)}\n",
    "- 職業：{player_context.get('class', '冒險者')}\n",
    "- 當前位置：{location_name}\n",
    "\n",
    "請生成一個適合此情境的遊戲事件。\n",
    "\"\"\".strip(),\n",
    "        }\n",
    "\n",
    "        return event_data\n",
    "\n",
    "    def generate_character_encounter(self, character_name: str) -> Dict:\n",
    "        \"\"\"Generate encounter with specific character\"\"\"\n",
    "\n",
    "        char_info = self.retriever.get_character_info(character_name)\n",
    "\n",
    "        # Collect character context\n",
    "        context_parts = []\n",
    "        for category, results in char_info.items():\n",
    "            for result in results:\n",
    "                context_parts.append(result[\"text\"])\n",
    "\n",
    "        character_context = \"\\n\".join(context_parts[:2])\n",
    "\n",
    "        encounter_data = {\n",
    "            \"character\": character_name,\n",
    "            \"context_used\": {\"character_info\": len(context_parts)},\n",
    "            \"encounter_prompt\": f\"\"\"\n",
    "基於以下角色信息生成遭遇事件：\n",
    "\n",
    "角色信息：\n",
    "{character_context}\n",
    "\n",
    "生成與此角色的互動事件，包括可能的對話選項和結果。\n",
    "\"\"\".strip(),\n",
    "        }\n",
    "\n",
    "        return encounter_data\n",
    "\n",
    "\n",
    "# Test event generation\n",
    "event_gen = GameEventGenerator(retriever)\n",
    "\n",
    "print(\"=== Testing Event Generation ===\\n\")\n",
    "\n",
    "# Test location event\n",
    "player_context = {\"level\": 3, \"class\": \"法師\"}\n",
    "location_event = event_gen.generate_location_event(\"翡翠森林\", player_context)\n",
    "print(\"Location Event for 翡翠森林:\")\n",
    "print(f\"Context used: {location_event['context_used']}\")\n",
    "print(f\"Prompt length: {len(location_event['event_prompt'])} characters\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test character encounter\n",
    "char_encounter = event_gen.generate_character_encounter(\"艾莉亞\")\n",
    "print(\"Character Encounter for 艾莉亞:\")\n",
    "print(f\"Context used: {char_encounter['context_used']}\")\n",
    "print(f\"Prompt length: {len(char_encounter['encounter_prompt'])} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Smoke Test - Complete World KB Pipeline\n",
    "def smoke_test_world_kb():\n",
    "    \"\"\"Comprehensive smoke test for world KB system\"\"\"\n",
    "\n",
    "    print(\"🧪 World KB Smoke Test\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Test 1: Data creation\n",
    "    print(\"\\n1. Testing sample data creation...\")\n",
    "    data = create_sample_world_data()\n",
    "    assert len(data[\"characters\"]) >= 2, \"Should have at least 2 characters\"\n",
    "    assert len(data[\"locations\"]) >= 2, \"Should have at least 2 locations\"\n",
    "    print(\"✓ Sample data created successfully\")\n",
    "\n",
    "    # Test 2: Document processing\n",
    "    print(\"\\n2. Testing document processing...\")\n",
    "    processor = WorldKBProcessor()\n",
    "    chunks = processor.process_world_data(data)\n",
    "    assert len(chunks) > 0, \"Should generate chunks\"\n",
    "    assert all(\n",
    "        \"text\" in chunk and \"meta\" in chunk for chunk in chunks\n",
    "    ), \"Chunks should have text and meta\"\n",
    "    print(f\"✓ Generated {len(chunks)} chunks\")\n",
    "\n",
    "    # Test 3: Index building\n",
    "    print(\"\\n3. Testing index building...\")\n",
    "    kb_index = WorldKBIndex()\n",
    "    index = kb_index.build_index(chunks)\n",
    "    assert index.ntotal == len(chunks), \"Index should contain all chunks\"\n",
    "    print(f\"✓ Built index with {index.ntotal} vectors\")\n",
    "\n",
    "    # Test 4: Search functionality\n",
    "    print(\"\\n4. Testing search functionality...\")\n",
    "    results = kb_index.search(\"艾莉亞\", k=3)\n",
    "    assert len(results) > 0, \"Should find results for character search\"\n",
    "    assert all(\"score\" in r for r in results), \"Results should have scores\"\n",
    "    print(f\"✓ Found {len(results)} results for character search\")\n",
    "\n",
    "    # Test 5: Retrieval system\n",
    "    print(\"\\n5. Testing retrieval system...\")\n",
    "    # Create temporary files for testing\n",
    "    kb_index.save_index(\"test_world.faiss\", \"test_world_chunks.jsonl\")\n",
    "    retriever = WorldKBRetriever(\"test_world.faiss\", \"test_world_chunks.jsonl\")\n",
    "\n",
    "    char_info = retriever.get_character_info(\"艾莉亞\")\n",
    "    assert any(\n",
    "        len(info) > 0 for info in char_info.values()\n",
    "    ), \"Should find character info\"\n",
    "    print(\"✓ Character retrieval working\")\n",
    "\n",
    "    # Test 6: Event generation\n",
    "    print(\"\\n6. Testing event generation...\")\n",
    "    event_gen = GameEventGenerator(retriever)\n",
    "    location_event = event_gen.generate_location_event(\"翡翠森林\", {\"level\": 1})\n",
    "    assert \"event_prompt\" in location_event, \"Should generate event prompt\"\n",
    "    assert (\n",
    "        len(location_event[\"event_prompt\"]) > 100\n",
    "    ), \"Event prompt should be substantial\"\n",
    "    print(\"✓ Event generation working\")\n",
    "\n",
    "    # Cleanup\n",
    "    import os\n",
    "\n",
    "    try:\n",
    "        os.remove(\"test_world.faiss\")\n",
    "        os.remove(\"test_world_chunks.jsonl\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n🎉 All tests passed! World KB system is ready.\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# Run smoke test\n",
    "smoke_test_world_kb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0964c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Integration Example - World Query System\n",
    "class WorldQuerySystem:\n",
    "    \"\"\"Complete query system for game world information\"\"\"\n",
    "\n",
    "    def __init__(self, retriever: WorldKBRetriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def answer_world_question(self, question: str) -> Dict:\n",
    "        \"\"\"Answer questions about the game world using RAG\"\"\"\n",
    "\n",
    "        # Search for relevant information\n",
    "        results = self.retriever.contextual_search(question, k=5)\n",
    "\n",
    "        # Build context from search results\n",
    "        context_parts = []\n",
    "        sources = []\n",
    "\n",
    "        for i, result in enumerate(results):\n",
    "            context_parts.append(f\"[{i+1}] {result['text']}\")\n",
    "            sources.append(\n",
    "                {\n",
    "                    \"index\": i + 1,\n",
    "                    \"type\": result[\"meta\"][\"type\"],\n",
    "                    \"name\": result[\"meta\"][\"name\"],\n",
    "                    \"category\": result[\"meta\"][\"category\"],\n",
    "                    \"score\": result[\"score\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "        # Generate answer prompt (in real game, this would go to LLM)\n",
    "        answer_prompt = f\"\"\"\n",
    "問題：{question}\n",
    "\n",
    "相關世界知識：\n",
    "{context}\n",
    "\n",
    "請根據上述世界知識回答問題，並在回答中標註引用來源 [1]、[2] 等。\n",
    "如果知識不足以回答問題，請說明需要更多哪方面的信息。\n",
    "\"\"\"\n",
    "\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"sources\": sources,\n",
    "            \"answer_prompt\": answer_prompt,\n",
    "            \"source_count\": len(sources),\n",
    "        }\n",
    "\n",
    "    def get_location_summary(self, location: str) -> str:\n",
    "        \"\"\"Get a comprehensive summary of a location\"\"\"\n",
    "        loc_info = self.retriever.get_location_info(location)\n",
    "\n",
    "        summary_parts = []\n",
    "        for category, results in loc_info.items():\n",
    "            if results:\n",
    "                summary_parts.append(f\"{category}: {results[0]['text']}\")\n",
    "\n",
    "        return \"\\n\".join(summary_parts)\n",
    "\n",
    "    def find_quest_hooks(self, player_interests: List[str]) -> List[Dict]:\n",
    "        \"\"\"Find potential quest hooks based on player interests\"\"\"\n",
    "        quest_hooks = []\n",
    "\n",
    "        for interest in player_interests:\n",
    "            results = self.retriever.contextual_search(f\"任務 {interest}\", k=3)\n",
    "            for result in results:\n",
    "                if result[\"meta\"][\"type\"] == \"event\":\n",
    "                    quest_hooks.append(\n",
    "                        {\n",
    "                            \"hook\": result[\"text\"],\n",
    "                            \"interest\": interest,\n",
    "                            \"score\": result[\"score\"],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Sort by score and remove duplicates\n",
    "        quest_hooks.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        seen = set()\n",
    "        unique_hooks = []\n",
    "        for hook in quest_hooks:\n",
    "            hook_text = hook[\"hook\"][:50]  # First 50 chars as identifier\n",
    "            if hook_text not in seen:\n",
    "                seen.add(hook_text)\n",
    "                unique_hooks.append(hook)\n",
    "\n",
    "        return unique_hooks[:5]  # Return top 5\n",
    "\n",
    "\n",
    "# Test the query system\n",
    "query_system = WorldQuerySystem(retriever)\n",
    "\n",
    "print(\"=== Testing World Query System ===\\n\")\n",
    "\n",
    "# Test world question answering\n",
    "question = \"艾莉亞有什麼特殊能力？\"\n",
    "answer_data = query_system.answer_world_question(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Found {answer_data['source_count']} relevant sources\")\n",
    "print(\"Sources:\")\n",
    "for source in answer_data[\"sources\"][:2]:\n",
    "    print(\n",
    "        f\"  [{source['index']}] {source['type']} - {source['name']} ({source['score']:.3f})\"\n",
    "    )\n",
    "\n",
    "print()\n",
    "\n",
    "# Test location summary\n",
    "location = \"銀月城\"\n",
    "summary = query_system.get_location_summary(location)\n",
    "print(f\"Location Summary for {location}:\")\n",
    "print(summary[:200] + \"...\" if len(summary) > 200 else summary)\n",
    "\n",
    "print()\n",
    "\n",
    "# Test quest hook finding\n",
    "player_interests = [\"魔法\", \"冒險\"]\n",
    "quest_hooks = query_system.find_quest_hooks(player_interests)\n",
    "print(f\"Quest hooks for interests {player_interests}:\")\n",
    "for i, hook in enumerate(quest_hooks[:2]):\n",
    "    print(\n",
    "        f\"  {i+1}. {hook['hook'][:80]}... (interest: {hook['interest']}, score: {hook['score']:.3f})\"\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ World KB system fully operational!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Performance and Usage Tips\n",
    "print(\"=== World KB Performance Metrics ===\")\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "\n",
    "def measure_performance():\n",
    "    \"\"\"Measure key performance metrics\"\"\"\n",
    "\n",
    "    # Memory usage\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "    # Index size\n",
    "    try:\n",
    "        index_size_mb = os.path.getsize(\"indices/world_kb.faiss\") / 1024 / 1024\n",
    "        chunks_size_mb = os.path.getsize(\"indices/world_kb_chunks.jsonl\") / 1024 / 1024\n",
    "    except:\n",
    "        index_size_mb = chunks_size_mb = 0\n",
    "\n",
    "    # Search latency\n",
    "    start_time = time.time()\n",
    "    results = retriever.contextual_search(\"測試查詢\", k=5)\n",
    "    search_latency_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "    print(f\"Memory usage: {memory_mb:.1f} MB\")\n",
    "    print(f\"Index size: {index_size_mb:.2f} MB\")\n",
    "    print(f\"Chunks size: {chunks_size_mb:.2f} MB\")\n",
    "    print(f\"Search latency: {search_latency_ms:.1f} ms\")\n",
    "    print(f\"Chunks in index: {len(retriever.kb_index.chunks)}\")\n",
    "\n",
    "    return {\n",
    "        \"memory_mb\": memory_mb,\n",
    "        \"index_size_mb\": index_size_mb,\n",
    "        \"search_latency_ms\": search_latency_ms,\n",
    "        \"chunk_count\": len(retriever.kb_index.chunks),\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = measure_performance()\n",
    "\n",
    "print(\"\\n=== Usage Tips ===\")\n",
    "print(\n",
    "    \"\"\"\n",
    "1. **擴展世界內容**：\n",
    "   - 在 data/world_kb/ 添加更多 JSON 檔案\n",
    "   - 使用 WorldKBProcessor 處理新內容\n",
    "   - 重建索引以包含新內容\n",
    "\n",
    "2. **優化檢索效果**：\n",
    "   - 使用具體的查詢詞彙\n",
    "   - 利用類型過濾 (filter_type) 縮小搜尋範圍\n",
    "   - 調整 k 值平衡召回率和精確度\n",
    "\n",
    "3. **記憶體優化**：\n",
    "   - 目前記憶體使用：{:.1f} MB\n",
    "   - 可使用較小的嵌入模型（如 bge-small-zh）\n",
    "   - 考慮使用 FAISS IVF 索引處理大型世界\n",
    "\n",
    "4. **遊戲整合**：\n",
    "   - 將 retriever 整合到遊戲主迴圈\n",
    "   - 快取常用查詢結果\n",
    "   - 使用 filter_type 提高查詢效率\n",
    "\n",
    "5. **內容管理**：\n",
    "   - 定期備份索引檔案\n",
    "   - 版本控制世界內容變更\n",
    "   - 監控索引大小和查詢延遲\n",
    "\"\"\".format(\n",
    "        metrics[\"memory_mb\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n🎮 Ready to power your text adventure game!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b998d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: What We Built / Pitfalls / Next Steps\n",
    "print(\"=== What We Built ===\")\n",
    "print(\n",
    "    \"\"\"\n",
    "✅ 完整的遊戲世界知識庫系統：\n",
    "   • Pydantic schema 定義角色、地點、物品、事件\n",
    "   • 世界內容處理器，將結構化數據轉為可檢索片段\n",
    "   • FAISS 向量索引，支援語義搜尋\n",
    "   • 專門的檢索系統，支援類型過濾和分類查詢\n",
    "   • 事件生成器，基於世界知識產生動態內容\n",
    "   • 完整的查詢系統，支援問答和任務線索發現\n",
    "\n",
    "✅ 核心功能：\n",
    "   • 多類型內容索引（角色、地點、物品、事件）\n",
    "   • 語義搜尋和精確檢索\n",
    "   • 上下文感知的事件生成\n",
    "   • 引用追蹤和來源標註\n",
    "   • 效能監控和優化建議\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Pitfalls 避坑指南 ===\")\n",
    "print(\n",
    "    \"\"\"\n",
    "⚠️  常見問題：\n",
    "   • 索引檔案可能很大，確保有足夠儲存空間\n",
    "   • 嵌入計算需要時間，大型世界建議分批處理\n",
    "   • 查詢結果品質取決於原始內容的結構化程度\n",
    "   • 中文分詞可能影響檢索效果，考慮使用專業中文嵌入模型\n",
    "\n",
    "⚠️  效能注意事項：\n",
    "   • 避免頻繁重建索引，使用增量更新\n",
    "   • 快取常用查詢結果\n",
    "   • 監控記憶體使用，必要時使用較小模型\n",
    "   • 大型世界考慮使用 FAISS GPU 版本\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Next Steps 後續發展 ===\")\n",
    "print(\n",
    "    \"\"\"\n",
    "🚀 立即可行：\n",
    "   • 整合到 nb41 狀態機核心\n",
    "   • 添加更豐富的世界內容\n",
    "   • 實現增量索引更新機制\n",
    "\n",
    "🚀 進階功能：\n",
    "   • 多語言世界內容支援\n",
    "   • 時間軸相關的動態世界狀態\n",
    "   • 玩家行為對世界知識的影響\n",
    "   • 更智慧的事件生成（整合 LLM）\n",
    "\n",
    "🚀 系統整合：\n",
    "   • 與 nb42 事件生成系統深度整合\n",
    "   • 支援 nb45 存檔系統的世界狀態\n",
    "   • 為 nb46 敘事風格提供一致性檢查\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Reproducibility 重現步驟 ===\")\n",
    "print(\n",
    "    \"\"\"\n",
    "1. 確保環境變數 AI_CACHE_ROOT 已設置\n",
    "2. 安裝依賴：sentence-transformers, faiss-cpu, opencc, pydantic\n",
    "3. 運行所有 cells 按順序執行\n",
    "4. 檢查 indices/ 資料夾下的索引檔案\n",
    "5. 驗證 smoke test 全部通過\n",
    "\n",
    "檔案輸出：\n",
    "• indices/world_kb.faiss (向量索引)\n",
    "• indices/world_kb_chunks.jsonl (文檔片段)\n",
    "• data/world_kb/world_data.json (範例世界數據)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\n🎯 本 Notebook 為 Stage 5 的基石，為後續文字冒險遊戲提供了強大的世界知識檢索能力！\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
